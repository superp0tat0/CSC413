{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "autograd_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW6E9VvcmYpd",
        "colab_type": "text"
      },
      "source": [
        "# Autograd\n",
        "\n",
        "References:\n",
        "\n",
        "* Ryan Adams' talk: https://www.youtube.com/watch?v=sq2gPzlrM0g\n",
        "* Backpropagation notes from Stanford's CS231n: http://cs231n.github.io/optimization-2/\n",
        "* Autograd Github Repository (contains a tutorial and examples): https://github.com/HIPS/autograd\n",
        "\n",
        "## Approaches for Computing Derivatives\n",
        "\n",
        "* **Symbolic differentiation:** automatic manipulation of mathematical expressions to get derivatives\n",
        "    - Takes a math expression and returns a math expression: $f(x) = x^2 \\rightarrow \\frac{df(x)}{dx} = 2x$\n",
        "    - Used in Mathematica, Maple, Sympy, etc.\n",
        "* **Numeric differentiation:** Approximating derivatives by finite differences:\n",
        "$$\n",
        "\\frac{\\partial}{\\partial x_i} f(x_1, \\dots, x_N) = \\lim_{h \\to 0} \\frac{f(x_1, \\dots, x_i + h, \\dots, x_N) - f(x_1, \\dots, x_i - h, \\dots, x_N)}{2h}\n",
        "$$\n",
        "* **Automatic differentiation:** Takes code that computes a function and returns code that computes the derivative of that function.\n",
        "    - Reverse Mode AD: A method to get exact derivatives efficiently, by storing information as you go forward that you can reuse as you go backwards\n",
        "    - \"The goal isn't to obtain closed-form solutions, but to be able to wirte a program that efficiently computes the derivatives.\" - Lecture 6 Slides (Backpropagation)\n",
        "    - **Torch, Autograd**\n",
        "\n",
        "## Reverse Mode Automatic Differentiation\n",
        "\n",
        "In machine learning, we have functions that have large fan-in, e.g. a neural net can have millions of parameters, that all squeeze down to one scalar that tells you how well it predicts something.  cats.\n",
        "\n",
        "### General Idea for Implementation\n",
        "\n",
        "* Create a \"tape\" data structure that tracks the operations performed in computing a function\n",
        "* Overload primitives to:\n",
        "    - Add themselves to the tape when called\n",
        "    - Compute gradients with respect to their local inputs\n",
        "* _Forward pass_ computes the function, and adds operations to the tape\n",
        "* _Reverse pass_ accumulates the local gradients using the chain rule\n",
        "* This is efficient for graphs with large fan-in, like most loss functions in ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JxunitHmYpf",
        "colab_type": "text"
      },
      "source": [
        "## Autograd\n",
        "\n",
        "* [Autograd](https://github.com/HIPS/autograd) is a Python package for automatic differentiation.\n",
        "* To install Autograd:\n",
        "                pip install autograd\n",
        "* There are a lot of great [examples](https://github.com/HIPS/autograd/tree/master/examples) provided with the source code\n",
        "\n",
        "### What can Autograd do?\n",
        "\n",
        "From the Autograd Github repository:\n",
        "\n",
        "* Autograd can automatically differentiate native Python and Numpy code.\n",
        "* It can handle a large subset of Python's features, including loops, conditional statements (if/else), recursion and closures\n",
        "* It can also compute higher-order derivatives\n",
        "* It uses reverse-mode differentiation (a.k.a. backpropagation) so it can efficiently take gradients of scalar-valued functions with respect to array-valued arguments.\n",
        "\n",
        "\n",
        "## Autograd vs Tensorflow, Theano, etc.\n",
        "\n",
        "Many deep learning packages implement automatic differentiation using small _domain-specific languages_ within Python:\n",
        "    - Theano\n",
        "    - Caffe\n",
        "    - Vanilla Torch (as compared to Autograd for Torch)\n",
        "    - Tensorflow\n",
        "Most of these alternatives require you to _explicitly_ construct a computation graph; Autograd constructs a computation graph _implicitly_, by tracking the sequence of operations that have been performed during the execution of a program.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kDjpkTqmYph",
        "colab_type": "text"
      },
      "source": [
        "## Autograd Basic Usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqGWFWj3mYpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import autograd.numpy as np # Import thinly-wrapped numpy\n",
        "from autograd import grad   # Basicallly the only function you need"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szDksM6wmYpn",
        "colab_type": "code",
        "outputId": "f0f05894-4e66-4679-8db0-c8a2424c2237",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Define a function like normal, using Python and Numpy\n",
        "def tanh(x):\n",
        "    y = np.exp(-x)\n",
        "    return (1.0 - y) / (1.0 + y)\n",
        "\n",
        "# Create a *function* that computes the gradient of tanh\n",
        "grad_tanh = grad(tanh)\n",
        "\n",
        "# Evaluate the gradient at x = 1.0\n",
        "print(grad_tanh(1.0))\n",
        "\n",
        "# Compare to numeric gradient computed using finite differences\n",
        "print((tanh(1.0001) - tanh(0.9999)) / 0.0002)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.39322386648296376\n",
            "0.39322386636453377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Rj5tTqGsHb2",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SDGKdlknJMuK"
      },
      "source": [
        "# Pytorch\n",
        "\n",
        "Autograd doesn't support GPUs, so we cannot use autograd for training big neural networks. Pytorch is a gpu friendly framework on top of autograd.\n",
        "\n",
        "## PyTorch: The Basics\n",
        "\n",
        "PyTorch allows you to dynamically define computational graphs that can be computed efficently on GPUs.\n",
        "\n",
        "Here is an example, where we work with the function\n",
        "\n",
        "$$f(x) = x^2 + 2x + 6$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM9OCyxms9Oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKC3Lzwqs07E",
        "colab_type": "code",
        "outputId": "ef425156-f89a-43ac-aa1d-1671544c6065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def f(x):\n",
        "    return x ** 2 + 2 * x + 6\n",
        "np_x = np.array([4.0])\n",
        "x = torch.from_numpy(np_x).requires_grad_(True)\n",
        "y = f(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([30.], dtype=torch.float64, grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWQJmBlytIOV",
        "colab_type": "code",
        "outputId": "2075ad1e-e13a-4f3b-98b7-4991060cf467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.backward()\n",
        "x.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10.], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCdN3mtXtX-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_x = np.array([5.0])\n",
        "x = torch.from_numpy(np_x).requires_grad_(True)\n",
        "y = f(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TWXc5gmtdrA",
        "colab_type": "code",
        "outputId": "2e058699-1e92-470b-8128-749cb5938c45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.backward()\n",
        "x.grad"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12.], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v60TtmvumYps",
        "colab_type": "text"
      },
      "source": [
        "## Pytorch vs Manual Gradients via Staged Computation\n",
        "\n",
        "In this example, we will see how a complicated computation can be written as a composition of simpler functions, and how this provides a scalable strategy for computing gradients using the chain rule.\n",
        "\n",
        "Say we want to write a function to compute the gradient of the *sigmoid function*:\n",
        "$$\n",
        "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
        "$$\n",
        "We can write $\\sigma(x)$ as a composition of several elementary functions, as $\\sigma(x) = s(c(b(a(x))))$, where:\n",
        "\n",
        "$$\n",
        "a(x) = -x\n",
        "$$\n",
        "\n",
        "$$\n",
        "b(a) = e^a\n",
        "$$\n",
        "\n",
        "$$\n",
        "c(b) = 1 + b\n",
        "$$\n",
        "\n",
        "$$\n",
        "s(c) = \\frac{1}{c}\n",
        "$$\n",
        "\n",
        "Here, we have \"staged\" the computation such that it contains several intermediate variables, each of which are basic expressions for which we can easily compute the local gradients.\n",
        "\n",
        "The computation graph for this expression is shown in the figure below. \n",
        " \n",
        "![Gradient Computation Image](https://drive.google.com/uc?export=view&id=1bvdPv0MI2eM3GeobsHFsFjLrLsibuhJa)\n",
        "\n",
        "The input to this function is $x$, and the output is represented by node $s$. We wish compute the gradient of $s$ with respect to $x$, $\\frac{\\partial s}{\\partial x}$. In order to make use of our intermediate computations, we can use the chain rule as follows:\n",
        "$$\n",
        "\\frac{\\partial s}{\\partial x} = \\frac{\\partial s}{\\partial c} \\frac{\\partial c}{\\partial b} \\frac{\\partial b}{\\partial a} \\frac{\\partial a}{\\partial x}\n",
        "$$\n",
        "\n",
        "<!--\n",
        "Given a vector-to-scalar function, $\\mathbb{R}^D \\to \\mathbb{R}$, composed of a set of primitive functions\n",
        "$\\mathbb{R}^M \\to \\mathbb{R}^N$ (for various $M$, $N$), the gradient of the composition is given by the product of the gradients of the primitive functions, according to the chain rule. But the chain rule doesn’t prescribe the order in which to multiply the gradients. From the perspective of computational complexity, the order makes all the\n",
        "difference.\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5RUMyRsmYpt",
        "colab_type": "code",
        "outputId": "60bb0e8a-e8da-4ea3-dd80-483fa8c50dd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def grad_sigmoid_manual(x):\n",
        "    \"\"\"Implements the gradient of the logistic sigmoid function \n",
        "    $\\sigma(x) = 1 / (1 + e^{-x})$ using staged computation\n",
        "    \"\"\"\n",
        "    # Forward pass, keeping track of intermediate values for use in the \n",
        "    # backward pass\n",
        "    a = -x         # -x in denominator\n",
        "    b = np.exp(a)  # e^{-x} in denominator\n",
        "    c = 1 + b      # 1 + e^{-x} in denominator\n",
        "    s = 1.0 / c    # Final result, 1.0 / (1 + e^{-x})\n",
        "    \n",
        "    # Backward pass\n",
        "    dsdc = (-1.0 / (c**2))\n",
        "    dsdb = dsdc * 1\n",
        "    dsda = dsdb * np.exp(a)\n",
        "    dsdx = dsda * (-1)\n",
        "    \n",
        "    return dsdx\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    y = 1.0 / (1.0 + torch.exp(-x))\n",
        "    return y\n",
        "\n",
        "input_x = 2.0\n",
        "x = torch.tensor(input_x).requires_grad_(True)\n",
        "y = sigmoid(x)\n",
        "y.backward()\n",
        "\n",
        "# Compare the results of manual and automatic gradient functions:\n",
        "print('autograd:', x.grad.item())\n",
        "print('manual:', grad_sigmoid_manual(input_x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "autograd: 0.10499356687068939\n",
            "manual: 0.1049935854035065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTHQYM2ImYq4",
        "colab_type": "text"
      },
      "source": [
        "## Modularity: Implementing Custom Gradients\n",
        "\n",
        "One thing you can do is define custom gradients for your own functions. There are several reasons you might want to do this, including:\n",
        "\n",
        "1. **Speed:** You may know a faster way to compute the gradient for a specific function.\n",
        "2. **Numerical Stability**\n",
        "3. When your code depends on **external library calls**\n",
        "\n",
        "The `@primitive` decorator wraps a function so that its gradient can be specified manually and its invocation can be recorded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIG9NpYimYq6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class MyLogSumExp(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        \"\"\"\n",
        "        In the forward pass we receive a Tensor containing the input and return\n",
        "        a Tensor containing the output. ctx is a context object that can be used\n",
        "        to stash information for backward computation. You can cache arbitrary\n",
        "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
        "        \"\"\"\n",
        "        max_x = torch.max(input)\n",
        "        ans = max_x + torch.log(torch.sum(torch.exp(input - max_x)))\n",
        "        ctx.save_for_backward(input, ans)\n",
        "        return ans\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\"\n",
        "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
        "        with respect to the output, and we need to compute the gradient of the loss\n",
        "        with respect to the input.\n",
        "        \"\"\"\n",
        "        input, ans = ctx.saved_tensors\n",
        "        return torch.ones_like(input)*grad_output * (input - ans).exp()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTzfGIWJmYq9",
        "colab_type": "code",
        "outputId": "c0ff0309-cb3a-42eb-c729-7004342d8dc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "mylogsumexp = MyLogSumExp.apply\n",
        "\n",
        "# Now we can use logsumexp() inside a larger function that we want to differentiate.\n",
        "def example_func(y, myimp):\n",
        "    z = y**2\n",
        "    if myimp is True:\n",
        "      lse = mylogsumexp(z)\n",
        "    else:\n",
        "      lse = torch.logsumexp(z, dim=0)\n",
        "    return lse\n",
        "\n",
        "\n",
        "input_x = torch.randn(10).requires_grad_(True)\n",
        "output = example_func(input_x, myimp=False)\n",
        "output.backward()\n",
        "print('our implementation:', input_x.grad)\n",
        "input_x.grad.zero_()\n",
        "\n",
        "output = example_func(input_x, myimp=False)\n",
        "output.backward()\n",
        "print('torch impelementation:', input_x.grad)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "our implementation: tensor([ 5.9797e+00,  4.7883e-04,  1.6453e-05, -1.7593e-06,  5.0308e-04,\n",
            "        -1.9143e-04, -1.0246e-04, -4.3527e-04,  1.1418e-04, -6.9619e-04])\n",
            "torch impelementation: tensor([ 5.9797e+00,  4.7883e-04,  1.6453e-05, -1.7593e-06,  5.0308e-04,\n",
            "        -1.9143e-04, -1.0246e-04, -4.3527e-04,  1.1418e-04, -6.9619e-04])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-ePOja_mYrA",
        "colab_type": "text"
      },
      "source": [
        "# Examples\n",
        "\n",
        "The next three sections of the notebook show examples of using pytorch in the context of three problems:\n",
        "\n",
        "1. **1-D linear regression**, where we try to fit a model to a function $y = wx + b$\n",
        "2. **Linear regression using a polynomial feature map**, to fit a function of the form $y = w_0 + w_1 x + w_2 x^2 + \\dots + w_M x^M$\n",
        "3. **Nonlinear regression using a neural network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBs8UkXfmYrC",
        "colab_type": "text"
      },
      "source": [
        "## Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLHB3U0BmYrD",
        "colab_type": "text"
      },
      "source": [
        "### Review\n",
        "\n",
        "We are given a set of data points $\\{ (x_1, t_1), (x_2, t_2), \\dots, (x_N, t_N) \\}$, where each point $(x_i, t_i)$ consists of an *input value* $x_i$ and a *target value* $t_i$. \n",
        "\n",
        "The **model** we use is:\n",
        "$$\n",
        "y_i = wx_i + b\n",
        "$$\n",
        "\n",
        "We want each predicted value $y_i$ to be close to the ground truth value $t_i$. In linear regression, we use squared error to quantify the disagreement between $y_i$ and $t_i$. The **loss function** for a single example is:\n",
        "$$\n",
        "\\mathcal{L}(y_i,t_i) = \\frac{1}{2} (y_i - t_i)^2\n",
        "$$\n",
        "\n",
        "The **cost function** is the loss averaged over all the training examples:\n",
        "$$\n",
        "\\mathcal{E}(w,b) = \\frac{1}{N} \\sum_{i=1}^N \\mathcal{L}(y_i, t_i) = \\frac{1}{N} \\sum_{i=1}^N \\frac{1}{2} \\left(wx_i + b - t_i \\right)^2\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dOjH3W31ITDU",
        "colab": {}
      },
      "source": [
        "import numpy as np # Import wrapped NumPy from Autograd\n",
        "import numpy.random as npr # For convenient access to numpy.random\n",
        "\n",
        "import matplotlib.pyplot as plt # For plotting\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-BhEYZOmYrJ",
        "colab_type": "text"
      },
      "source": [
        "We generate a synthetic dataset $\\{ (x_i, t_i) \\}$ by first taking the $x_i$ to be linearly spaced in the range $[0, 10]$ and generating the corresponding value of $t_i$ using the following equation (where $w = 4$ and $b=10$):\n",
        "$$\n",
        "t_i = 4 x_i + 10 + \\epsilon\n",
        "$$\n",
        "\n",
        "Here, $\\epsilon \\sim \\mathcal{N}(0, 2)$ (that is, $\\epsilon$ is drawn from a Gaussian distribution with mean 0 and variance 2). This introduces some random fluctuation in the data, to mimic real data that has an underlying regularity, but for which individual observations are corrupted by random noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOLDubBYmYrK",
        "colab_type": "code",
        "outputId": "5c85ac5d-bb0e-4ec9-f0cb-74c2d707006f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# In our synthetic data, we have w = 4 and b = 10\n",
        "N = 100 # Number of training data points\n",
        "x = np.linspace(0, 10, N)\n",
        "\n",
        "t = 4 * x + 10 + npr.normal(0, 2, x.shape[0])\n",
        "plt.plot(x, t, 'r.')\n",
        "\n",
        "x = torch.from_numpy(x)\n",
        "t = torch.from_numpy(t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4JLUUwa4JPXU/wMtAd9zFTzhBwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWKVaOrimYrO",
        "colab_type": "code",
        "outputId": "1a1e3f1d-5389-45c7-9da2-91472cdf95a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initialize random parameters\n",
        "\n",
        "w = torch.nn.Parameter(torch.randn(1))\n",
        "b = torch.nn.Parameter(torch.randn(1))\n",
        "\n",
        "\n",
        "params = { 'w': w, 'b': b } # One option: aggregate parameters in a dictionary\n",
        "\n",
        "def cost(params):\n",
        "    y = params['w'] * x + params['b']\n",
        "    return (1 / N) * torch.sum(0.5 * (y - t)**2)\n",
        "\n",
        "# Find the gradient of the cost function using pytorch\n",
        "\n",
        "num_epochs = 1000  # Number of epochs of training\n",
        "alpha = 0.01       # Learning rate\n",
        "\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    # Evaluate the gradient of the current parameters stored in params\n",
        "    loss = cost(params)\n",
        "    loss.backward()\n",
        "\n",
        "    print('loss:', loss.item())\n",
        "\n",
        "    # Update parameters w and b\n",
        "    with torch.no_grad():\n",
        "      params['w'].data = params['w'] - alpha * params['w'].grad\n",
        "      params['b'].data = params['b'] - alpha * params['b'].grad\n",
        "      params['w'].grad.zero_()\n",
        "      params['b'].grad.zero_()\n",
        "\n",
        "print(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 644.3502192412097\n",
            "loss: 284.33803130150415\n",
            "loss: 128.69493086313977\n",
            "loss: 61.392618566596674\n",
            "loss: 32.276658349859\n",
            "loss: 19.667251171163944\n",
            "loss: 14.193091680762393\n",
            "loss: 11.803340327616109\n",
            "loss: 10.74696917052546\n",
            "loss: 10.267083920749766\n",
            "loss: 10.036507399837172\n",
            "loss: 9.913810095763878\n",
            "loss: 9.837859292761152\n",
            "loss: 9.78222826131612\n",
            "loss: 9.735494160408527\n",
            "loss: 9.692718290437435\n",
            "loss: 9.651765206940448\n",
            "loss: 9.611711641154466\n",
            "loss: 9.572157609661964\n",
            "loss: 9.53292974746821\n",
            "loss: 9.493952529339717\n",
            "loss: 9.455192826723676\n",
            "loss: 9.416635950895934\n",
            "loss: 9.378274648154207\n",
            "loss: 9.340105638958265\n",
            "loss: 9.302126644381536\n",
            "loss: 9.264336209654502\n",
            "loss: 9.226733248790838\n",
            "loss: 9.189316842641079\n",
            "loss: 9.152086124481851\n",
            "loss: 9.11503984387626\n",
            "loss: 9.07817717315171\n",
            "loss: 9.041497381638102\n",
            "loss: 9.004999382711368\n",
            "loss: 8.96868227508728\n",
            "loss: 8.932545430545098\n",
            "loss: 8.896587596710395\n",
            "loss: 8.86080801888969\n",
            "loss: 8.825205944985456\n",
            "loss: 8.789780359073154\n",
            "loss: 8.75453038324372\n",
            "loss: 8.719455275958842\n",
            "loss: 8.68455403376608\n",
            "loss: 8.649825570935516\n",
            "loss: 8.61526959544456\n",
            "loss: 8.580884678185358\n",
            "loss: 8.54667031419501\n",
            "loss: 8.512625737637471\n",
            "loss: 8.478749882673007\n",
            "loss: 8.445041689340915\n",
            "loss: 8.41150109510514\n",
            "loss: 8.378126485096393\n",
            "loss: 8.344917242490125\n",
            "loss: 8.311872751991336\n",
            "loss: 8.278991973111783\n",
            "loss: 8.24627429679235\n",
            "loss: 8.213718690879857\n",
            "loss: 8.18132455250299\n",
            "loss: 8.149091280287909\n",
            "loss: 8.117017852904358\n",
            "loss: 8.085103254703577\n",
            "loss: 8.053346895057171\n",
            "loss: 8.021748184803545\n",
            "loss: 7.990305993479243\n",
            "loss: 7.959019447816299\n",
            "loss: 7.927888384455002\n",
            "loss: 7.896911394793938\n",
            "loss: 7.866088195133265\n",
            "loss: 7.835417923931732\n",
            "loss: 7.804899476682112\n",
            "loss: 7.774532412340329\n",
            "loss: 7.7443156349328754\n",
            "loss: 7.714249116707888\n",
            "loss: 7.684331360086118\n",
            "loss: 7.6545618123594785\n",
            "loss: 7.624940043987058\n",
            "loss: 7.595464978576722\n",
            "loss: 7.566136191732804\n",
            "loss: 7.53695301742474\n",
            "loss: 7.507914511754702\n",
            "loss: 7.479019736162126\n",
            "loss: 7.450268156428189\n",
            "loss: 7.4216593593563225\n",
            "loss: 7.393192296033374\n",
            "loss: 7.364866320063091\n",
            "loss: 7.336680748897109\n",
            "loss: 7.308634941407901\n",
            "loss: 7.280728258942177\n",
            "loss: 7.252960026956488\n",
            "loss: 7.225329103204695\n",
            "loss: 7.197835485386886\n",
            "loss: 7.170477882662523\n",
            "loss: 7.143256178011817\n",
            "loss: 7.1161694771991995\n",
            "loss: 7.0892168911017315\n",
            "loss: 7.062397805178006\n",
            "loss: 7.035711838481822\n",
            "loss: 7.009158111360741\n",
            "loss: 6.982736016697953\n",
            "loss: 6.956445179235555\n",
            "loss: 6.930284614243797\n",
            "loss: 6.904253571486739\n",
            "loss: 6.878351834262517\n",
            "loss: 6.852578278253425\n",
            "loss: 6.826932690654153\n",
            "loss: 6.801414331459231\n",
            "loss: 6.776022238935422\n",
            "loss: 6.750756056406863\n",
            "loss: 6.725615202829658\n",
            "loss: 6.7005988391585225\n",
            "loss: 6.6757065024928615\n",
            "loss: 6.6509377310824735\n",
            "loss: 6.626291805979999\n",
            "loss: 6.601768158831808\n",
            "loss: 6.577365966459297\n",
            "loss: 6.553084777169115\n",
            "loss: 6.528923774599823\n",
            "loss: 6.504882876906895\n",
            "loss: 6.480960907802235\n",
            "loss: 6.457157788565022\n",
            "loss: 6.433472713620463\n",
            "loss: 6.409904882097044\n",
            "loss: 6.386453858180983\n",
            "loss: 6.363119207139818\n",
            "loss: 6.339900028895933\n",
            "loss: 6.316796001920571\n",
            "loss: 6.293806697376986\n",
            "loss: 6.270931331570341\n",
            "loss: 6.248169480451684\n",
            "loss: 6.225520260362741\n",
            "loss: 6.20298335902919\n",
            "loss: 6.18055835818712\n",
            "loss: 6.158244383369948\n",
            "loss: 6.136041127250068\n",
            "loss: 6.113948072099712\n",
            "loss: 6.0919645631996735\n",
            "loss: 6.070089739942063\n",
            "loss: 6.048323650424484\n",
            "loss: 6.026665438305301\n",
            "loss: 6.005114356621566\n",
            "loss: 5.983670111078503\n",
            "loss: 5.962332200593107\n",
            "loss: 5.941100332329188\n",
            "loss: 5.919973665641578\n",
            "loss: 5.898951809097528\n",
            "loss: 5.878034031882579\n",
            "loss: 5.857220049141709\n",
            "loss: 5.8365093722800285\n",
            "loss: 5.815901278438799\n",
            "loss: 5.795395386063434\n",
            "loss: 5.774990978394433\n",
            "loss: 5.7546876782758\n",
            "loss: 5.734485109486697\n",
            "loss: 5.714382896741442\n",
            "loss: 5.694380332861254\n",
            "loss: 5.674476714906361\n",
            "loss: 5.65467200651206\n",
            "loss: 5.63496550822387\n",
            "loss: 5.61535652479\n",
            "loss: 5.595844693859638\n",
            "loss: 5.576429555367769\n",
            "loss: 5.557110847859755\n",
            "loss: 5.537887885398703\n",
            "loss: 5.518760311653041\n",
            "loss: 5.499727348885097\n",
            "loss: 5.480788743070143\n",
            "loss: 5.4619441429373286\n",
            "loss: 5.443193101184672\n",
            "loss: 5.4245350442283895\n",
            "loss: 5.40596930516116\n",
            "loss: 5.3874954447903445\n",
            "loss: 5.369113217622448\n",
            "loss: 5.350822186637581\n",
            "loss: 5.33262210756333\n",
            "loss: 5.314511912170324\n",
            "loss: 5.296491898932311\n",
            "loss: 5.278561195155809\n",
            "loss: 5.260719373928971\n",
            "loss: 5.242965571574026\n",
            "loss: 5.22529999352992\n",
            "loss: 5.2077223105785775\n",
            "loss: 5.190231665460901\n",
            "loss: 5.172827641182462\n",
            "loss: 5.155509915606626\n",
            "loss: 5.138278167397691\n",
            "loss: 5.1211314597194075\n",
            "loss: 5.104070092197341\n",
            "loss: 5.08709322484445\n",
            "loss: 5.070200451414728\n",
            "loss: 5.053391459104347\n",
            "loss: 5.03666584435944\n",
            "loss: 5.020022872030374\n",
            "loss: 5.00346275008575\n",
            "loss: 4.9869845646490765\n",
            "loss: 4.970587920666291\n",
            "loss: 4.954272695928861\n",
            "loss: 4.938038406495489\n",
            "loss: 4.92188484081863\n",
            "loss: 4.905811100772082\n",
            "loss: 4.889816890136873\n",
            "loss: 4.873902507178663\n",
            "loss: 4.858067060445686\n",
            "loss: 4.842309576286018\n",
            "loss: 4.826630444436567\n",
            "loss: 4.8110287844603405\n",
            "loss: 4.795504807153367\n",
            "loss: 4.78005772505846\n",
            "loss: 4.764687252155943\n",
            "loss: 4.749393015619088\n",
            "loss: 4.734174818801849\n",
            "loss: 4.719031711553426\n",
            "loss: 4.703963502521135\n",
            "loss: 4.68897048983304\n",
            "loss: 4.674051730394261\n",
            "loss: 4.6592069480568\n",
            "loss: 4.644435381340779\n",
            "loss: 4.629737243900592\n",
            "loss: 4.615111778027723\n",
            "loss: 4.600559196316813\n",
            "loss: 4.5860786596622285\n",
            "loss: 4.571669985175163\n",
            "loss: 4.557332820317267\n",
            "loss: 4.543066336422597\n",
            "loss: 4.528870916919461\n",
            "loss: 4.514745652513604\n",
            "loss: 4.500690282848858\n",
            "loss: 4.486705104813369\n",
            "loss: 4.472788744758464\n",
            "loss: 4.458941502245934\n",
            "loss: 4.4451631194970345\n",
            "loss: 4.4314528711397205\n",
            "loss: 4.417810971240653\n",
            "loss: 4.404236615578196\n",
            "loss: 4.3907295530209165\n",
            "loss: 4.377289451013688\n",
            "loss: 4.363915679677501\n",
            "loss: 4.350608454493444\n",
            "loss: 4.337366903783711\n",
            "loss: 4.324191405646131\n",
            "loss: 4.311081254786202\n",
            "loss: 4.298036046166916\n",
            "loss: 4.28505508260882\n",
            "loss: 4.2721386614362915\n",
            "loss: 4.259286541670481\n",
            "loss: 4.24649787065458\n",
            "loss: 4.233772493004713\n",
            "loss: 4.221110173491217\n",
            "loss: 4.208510677469443\n",
            "loss: 4.195973691642889\n",
            "loss: 4.183499062161056\n",
            "loss: 4.171086031751275\n",
            "loss: 4.158734816433357\n",
            "loss: 4.146444741726687\n",
            "loss: 4.134215580358145\n",
            "loss: 4.1220470275566905\n",
            "loss: 4.109938935625966\n",
            "loss: 4.097891001306012\n",
            "loss: 4.085902562307039\n",
            "loss: 4.073973320716633\n",
            "loss: 4.062103646912073\n",
            "loss: 4.050292729127841\n",
            "loss: 4.038540348958567\n",
            "loss: 4.026846365067607\n",
            "loss: 4.015209975519992\n",
            "loss: 4.003631549908737\n",
            "loss: 3.9921102902734944\n",
            "loss: 3.980646488605086\n",
            "loss: 3.96923950263185\n",
            "loss: 3.957889045508198\n",
            "loss: 3.9465949068702106\n",
            "loss: 3.9353563779289975\n",
            "loss: 3.9241737507949\n",
            "loss: 3.9130463948364986\n",
            "loss: 3.9019745256950813\n",
            "loss: 3.890957441590175\n",
            "loss: 3.879994938957688\n",
            "loss: 3.8690868147383823\n",
            "loss: 3.858232866377851\n",
            "loss: 3.847432476238748\n",
            "loss: 3.836685787063396\n",
            "loss: 3.8259922580031516\n",
            "loss: 3.8153520310905766\n",
            "loss: 3.804764568162978\n",
            "loss: 3.794229527465808\n",
            "loss: 3.7837468589986805\n",
            "loss: 3.773315742008861\n",
            "loss: 3.762936537731445\n",
            "loss: 3.7526085738520387\n",
            "loss: 3.7423321375375456\n",
            "loss: 3.732106559809068\n",
            "loss: 3.7219316516573544\n",
            "loss: 3.71180715333447\n",
            "loss: 3.70173294832836\n",
            "loss: 3.691708377800589\n",
            "loss: 3.681733728185217\n",
            "loss: 3.6718083439115405\n",
            "loss: 3.6619324396660944\n",
            "loss: 3.652105433806492\n",
            "loss: 3.6423271445258854\n",
            "loss: 3.632597320661706\n",
            "loss: 3.6229158514619475\n",
            "loss: 3.6132820945174053\n",
            "loss: 3.6036962647820925\n",
            "loss: 3.594157792664919\n",
            "loss: 3.5846668920517812\n",
            "loss: 3.5752229961791606\n",
            "loss: 3.5658258616273706\n",
            "loss: 3.5564753829628013\n",
            "loss: 3.5471713179743105\n",
            "loss: 3.537913108889826\n",
            "loss: 3.52870096981437\n",
            "loss: 3.519534345738679\n",
            "loss: 3.5104134497064314\n",
            "loss: 3.501337662043673\n",
            "loss: 3.492306882477866\n",
            "loss: 3.483320876317166\n",
            "loss: 3.474379543784958\n",
            "loss: 3.46548220740861\n",
            "loss: 3.45662914747756\n",
            "loss: 3.4478198232114265\n",
            "loss: 3.4390544467589614\n",
            "loss: 3.430332413930263\n",
            "loss: 3.4216535637806897\n",
            "loss: 3.4130177357650386\n",
            "loss: 3.4044248353358912\n",
            "loss: 3.3958746368170116\n",
            "loss: 3.387366546729452\n",
            "loss: 3.3789008424046996\n",
            "loss: 3.3704769333056794\n",
            "loss: 3.36209466448604\n",
            "loss: 3.3537543758441064\n",
            "loss: 3.345455416281268\n",
            "loss: 3.3371975676940937\n",
            "loss: 3.3289803788135117\n",
            "loss: 3.320804060903704\n",
            "loss: 3.312668397477299\n",
            "loss: 3.304572940618123\n",
            "loss: 3.2965174776010975\n",
            "loss: 3.2885022180690413\n",
            "loss: 3.280526654234188\n",
            "loss: 3.272590701508702\n",
            "loss: 3.2646940863888716\n",
            "loss: 3.2568363079742233\n",
            "loss: 3.2490176390128336\n",
            "loss: 3.2412379333350283\n",
            "loss: 3.2334966310306696\n",
            "loss: 3.225793589748024\n",
            "loss: 3.218129017579563\n",
            "loss: 3.2105024210415216\n",
            "loss: 3.202913658839619\n",
            "loss: 3.1953625900319396\n",
            "loss: 3.18784860470464\n",
            "loss: 3.180372034270106\n",
            "loss: 3.1729323328746517\n",
            "loss: 3.165529708054939\n",
            "loss: 3.1581636778547386\n",
            "loss: 3.1508341064279075\n",
            "loss: 3.1435407978314402\n",
            "loss: 3.136283677625646\n",
            "loss: 3.1290626109727113\n",
            "loss: 3.1218774033841674\n",
            "loss: 3.114727980977899\n",
            "loss: 3.107613753256051\n",
            "loss: 3.100535045656427\n",
            "loss: 3.093491270609238\n",
            "loss: 3.0864823579110805\n",
            "loss: 3.0795081188936506\n",
            "loss: 3.0725684836984954\n",
            "loss: 3.0656632645919797\n",
            "loss: 3.0587923920631184\n",
            "loss: 3.0519556793104257\n",
            "loss: 3.045152668976791\n",
            "loss: 3.038383565313469\n",
            "loss: 3.0316478551491475\n",
            "loss: 3.0249458000954084\n",
            "loss: 3.0182769473194293\n",
            "loss: 3.011641115656136\n",
            "loss: 3.005038239826782\n",
            "loss: 2.9984681395672568\n",
            "loss: 2.9919303121509184\n",
            "loss: 2.9854250752343434\n",
            "loss: 2.97895224988842\n",
            "loss: 2.9725113371207916\n",
            "loss: 2.9661022187858515\n",
            "loss: 2.9597251528849244\n",
            "loss: 2.9533796441346976\n",
            "loss: 2.9470656315006467\n",
            "loss: 2.940782941495375\n",
            "loss: 2.9345310852963014\n",
            "loss: 2.928310320495689\n",
            "loss: 2.9221205309843588\n",
            "loss: 2.9159612315696433\n",
            "loss: 2.9098326779321737\n",
            "loss: 2.903734442543993\n",
            "loss: 2.8976663576557975\n",
            "loss: 2.8916282563345685\n",
            "loss: 2.8856201370381886\n",
            "loss: 2.8796417785332533\n",
            "loss: 2.8736931247047175\n",
            "loss: 2.8677741191636534\n",
            "loss: 2.8618845423300914\n",
            "loss: 2.8560240323730524\n",
            "loss: 2.8501923734888983\n",
            "loss: 2.844389871455682\n",
            "loss: 2.8386160591802203\n",
            "loss: 2.832870830141161\n",
            "loss: 2.8271540780811764\n",
            "loss: 2.8214656970069654\n",
            "loss: 2.8158055811892417\n",
            "loss: 2.810173572049062\n",
            "loss: 2.804569265420249\n",
            "loss: 2.798992910449494\n",
            "loss: 2.793444051861227\n",
            "loss: 2.7879229375691734\n",
            "loss: 2.7824290620997933\n",
            "loss: 2.776962376868237\n",
            "loss: 2.7715227808221643\n",
            "loss: 2.7661101210935928\n",
            "loss: 2.760724349456436\n",
            "loss: 2.755365365608117\n",
            "loss: 2.750033069498486\n",
            "loss: 2.744726966938487\n",
            "loss: 2.739447354724598\n",
            "loss: 2.7341937411169055\n",
            "loss: 2.7289664214403646\n",
            "loss: 2.723764957434061\n",
            "loss: 2.718589202150913\n",
            "loss: 2.7134391109583653\n",
            "loss: 2.708314537637018\n",
            "loss: 2.703215437774247\n",
            "loss: 2.698141716284764\n",
            "loss: 2.693092893614748\n",
            "loss: 2.6880692116115803\n",
            "loss: 2.683070293537737\n",
            "loss: 2.6780963796684536\n",
            "loss: 2.673146995191107\n",
            "loss: 2.668222049267655\n",
            "loss: 2.6633218302993624\n",
            "loss: 2.658445867000856\n",
            "loss: 2.653594118507425\n",
            "loss: 2.648766118317896\n",
            "loss: 2.643962105371031\n",
            "loss: 2.639182039101676\n",
            "loss: 2.6344257810690657\n",
            "loss: 2.629692967121887\n",
            "loss: 2.6249834619221213\n",
            "loss: 2.6202975014556706\n",
            "loss: 2.61563467595118\n",
            "loss: 2.6109949478459025\n",
            "loss: 2.6063781831364983\n",
            "loss: 2.6017842964774527\n",
            "loss: 2.5972132027364445\n",
            "loss: 2.592664864719597\n",
            "loss: 2.5881391497516186\n",
            "loss: 2.583635657490213\n",
            "loss: 2.579154621061986\n",
            "loss: 2.574695689363446\n",
            "loss: 2.570259046874931\n",
            "loss: 2.5658442972129563\n",
            "loss: 2.561451359254951\n",
            "loss: 2.5570804632477495\n",
            "loss: 2.5527312157559687\n",
            "loss: 2.5484035362638697\n",
            "loss: 2.544097035596424\n",
            "loss: 2.5398119903509486\n",
            "loss: 2.5355482740532236\n",
            "loss: 2.5313058069805936\n",
            "loss: 2.5270841578232455\n",
            "loss: 2.5228836466616533\n",
            "loss: 2.5187038439836966\n",
            "loss: 2.5145446731275136\n",
            "loss: 2.510406360398058\n",
            "loss: 2.506288479811875\n",
            "loss: 2.5021910462235137\n",
            "loss: 2.4981139382025526\n",
            "loss: 2.494057034957385\n",
            "loss: 2.490020052189227\n",
            "loss: 2.4860031250443786\n",
            "loss: 2.4820062234467226\n",
            "loss: 2.478028975610095\n",
            "loss: 2.4740716050502805\n",
            "loss: 2.470133741824263\n",
            "loss: 2.466215313725794\n",
            "loss: 2.4623165426110316\n",
            "loss: 2.458437061286562\n",
            "loss: 2.454576754117442\n",
            "loss: 2.45073559379845\n",
            "loss: 2.446913509015004\n",
            "loss: 2.44311042863093\n",
            "loss: 2.439325992154106\n",
            "loss: 2.4355603763516447\n",
            "loss: 2.4318135542541133\n",
            "loss: 2.4280851680449795\n",
            "loss: 2.4243754362814847\n",
            "loss: 2.420683959926517\n",
            "loss: 2.4170107144136668\n",
            "loss: 2.4133559166749903\n",
            "loss: 2.4097191706375036\n",
            "loss: 2.4061004519197158\n",
            "loss: 2.4024996934170857\n",
            "loss: 2.398916785833686\n",
            "loss: 2.3953517049681863\n",
            "loss: 2.391804103886084\n",
            "loss: 2.3882741558277503\n",
            "loss: 2.384761836770662\n",
            "loss: 2.3812667605215645\n",
            "loss: 2.3777891828100945\n",
            "loss: 2.374328760985718\n",
            "loss: 2.3708853899707014\n",
            "loss: 2.3674590481000513\n",
            "loss: 2.364049905623136\n",
            "loss: 2.3606576648064914\n",
            "loss: 2.357282221609372\n",
            "loss: 2.3539235545860024\n",
            "loss: 2.3505812881183092\n",
            "loss: 2.347255674312682\n",
            "loss: 2.3439466101535062\n",
            "loss: 2.3406540337982675\n",
            "loss: 2.337377654662454\n",
            "loss: 2.3341176816493645\n",
            "loss: 2.3308737447021968\n",
            "loss: 2.327645784588314\n",
            "loss: 2.3244340490662965\n",
            "loss: 2.3212381708260774\n",
            "loss: 2.318058091077774\n",
            "loss: 2.3148937909828224\n",
            "loss: 2.3117451720357733\n",
            "loss: 2.3086122154910114\n",
            "loss: 2.3054948233325323\n",
            "loss: 2.302392675357557\n",
            "loss: 2.299306016404202\n",
            "loss: 2.2962347491803254\n",
            "loss: 2.2931785558613096\n",
            "loss: 2.29013764044174\n",
            "loss: 2.2871117256036344\n",
            "loss: 2.2841007169485215\n",
            "loss: 2.281104816953557\n",
            "loss: 2.2781237117207342\n",
            "loss: 2.275157384930875\n",
            "loss: 2.272205743120558\n",
            "loss: 2.269268731697311\n",
            "loss: 2.266346296205098\n",
            "loss: 2.2634383823243334\n",
            "loss: 2.260544973935749\n",
            "loss: 2.2576657261877635\n",
            "loss: 2.254800838965643\n",
            "loss: 2.251950007192065\n",
            "loss: 2.249113429760757\n",
            "loss: 2.2462908031071493\n",
            "loss: 2.2434823626431317\n",
            "loss: 2.240687731207039\n",
            "loss: 2.2379069324523795\n",
            "loss: 2.2351398777396545\n",
            "loss: 2.232386763018218\n",
            "loss: 2.22964728921788\n",
            "loss: 2.226921405585429\n",
            "loss: 2.224208816368325\n",
            "loss: 2.2215097174079905\n",
            "loss: 2.2188240583250725\n",
            "loss: 2.2161517888664246\n",
            "loss: 2.2134926162040607\n",
            "loss: 2.210846734242709\n",
            "loss: 2.2082138516052905\n",
            "loss: 2.205594161235008\n",
            "loss: 2.2029873731997784\n",
            "loss: 2.200393439783376\n",
            "loss: 2.197812552495467\n",
            "loss: 2.1952443876897436\n",
            "loss: 2.192688969830286\n",
            "loss: 2.190146180029728\n",
            "loss: 2.1876160426240343\n",
            "loss: 2.1850984393196846\n",
            "loss: 2.18259335891137\n",
            "loss: 2.180100519635794\n",
            "loss: 2.177620110987555\n",
            "loss: 2.1751520864211242\n",
            "loss: 2.172696166266918\n",
            "loss: 2.1702525386139655\n",
            "loss: 2.1678208902826976\n",
            "loss: 2.165401443498085\n",
            "loss: 2.162993921355702\n",
            "loss: 2.16059827972279\n",
            "loss: 2.1582147043653865\n",
            "loss: 2.1558428859741063\n",
            "loss: 2.1534828153811727\n",
            "loss: 2.1511344488904505\n",
            "loss: 2.1487977429156486\n",
            "loss: 2.146472653980312\n",
            "loss: 2.1441591046757638\n",
            "loss: 2.1418568601223353\n",
            "loss: 2.1395661041151\n",
            "loss: 2.137286759817172\n",
            "loss: 2.1350185940950293\n",
            "loss: 2.132761789377736\n",
            "loss: 2.1305160463632036\n",
            "loss: 2.1282815802795265\n",
            "loss: 2.1260581266780854\n",
            "loss: 2.123845611518209\n",
            "loss: 2.121644248427906\n",
            "loss: 2.1194537749233455\n",
            "loss: 2.117274117516166\n",
            "loss: 2.1151052690569903\n",
            "loss: 2.11294718929537\n",
            "loss: 2.110799805286717\n",
            "loss: 2.108663109937103\n",
            "loss: 2.1065368136396048\n",
            "loss: 2.104421127438345\n",
            "loss: 2.1023159791074555\n",
            "loss: 2.100221361622939\n",
            "loss: 2.0981370205522056\n",
            "loss: 2.096063100154235\n",
            "loss: 2.0939993796485306\n",
            "loss: 2.091945789295401\n",
            "loss: 2.089902504509567\n",
            "loss: 2.0878693061503553\n",
            "loss: 2.085846156828344\n",
            "loss: 2.083832987494658\n",
            "loss: 2.081829971828977\n",
            "loss: 2.079836892857114\n",
            "loss: 2.077853713561464\n",
            "loss: 2.075880365580311\n",
            "loss: 2.073916603751281\n",
            "loss: 2.071962632448263\n",
            "loss: 2.0700183838136654\n",
            "loss: 2.0680838526463887\n",
            "loss: 2.06615876492634\n",
            "loss: 2.06424329203331\n",
            "loss: 2.0623374288050242\n",
            "loss: 2.0604409032578785\n",
            "loss: 2.0585537117843917\n",
            "loss: 2.0566759931736165\n",
            "loss: 2.0548075082796062\n",
            "loss: 2.0529482535231436\n",
            "loss: 2.051098366660328\n",
            "loss: 2.0492576103230773\n",
            "loss: 2.0474259809604636\n",
            "loss: 2.045603414375377\n",
            "loss: 2.043789876894419\n",
            "loss: 2.0419853349298047\n",
            "loss: 2.0401897849618136\n",
            "loss: 2.0384031634320716\n",
            "loss: 2.036625268388362\n",
            "loss: 2.0348562360265845\n",
            "loss: 2.0330960331693086\n",
            "loss: 2.0313444297480583\n",
            "loss: 2.0296015907098717\n",
            "loss: 2.0278673165988077\n",
            "loss: 2.0261417419240617\n",
            "loss: 2.0244246388919613\n",
            "loss: 2.0227161708180694\n",
            "loss: 2.021016111041054\n",
            "loss: 2.0193244575925235\n",
            "loss: 2.01764115022546\n",
            "loss: 2.015966158019002\n",
            "loss: 2.0142994501290343\n",
            "loss: 2.0126409957881926\n",
            "loss: 2.0109907930512794\n",
            "loss: 2.0093487824144542\n",
            "loss: 2.007714933337532\n",
            "loss: 2.0060892153570773\n",
            "loss: 2.0044715980864036\n",
            "loss: 2.0028620512155735\n",
            "loss: 2.001260356151516\n",
            "loss: 1.9996666720314964\n",
            "loss: 1.9980808095259843\n",
            "loss: 1.9965028705469243\n",
            "loss: 1.9949326949567956\n",
            "loss: 1.9933704121365603\n",
            "loss: 1.9918158067265797\n",
            "loss: 1.990268850397539\n",
            "loss: 1.988729699540336\n",
            "loss: 1.9871981403961894\n",
            "loss: 1.9856741448469293\n",
            "loss: 1.9841576848436393\n",
            "loss: 1.9826487324066433\n",
            "loss: 1.9811472596255126\n",
            "loss: 1.9796532386590648\n",
            "loss: 1.9781666144422025\n",
            "loss: 1.976687413926087\n",
            "loss: 1.9752155821164648\n",
            "loss: 1.9737510914491339\n",
            "loss: 1.9722937347567502\n",
            "loss: 1.9708436651779795\n",
            "loss: 1.96940085535295\n",
            "loss: 1.967965072832884\n",
            "loss: 1.9665365233255194\n",
            "loss: 1.9651149486507737\n",
            "loss: 1.963700376478165\n",
            "loss: 1.9622929043773853\n",
            "loss: 1.9608923559423477\n",
            "loss: 1.9594987055976743\n",
            "loss: 1.958112103094709\n",
            "loss: 1.956732346850515\n",
            "loss: 1.9553594114817625\n",
            "loss: 1.9539932716682311\n",
            "loss: 1.952633902152804\n",
            "loss: 1.9512812517122908\n",
            "loss: 1.9499353213712434\n",
            "loss: 1.94859608605811\n",
            "loss: 1.9472635207644466\n",
            "loss: 1.9459376005449145\n",
            "loss: 1.9446181295555776\n",
            "loss: 1.9433052547887104\n",
            "loss: 1.9419989259029222\n",
            "loss: 1.940698974215332\n",
            "loss: 1.939405545623665\n",
            "loss: 1.9381186155520087\n",
            "loss: 1.9368379657278687\n",
            "loss: 1.9355635984076878\n",
            "loss: 1.9342954904494043\n",
            "loss: 1.9330339531286482\n",
            "loss: 1.9317786023218182\n",
            "loss: 1.930529440262999\n",
            "loss: 1.929286444040379\n",
            "loss: 1.9280495908004778\n",
            "loss: 1.9268188329219573\n",
            "loss: 1.9255941726111017\n",
            "loss: 1.92437558718226\n",
            "loss: 1.9231630540081142\n",
            "loss: 1.9219565259358278\n",
            "loss: 1.9207560051516308\n",
            "loss: 1.9195614691960337\n",
            "loss: 1.91837287126546\n",
            "loss: 1.9171902135334447\n",
            "loss: 1.9160134737083232\n",
            "loss: 1.9148422832104763\n",
            "loss: 1.9136769679249337\n",
            "loss: 1.9125174816250115\n",
            "loss: 1.9113638264558543\n",
            "loss: 1.91021566145788\n",
            "loss: 1.9090732851974\n",
            "loss: 1.907936651903449\n",
            "loss: 1.9068057637011708\n",
            "loss: 1.9056802592642839\n",
            "loss: 1.9045604580649802\n",
            "loss: 1.9034463147868552\n",
            "loss: 1.9023375180961204\n",
            "loss: 1.9012343614084528\n",
            "loss: 1.9001364878611338\n",
            "loss: 1.8990442129794656\n",
            "loss: 1.8979571816690253\n",
            "loss: 1.8968757078905774\n",
            "loss: 1.8957994383109418\n",
            "loss: 1.894728685333397\n",
            "loss: 1.893663120476422\n",
            "loss: 1.8926030083393284\n",
            "loss: 1.8915480452283122\n",
            "loss: 1.8904981894414545\n",
            "loss: 1.889453726653505\n",
            "loss: 1.888414355426427\n",
            "loss: 1.887380057125983\n",
            "loss: 1.8863510924346116\n",
            "loss: 1.8853271621530032\n",
            "loss: 1.8843082251973207\n",
            "loss: 1.883294263287162\n",
            "loss: 1.8822852806639834\n",
            "loss: 1.8812815347893703\n",
            "loss: 1.8802827301560587\n",
            "loss: 1.8792888261910066\n",
            "loss: 1.8782998270905278\n",
            "loss: 1.8773156924832362\n",
            "loss: 1.8763364265439024\n",
            "loss: 1.8753619890993776\n",
            "loss: 1.8743923843063075\n",
            "loss: 1.8734275721863645\n",
            "loss: 1.872467534948288\n",
            "loss: 1.8715122767228476\n",
            "loss: 1.870561757823885\n",
            "loss: 1.869615960594534\n",
            "loss: 1.8686748891359435\n",
            "loss: 1.8677385040578671\n",
            "loss: 1.8668067878378338\n",
            "loss: 1.8658797445436253\n",
            "loss: 1.8649573350846553\n",
            "loss: 1.8640392783103275\n",
            "loss: 1.8631258219403026\n",
            "loss: 1.862216948664958\n",
            "loss: 1.8613126624987988\n",
            "loss: 1.8604129248356782\n",
            "loss: 1.859517436824846\n",
            "loss: 1.8586264855262231\n",
            "loss: 1.8577400326206803\n",
            "loss: 1.8568577814759684\n",
            "loss: 1.8559800170202387\n",
            "loss: 1.8551067012183036\n",
            "loss: 1.8542375396414066\n",
            "loss: 1.8533728151040172\n",
            "loss: 1.852512213723746\n",
            "loss: 1.8516559962017523\n",
            "loss: 1.850803871021726\n",
            "loss: 1.8499560975942622\n",
            "loss: 1.849112406403233\n",
            "loss: 1.8482730349144223\n",
            "loss: 1.8474376944944184\n",
            "loss: 1.8466066419888314\n",
            "loss: 1.8457796105446531\n",
            "loss: 1.844956835283148\n",
            "loss: 1.8441380304265107\n",
            "loss: 1.843323181598351\n",
            "loss: 1.842512562619048\n",
            "loss: 1.8417058695856716\n",
            "loss: 1.8409030882275779\n",
            "loss: 1.840104470333175\n",
            "loss: 1.8393097343554252\n",
            "loss: 1.8385188860284427\n",
            "loss: 1.8377321552747494\n",
            "loss: 1.8369492626375716\n",
            "loss: 1.836170194059802\n",
            "loss: 1.835394935518442\n",
            "loss: 1.8346234730246032\n",
            "loss: 1.8338558122259607\n",
            "loss: 1.833092179642042\n",
            "loss: 1.8323322999513472\n",
            "loss: 1.831576159304846\n",
            "loss: 1.8308237438876156\n",
            "loss: 1.8300750399188457\n",
            "loss: 1.8293300336518357\n",
            "loss: 1.8285887306379838\n",
            "loss: 1.82785109783811\n",
            "loss: 1.8271171216058024\n",
            "loss: 1.8263867883287588\n",
            "loss: 1.8256600844287885\n",
            "loss: 1.8249369963618114\n",
            "loss: 1.824217510617858\n",
            "loss: 1.8235016137210687\n",
            "loss: 1.8227892922296953\n",
            "loss: 1.8220805327361012\n",
            "loss: 1.8213750718648434\n",
            "loss: 1.8206731475171523\n",
            "loss: 1.8199747650811406\n",
            "loss: 1.819279873831955\n",
            "loss: 1.8185884978806075\n",
            "loss: 1.817900358404479\n",
            "loss: 1.8172156718469992\n",
            "loss: 1.8165344621445099\n",
            "loss: 1.8158566976204238\n",
            "loss: 1.8151821023422003\n",
            "loss: 1.8145109457578832\n",
            "loss: 1.813843196425234\n",
            "loss: 1.813178580460946\n",
            "loss: 1.812517365311698\n",
            "loss: 1.8118595197689125\n",
            "loss: 1.8112047719841864\n",
            "loss: 1.8105533874178554\n",
            "loss: 1.8099050954360787\n",
            "loss: 1.8092601061209344\n",
            "loss: 1.808618186310129\n",
            "loss: 1.8079795808140966\n",
            "loss: 1.8073440038354796\n",
            "loss: 1.806711699107612\n",
            "loss: 1.8060824356326353\n",
            "loss: 1.8054564025511195\n",
            "loss: 1.8048333701457409\n",
            "loss: 1.804213561987393\n",
            "loss: 1.8035967317906167\n",
            "loss: 1.8029831020194578\n",
            "loss: 1.802372427609922\n",
            "loss: 1.8017646978829944\n",
            "loss: 1.8011601336501843\n",
            "loss: 1.8005584916683182\n",
            "loss: 1.7999597613388876\n",
            "loss: 1.799364144555042\n",
            "loss: 1.798771417244164\n",
            "loss: 1.7981815688834717\n",
            "loss: 1.797594588976111\n",
            "loss: 1.797010694524883\n",
            "loss: 1.7964296464805491\n",
            "loss: 1.795851434426761\n",
            "loss: 1.7952760479730896\n",
            "loss: 1.7947034598188276\n",
            "loss: 1.7941339013041286\n",
            "loss: 1.7935671363322216\n",
            "loss: 1.7930031546143337\n",
            "loss: 1.7924419458876155\n",
            "loss: 1.791883499915146\n",
            "loss: 1.7913278064859242\n",
            "loss: 1.7907748387691889\n",
            "loss: 1.7902246033271885\n",
            "loss: 1.7896770900219243\n",
            "loss: 1.7891322887413217\n",
            "loss: 1.7885901729182525\n",
            "loss: 1.7880507490516737\n",
            "loss: 1.7875140071025097\n",
            "loss: 1.786979937057611\n",
            "loss: 1.7864485289297498\n",
            "loss: 1.785919756482891\n",
            "loss: 1.78539362613391\n",
            "loss: 1.784870127968578\n",
            "loss: 1.7843492520985929\n",
            "loss: 1.7838309886615793\n",
            "loss: 1.7833153117508704\n",
            "loss: 1.7828022277029785\n",
            "loss: 1.7822915140163489\n",
            "loss: 1.7817833746965377\n",
            "loss: 1.781277800003288\n",
            "loss: 1.78077476434576\n",
            "loss: 1.780274273983645\n",
            "loss: 1.779776109166857\n",
            "loss: 1.779280455622492\n",
            "loss: 1.7787873195645434\n",
            "loss: 1.7782966913960232\n",
            "loss: 1.777808353541236\n",
            "loss: 1.7773224898894668\n",
            "loss: 1.776839106594659\n",
            "loss: 1.7763579876966182\n",
            "loss: 1.7758793157172066\n",
            "loss: 1.7754030967660455\n",
            "loss: 1.774929116486166\n",
            "loss: 1.7744575560459828\n",
            "loss: 1.7739882175976465\n",
            "loss: 1.7735212967046252\n",
            "loss: 1.773056768774641\n",
            "loss: 1.7725944374277995\n",
            "loss: 1.7721344967762525\n",
            "loss: 1.7716767361601518\n",
            "loss: 1.7712213336265341\n",
            "loss: 1.7707680947381965\n",
            "loss: 1.7703171966580897\n",
            "loss: 1.76986844591337\n",
            "loss: 1.7694220337435702\n",
            "loss: 1.7689777376899687\n",
            "loss: 1.7685355651142842\n",
            "loss: 1.7680957058361124\n",
            "loss: 1.767657939046751\n",
            "loss: 1.7672224685042641\n",
            "loss: 1.7667890744960542\n",
            "loss: 1.7663577642934678\n",
            "loss: 1.765928725371447\n",
            "loss: 1.7655017396496642\n",
            "loss: 1.76507681434496\n",
            "loss: 1.7646541209910769\n",
            "loss: 1.764233472261735\n",
            "loss: 1.7638148607339879\n",
            "loss: 1.7633984566702783\n",
            "loss: 1.7629840741345622\n",
            "loss: 1.7625717057618822\n",
            "loss: 1.7621613298695105\n",
            "loss: 1.7617529392316957\n",
            "loss: 1.7613467306389874\n",
            "loss: 1.7609425061186283\n",
            "loss: 1.7605402442029354\n",
            "loss: 1.7601399518967964\n",
            "loss: 1.7597416078370356\n",
            "loss: 1.7593452189933936\n",
            "loss: 1.7589509510322467\n",
            "loss: 1.7585586230345498\n",
            "loss: 1.7581682278325201\n",
            "loss: 1.757779744328619\n",
            "loss: 1.7573931794088793\n",
            "loss: 1.7570085120763979\n",
            "loss: 1.7566257353373649\n",
            "loss: 1.756244856027097\n",
            "loss: 1.7558658670821934\n",
            "loss: 1.7554887477139474\n",
            "loss: 1.7551135047076452\n",
            "loss: 1.7547401173745198\n",
            "loss: 1.7543685788241188\n",
            "loss: 1.7539988957920383\n",
            "loss: 1.7536310613192663\n",
            "loss: 1.7532650549238593\n",
            "loss: 1.752900869784261\n",
            "loss: 1.7525385125682027\n",
            "loss: 1.7521779763862617\n",
            "loss: 1.7518192409623936\n",
            "loss: 1.7514622995439448\n",
            "loss: 1.7511069813106415\n",
            "loss: 1.7507534444417057\n",
            "loss: 1.7504016955009807\n",
            "loss: 1.7500517144650343\n",
            "loss: 1.74970350786555\n",
            "loss: 1.7493570557803892\n",
            "loss: 1.7490121899139561\n",
            "loss: 1.7486690661072697\n",
            "loss: 1.7483276908283756\n",
            "loss: 1.7479880443479368\n",
            "loss: 1.747649947028823\n",
            "loss: 1.7473135792202976\n",
            "loss: 1.7469789213377298\n",
            "loss: 1.7466459797730463\n",
            "loss: 1.7463145636870383\n",
            "loss: 1.7459848387944572\n",
            "loss: 1.74565681143929\n",
            "loss: 1.7453302921999767\n",
            "loss: 1.7450054583151675\n",
            "loss: 1.744682290539647\n",
            "loss: 1.744360613646213\n",
            "loss: 1.7440406035562683\n",
            "loss: 1.743722073188109\n",
            "loss: 1.743405197590849\n",
            "loss: 1.7430899577570538\n",
            "loss: 1.7427761806226465\n",
            "loss: 1.7424640399375841\n",
            "loss: 1.7421533509298723\n",
            "loss: 1.7418442740471733\n",
            "loss: 1.7415366503449483\n",
            "loss: 1.7412306270044722\n",
            "loss: 1.740926045869893\n",
            "loss: 1.7406230533911053\n",
            "loss: 1.7403214799090825\n",
            "loss: 1.7400214834968029\n",
            "{'w': Parameter containing:\n",
            "tensor([4.1978], requires_grad=True), 'b': Parameter containing:\n",
            "tensor([8.7420], requires_grad=True)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6JKtls8mYrY",
        "colab_type": "code",
        "outputId": "154d136d-5e78-49cd-8cbf-46fa2029ff08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Plot the training data again, together with the line defined by y = wx + b\n",
        "# where w and b are our final learned parameters\n",
        "plt.plot(x, t, 'r.')\n",
        "plt.plot([0, 10], [params['b'], params['w'] * 10 + params['b']], 'b-')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6aaf850ef0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMf3GbOhmYrc",
        "colab_type": "text"
      },
      "source": [
        "## Linear Regression with a Feature Mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6sur0MDmYrd",
        "colab_type": "text"
      },
      "source": [
        "In this example we will fit a polynomial using linear regression with a polynomial feature mapping.\n",
        "The target function is:\n",
        "\n",
        "$$\n",
        "t = x^4 - 10 x^2 + 10 x + \\epsilon\n",
        "$$\n",
        "\n",
        "where $\\epsilon \\sim \\mathcal{N}(0, 4)$. \n",
        "\n",
        "This is an example of a _generalized linear model_, in which we perform a fixed nonlinear transformation of the inputs $\\mathbf{x} = (x_1, x_2, \\dots, x_D)$, and the model is still linear in the _parameters_. We can define a set of _feature mappings_ (also called feature functions or basis functions) $\\phi$ to implement the fixed transformations.\n",
        "\n",
        "In this case, we have $x \\in \\mathbb{R}$, and we define the feature mapping:\n",
        "$$\n",
        "\\mathbf{\\phi}(x) = \\begin{pmatrix}\\phi_1(x) \\\\ \\phi_2(x) \\\\ \\phi_3(x) \\\\ \\phi_4(x) \\end{pmatrix} = \\begin{pmatrix}1\\\\x\\\\x^2\\\\x^3\\end{pmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-XKvKC4mYre",
        "colab_type": "code",
        "outputId": "47d5582c-ef14-4989-d23d-826b94d3a762",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Generate synthetic data\n",
        "N = 100 # Number of data points\n",
        "x = np.linspace(-3, 3, N) # Generate N values linearly-spaced between -3 and 3\n",
        "t = x ** 4 - 10 * x ** 2 + 10 * x + npr.normal(0, 4, x.shape[0]) # Generate corresponding targets\n",
        "plt.plot(x, t, 'r.') # Plot data points\n",
        "\n",
        "t = torch.from_numpy(t).view(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGgROsxlmYrk",
        "colab_type": "code",
        "outputId": "c47b640f-3343-413b-f453-82825c30219a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "M = 4 # Degree of polynomial to fit to the data (this is a hyperparameter)\n",
        "feature_matrix = np.array([[item ** i for i in range(M+1)] for item in x]) # Construct a feature matrix \n",
        "feature_matrix = torch.from_numpy(feature_matrix).float()\n",
        "\n",
        "w = torch.nn.Parameter(torch.randn(feature_matrix.shape[-1], 1))\n",
        "print(w.shape)\n",
        "\n",
        "def cost():\n",
        "    y = torch.mm(feature_matrix, w)\n",
        "    return (1.0 / N) * torch.sum(0.5 * (y - t)**2)\n",
        "\n",
        "# Compute the gradient of the cost function using Autograd\n",
        "\n",
        "\n",
        "num_epochs = 1000\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Manually implement gradient descent\n",
        "for i in range(num_epochs):\n",
        "  loss = cost()\n",
        "  loss.backward()\n",
        "  print('loss:', loss.item())\n",
        "  with torch.no_grad():\n",
        "    w.data = w - learning_rate * w.grad\n",
        "    w.grad.zero_()\n",
        "\n",
        "\n",
        "# Print the final learned parameters.\n",
        "print(w)\n",
        "w = w.detach().cpu().numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 1])\n",
            "loss: 472.4221742639479\n",
            "loss: 152.2463276293331\n",
            "loss: 136.9154740323588\n",
            "loss: 133.78703357596578\n",
            "loss: 131.59982490233335\n",
            "loss: 129.82386945283793\n",
            "loss: 128.3590882734102\n",
            "loss: 127.13880821175869\n",
            "loss: 126.11105022892552\n",
            "loss: 125.2349282691962\n",
            "loss: 124.47831639097512\n",
            "loss: 123.81591572770598\n",
            "loss: 123.22783454112954\n",
            "loss: 122.69843279933957\n",
            "loss: 122.21540652163065\n",
            "loss: 121.76906137476972\n",
            "loss: 121.35180240060124\n",
            "loss: 120.95763023019487\n",
            "loss: 120.58182451073323\n",
            "loss: 120.22068539146143\n",
            "loss: 119.87129615046938\n",
            "loss: 119.53135969523458\n",
            "loss: 119.19907896316094\n",
            "loss: 118.8730218406355\n",
            "loss: 118.55207347697315\n",
            "loss: 118.23534713373569\n",
            "loss: 117.92216422818747\n",
            "loss: 117.61196831240274\n",
            "loss: 117.30432540776864\n",
            "loss: 116.9989078322227\n",
            "loss: 116.69543756066298\n",
            "loss: 116.39371316207904\n",
            "loss: 116.09356253763026\n",
            "loss: 115.7948536108916\n",
            "loss: 115.49748254014732\n",
            "loss: 115.20136580210426\n",
            "loss: 114.90644272653641\n",
            "loss: 114.61265068354066\n",
            "loss: 114.31996048716529\n",
            "loss: 114.02832573905569\n",
            "loss: 113.73772606951471\n",
            "loss: 113.44814584731583\n",
            "loss: 113.15954896396669\n",
            "loss: 112.87193897036374\n",
            "loss: 112.58529136885726\n",
            "loss: 112.29959914177533\n",
            "loss: 112.01485625151656\n",
            "loss: 111.73105366669003\n",
            "loss: 111.44817901339883\n",
            "loss: 111.16623931112038\n",
            "loss: 110.88521332471846\n",
            "loss: 110.60511079005515\n",
            "loss: 110.32591925051862\n",
            "loss: 110.04763650598753\n",
            "loss: 109.77025266149342\n",
            "loss: 109.49377700780656\n",
            "loss: 109.21819823562204\n",
            "loss: 108.94350841294984\n",
            "loss: 108.66970860306056\n",
            "loss: 108.39679768053713\n",
            "loss: 108.12476850482055\n",
            "loss: 107.85362240467995\n",
            "loss: 107.58334977977269\n",
            "loss: 107.31395175237869\n",
            "loss: 107.04542673992732\n",
            "loss: 106.7777688361498\n",
            "loss: 106.51097740406105\n",
            "loss: 106.24504306317598\n",
            "loss: 105.97997291244583\n",
            "loss: 105.71575674498814\n",
            "loss: 105.45239411694813\n",
            "loss: 105.18988018164448\n",
            "loss: 104.92821395472403\n",
            "loss: 104.66739070991525\n",
            "loss: 104.40740896638799\n",
            "loss: 104.14827112055538\n",
            "loss: 103.88996212294172\n",
            "loss: 103.63248984411405\n",
            "loss: 103.37584197862674\n",
            "loss: 103.12002379777192\n",
            "loss: 102.86503235421448\n",
            "loss: 102.61085755464717\n",
            "loss: 102.3575036641449\n",
            "loss: 102.10496939950085\n",
            "loss: 101.8532379547804\n",
            "loss: 101.60232312291255\n",
            "loss: 101.35221313351838\n",
            "loss: 101.10290951066382\n",
            "loss: 100.85440385318593\n",
            "loss: 100.6067001578044\n",
            "loss: 100.35979433907292\n",
            "loss: 100.11367613188301\n",
            "loss: 99.86835535849383\n",
            "loss: 99.62381533664988\n",
            "loss: 99.38006531467201\n",
            "loss: 99.13709336605673\n",
            "loss: 98.89490512660086\n",
            "loss: 98.65349367378934\n",
            "loss: 98.41285833305281\n",
            "loss: 98.17299202163541\n",
            "loss: 97.93389228552783\n",
            "loss: 97.69556630687761\n",
            "loss: 97.45799739183454\n",
            "loss: 97.22119388774823\n",
            "loss: 96.98514817674874\n",
            "loss: 96.74985573478392\n",
            "loss: 96.51531659132665\n",
            "loss: 96.28153123885383\n",
            "loss: 96.0484934792623\n",
            "loss: 95.81620086511617\n",
            "loss: 95.5846509667266\n",
            "loss: 95.35384094735281\n",
            "loss: 95.12377026698744\n",
            "loss: 94.8944373392134\n",
            "loss: 94.66583594105448\n",
            "loss: 94.43796728049747\n",
            "loss: 94.210822918714\n",
            "loss: 93.98440347498664\n",
            "loss: 93.75870577252331\n",
            "loss: 93.53373331170584\n",
            "loss: 93.30947196164861\n",
            "loss: 93.08593580603032\n",
            "loss: 92.86310339761921\n",
            "loss: 92.6409912366529\n",
            "loss: 92.41957976170423\n",
            "loss: 92.19887407193265\n",
            "loss: 91.97887415174266\n",
            "loss: 91.75957769791026\n",
            "loss: 91.54097391776493\n",
            "loss: 91.32307168150093\n",
            "loss: 91.10585755096724\n",
            "loss: 90.8893379420962\n",
            "loss: 90.67351035712258\n",
            "loss: 90.45836280102758\n",
            "loss: 90.24390076424444\n",
            "loss: 90.03012734203745\n",
            "loss: 89.81702870781353\n",
            "loss: 89.60460660065442\n",
            "loss: 89.3928600682273\n",
            "loss: 89.18178791399679\n",
            "loss: 88.97138415469615\n",
            "loss: 88.76165348221618\n",
            "loss: 88.55258114200356\n",
            "loss: 88.34417356763001\n",
            "loss: 88.13643290273299\n",
            "loss: 87.92934612850722\n",
            "loss: 87.72291546972706\n",
            "loss: 87.5171420549413\n",
            "loss: 87.31202142345825\n",
            "loss: 87.10754737928752\n",
            "loss: 86.90372454827177\n",
            "loss: 86.70054376615649\n",
            "loss: 86.49800876013359\n",
            "loss: 86.29611659263381\n",
            "loss: 86.0948593658727\n",
            "loss: 85.89423941537541\n",
            "loss: 85.69425611713345\n",
            "loss: 85.49490535033141\n",
            "loss: 85.29618117910881\n",
            "loss: 85.09808829029154\n",
            "loss: 84.90062060287319\n",
            "loss: 84.70377676200425\n",
            "loss: 84.50755640678499\n",
            "loss: 84.31194859675648\n",
            "loss: 84.11696792871238\n",
            "loss: 83.92259621348256\n",
            "loss: 83.72883861097618\n",
            "loss: 83.53569538760225\n",
            "loss: 83.34315776279773\n",
            "loss: 83.15122845130419\n",
            "loss: 82.95989997259359\n",
            "loss: 82.76917898390728\n",
            "loss: 82.57905577681178\n",
            "loss: 82.38953496061517\n",
            "loss: 82.20061090473284\n",
            "loss: 82.01227515926752\n",
            "loss: 81.82453543356583\n",
            "loss: 81.63738691890232\n",
            "loss: 81.45082795818774\n",
            "loss: 81.26484946111592\n",
            "loss: 81.07946296002535\n",
            "loss: 80.89465560477616\n",
            "loss: 80.7104314594732\n",
            "loss: 80.52678293613494\n",
            "loss: 80.34371335856193\n",
            "loss: 80.16121509495972\n",
            "loss: 79.97929139640894\n",
            "loss: 79.79793521200732\n",
            "loss: 79.61715497336746\n",
            "loss: 79.4369340027776\n",
            "loss: 79.25728034283014\n",
            "loss: 79.07819248215104\n",
            "loss: 78.89966276047858\n",
            "loss: 78.72169226821498\n",
            "loss: 78.54428129720284\n",
            "loss: 78.36742073980432\n",
            "loss: 78.1911173583409\n",
            "loss: 78.01536540620413\n",
            "loss: 77.84016356764786\n",
            "loss: 77.66550580027821\n",
            "loss: 77.49139501228633\n",
            "loss: 77.31783346396402\n",
            "loss: 77.14481106485913\n",
            "loss: 76.97232739711633\n",
            "loss: 76.8003820798024\n",
            "loss: 76.6289736101696\n",
            "loss: 76.45809977482173\n",
            "loss: 76.28775712203182\n",
            "loss: 76.11795161465184\n",
            "loss: 75.94867351392217\n",
            "loss: 75.77992020405186\n",
            "loss: 75.61169117941483\n",
            "loss: 75.44399039637912\n",
            "loss: 75.2768097242748\n",
            "loss: 75.11015214938851\n",
            "loss: 74.94401088508974\n",
            "loss: 74.77838853352719\n",
            "loss: 74.61327712006255\n",
            "loss: 74.44868319053715\n",
            "loss: 74.28460042970687\n",
            "loss: 74.12102567302566\n",
            "loss: 73.95795952662078\n",
            "loss: 73.79539816225655\n",
            "loss: 73.63334507246627\n",
            "loss: 73.47179391154764\n",
            "loss: 73.31074021024078\n",
            "loss: 73.15018874445306\n",
            "loss: 72.99013609441162\n",
            "loss: 72.83057545897897\n",
            "loss: 72.6715140930964\n",
            "loss: 72.51294369225127\n",
            "loss: 72.35486281637851\n",
            "loss: 72.1972718040454\n",
            "loss: 72.04016876876037\n",
            "loss: 71.8835551607062\n",
            "loss: 71.72742142795894\n",
            "loss: 71.5717712005671\n",
            "loss: 71.41660534895792\n",
            "loss: 71.2619173329744\n",
            "loss: 71.10770790242556\n",
            "loss: 70.95397468090884\n",
            "loss: 70.80071553850657\n",
            "loss: 70.64792690169517\n",
            "loss: 70.49561390159437\n",
            "loss: 70.34377030329428\n",
            "loss: 70.1923910412065\n",
            "loss: 70.04148284532982\n",
            "loss: 69.89103773308292\n",
            "loss: 69.74105661236563\n",
            "loss: 69.59154086323059\n",
            "loss: 69.44248112238812\n",
            "loss: 69.29387976391783\n",
            "loss: 69.14573640222788\n",
            "loss: 68.99805071136237\n",
            "loss: 68.85081824348985\n",
            "loss: 68.70403977906419\n",
            "loss: 68.55770709504138\n",
            "loss: 68.41183153642088\n",
            "loss: 68.26639584117873\n",
            "loss: 68.12140944163988\n",
            "loss: 67.97687255417574\n",
            "loss: 67.83277366771289\n",
            "loss: 67.68911791587203\n",
            "loss: 67.54590643963466\n",
            "loss: 67.40312991677885\n",
            "loss: 67.26079262093029\n",
            "loss: 67.11889533691\n",
            "loss: 66.97742694024066\n",
            "loss: 66.83639277169806\n",
            "loss: 66.69579259535725\n",
            "loss: 66.5556183872067\n",
            "loss: 66.4158746420078\n",
            "loss: 66.27655811173945\n",
            "loss: 66.13766816107164\n",
            "loss: 65.99920175915307\n",
            "loss: 65.86115738403905\n",
            "loss: 65.7235339565371\n",
            "loss: 65.58633375970493\n",
            "loss: 65.44954842536478\n",
            "loss: 65.31318377520205\n",
            "loss: 65.17723255499706\n",
            "loss: 65.04169472364887\n",
            "loss: 64.90657192983844\n",
            "loss: 64.7718654800675\n",
            "loss: 64.6375635580963\n",
            "loss: 64.50367007006439\n",
            "loss: 64.37018395526334\n",
            "loss: 64.23710830005074\n",
            "loss: 64.1044333441189\n",
            "loss: 63.97216037015898\n",
            "loss: 63.84029214550635\n",
            "loss: 63.7088225386362\n",
            "loss: 63.577752189096564\n",
            "loss: 63.44707953462303\n",
            "loss: 63.31680656435866\n",
            "loss: 63.18692562309583\n",
            "loss: 63.05744063408941\n",
            "loss: 62.92834760427531\n",
            "loss: 62.79964619168979\n",
            "loss: 62.67133503715702\n",
            "loss: 62.543410633743\n",
            "loss: 62.41587354425551\n",
            "loss: 62.288723646114384\n",
            "loss: 62.16195926696741\n",
            "loss: 62.0355769147565\n",
            "loss: 61.90957711230256\n",
            "loss: 61.78395992106676\n",
            "loss: 61.658721473849994\n",
            "loss: 61.53385632411314\n",
            "loss: 61.40937239509419\n",
            "loss: 61.28526654967251\n",
            "loss: 61.16152761702459\n",
            "loss: 61.03816738097489\n",
            "loss: 60.91517903833151\n",
            "loss: 60.79256147116683\n",
            "loss: 60.67030948519335\n",
            "loss: 60.54842955418895\n",
            "loss: 60.42691391939115\n",
            "loss: 60.305766329703474\n",
            "loss: 60.18497851730356\n",
            "loss: 60.06456062757393\n",
            "loss: 59.944498601007155\n",
            "loss: 59.82480211701356\n",
            "loss: 59.705462353830725\n",
            "loss: 59.586481818892246\n",
            "loss: 59.467858918599504\n",
            "loss: 59.34958915421247\n",
            "loss: 59.231679950134605\n",
            "loss: 59.1141202846294\n",
            "loss: 58.99691132802244\n",
            "loss: 58.88005874644678\n",
            "loss: 58.763551154516776\n",
            "loss: 58.647394430999604\n",
            "loss: 58.53158703058332\n",
            "loss: 58.41612311998159\n",
            "loss: 58.30100478784486\n",
            "loss: 58.186230730715195\n",
            "loss: 58.07179889688811\n",
            "loss: 57.95771039381794\n",
            "loss: 57.84396611965225\n",
            "loss: 57.73055591682087\n",
            "loss: 57.61748562540363\n",
            "loss: 57.504751481258495\n",
            "loss: 57.392349265844494\n",
            "loss: 57.28029219428721\n",
            "loss: 57.16856264666168\n",
            "loss: 57.05716649960245\n",
            "loss: 56.9461044107354\n",
            "loss: 56.83536732665675\n",
            "loss: 56.72496589777336\n",
            "loss: 56.61489100577177\n",
            "loss: 56.5051413218908\n",
            "loss: 56.39572262690857\n",
            "loss: 56.2866219964596\n",
            "loss: 56.177853683634574\n",
            "loss: 56.06940189199278\n",
            "loss: 55.961270666690105\n",
            "loss: 55.85346281706117\n",
            "loss: 55.74597556804304\n",
            "loss: 55.6388062756286\n",
            "loss: 55.531952201975116\n",
            "loss: 55.42541886673377\n",
            "loss: 55.31919245418938\n",
            "loss: 55.21328493116468\n",
            "loss: 55.10769372285193\n",
            "loss: 55.00241406510555\n",
            "loss: 54.8974423556983\n",
            "loss: 54.79277905271846\n",
            "loss: 54.688435042109845\n",
            "loss: 54.584389197851586\n",
            "loss: 54.480651936388654\n",
            "loss: 54.377221750191474\n",
            "loss: 54.2740977587623\n",
            "loss: 54.171275883112834\n",
            "loss: 54.06875541410117\n",
            "loss: 53.96653704797327\n",
            "loss: 53.86462402020019\n",
            "loss: 53.7630070169531\n",
            "loss: 53.66169194584958\n",
            "loss: 53.560673730098586\n",
            "loss: 53.4599475879111\n",
            "loss: 53.35952504637842\n",
            "loss: 53.259391910159785\n",
            "loss: 53.15955214596295\n",
            "loss: 53.06000770297986\n",
            "loss: 52.96075375735885\n",
            "loss: 52.86179225022498\n",
            "loss: 52.76312292753648\n",
            "loss: 52.664740171902686\n",
            "loss: 52.566647293714695\n",
            "loss: 52.46883887955301\n",
            "loss: 52.371317186000645\n",
            "loss: 52.27408138707778\n",
            "loss: 52.17712528702483\n",
            "loss: 52.0804597693338\n",
            "loss: 51.98407466617095\n",
            "loss: 51.887967207270194\n",
            "loss: 51.792143476061426\n",
            "loss: 51.696598615208934\n",
            "loss: 51.60133095141902\n",
            "loss: 51.5063450463847\n",
            "loss: 51.4116324587876\n",
            "loss: 51.31719335005868\n",
            "loss: 51.223031563548346\n",
            "loss: 51.12914778350224\n",
            "loss: 51.035527079625844\n",
            "loss: 50.942188092612234\n",
            "loss: 50.84911762987912\n",
            "loss: 50.756315493199146\n",
            "loss: 50.663783747358096\n",
            "loss: 50.57151871549406\n",
            "loss: 50.4795223139894\n",
            "loss: 50.38779653106974\n",
            "loss: 50.296330890260506\n",
            "loss: 50.20513496683848\n",
            "loss: 50.11420018544673\n",
            "loss: 50.02352947499263\n",
            "loss: 49.933124619214034\n",
            "loss: 49.8429742695429\n",
            "loss: 49.75308871583975\n",
            "loss: 49.663462141246214\n",
            "loss: 49.57409701523387\n",
            "loss: 49.484985787468595\n",
            "loss: 49.396135536249474\n",
            "loss: 49.30754003517541\n",
            "loss: 49.21919905631813\n",
            "loss: 49.1311145403137\n",
            "loss: 49.04327986776742\n",
            "loss: 48.95570462836815\n",
            "loss: 48.8683751411444\n",
            "loss: 48.781301004090395\n",
            "loss: 48.694476076422156\n",
            "loss: 48.60789581078292\n",
            "loss: 48.52157562387548\n",
            "loss: 48.435491961113286\n",
            "loss: 48.34966155186111\n",
            "loss: 48.264078558808464\n",
            "loss: 48.178734942222846\n",
            "loss: 48.09364077531564\n",
            "loss: 48.00878903094315\n",
            "loss: 47.924180278608866\n",
            "loss: 47.83981346922482\n",
            "loss: 47.755690842430205\n",
            "loss: 47.671803457935695\n",
            "loss: 47.58815804883266\n",
            "loss: 47.50475306169649\n",
            "loss: 47.421589987609266\n",
            "loss: 47.33865889655742\n",
            "loss: 47.25596491556708\n",
            "loss: 47.17350530114524\n",
            "loss: 47.091284919085375\n",
            "loss: 47.009295583725105\n",
            "loss: 46.92754082093074\n",
            "loss: 46.84602399023128\n",
            "loss: 46.7647301437155\n",
            "loss: 46.683677371135325\n",
            "loss: 46.60284427815497\n",
            "loss: 46.522250119111476\n",
            "loss: 46.44187791196626\n",
            "loss: 46.36173870529777\n",
            "loss: 46.28181967101409\n",
            "loss: 46.202135935158005\n",
            "loss: 46.12267540016653\n",
            "loss: 46.04343831952429\n",
            "loss: 45.96442832032576\n",
            "loss: 45.885642862833684\n",
            "loss: 45.807079660520884\n",
            "loss: 45.72873876575275\n",
            "loss: 45.6506183410374\n",
            "loss: 45.57271516324444\n",
            "loss: 45.49503780069005\n",
            "loss: 45.41757722719511\n",
            "loss: 45.34033173337689\n",
            "loss: 45.2633055314202\n",
            "loss: 45.186500663830756\n",
            "loss: 45.10991098707492\n",
            "loss: 45.03353324909667\n",
            "loss: 44.9573755042982\n",
            "loss: 44.881424692745334\n",
            "loss: 44.80569671148113\n",
            "loss: 44.73017644493371\n",
            "loss: 44.65487057940557\n",
            "loss: 44.579773764740175\n",
            "loss: 44.50489137967954\n",
            "loss: 44.43021236483828\n",
            "loss: 44.355748337352374\n",
            "loss: 44.28149190761138\n",
            "loss: 44.20744548476217\n",
            "loss: 44.1336062167941\n",
            "loss: 44.059969968664674\n",
            "loss: 43.986545085111594\n",
            "loss: 43.913321753880126\n",
            "loss: 43.8403026211514\n",
            "loss: 43.76749076910485\n",
            "loss: 43.69487816600704\n",
            "loss: 43.62246949273026\n",
            "loss: 43.550263065396024\n",
            "loss: 43.47826005472448\n",
            "loss: 43.40645616103587\n",
            "loss: 43.334851961835376\n",
            "loss: 43.26344368140926\n",
            "loss: 43.19223898424086\n",
            "loss: 43.121233992550614\n",
            "loss: 43.050423190773685\n",
            "loss: 42.97980689280923\n",
            "loss: 42.90939048657977\n",
            "loss: 42.83916895102554\n",
            "loss: 42.7691420066672\n",
            "loss: 42.69930905744886\n",
            "loss: 42.62966781084608\n",
            "loss: 42.56021763402601\n",
            "loss: 42.49096671606954\n",
            "loss: 42.42189997936449\n",
            "loss: 42.35303158932314\n",
            "loss: 42.284347450537915\n",
            "loss: 42.21585835792955\n",
            "loss: 42.147553901700675\n",
            "loss: 42.07944210274113\n",
            "loss: 42.01151589599963\n",
            "loss: 41.94377072815467\n",
            "loss: 41.876220960630235\n",
            "loss: 41.808851813268504\n",
            "loss: 41.74167109592908\n",
            "loss: 41.67467489000359\n",
            "loss: 41.607863297583236\n",
            "loss: 41.54123319817437\n",
            "loss: 41.47479084164197\n",
            "loss: 41.40852689302288\n",
            "loss: 41.34244478602711\n",
            "loss: 41.276544599994715\n",
            "loss: 41.2108252218325\n",
            "loss: 41.145284588394716\n",
            "loss: 41.07992668353073\n",
            "loss: 41.01474618678801\n",
            "loss: 40.94974568256542\n",
            "loss: 40.884920816563884\n",
            "loss: 40.820273347896986\n",
            "loss: 40.7558019922005\n",
            "loss: 40.69150630222133\n",
            "loss: 40.627383503862106\n",
            "loss: 40.56343930046009\n",
            "loss: 40.49966866540856\n",
            "loss: 40.436070762807404\n",
            "loss: 40.372643641310546\n",
            "loss: 40.309394494986314\n",
            "loss: 40.246311989436045\n",
            "loss: 40.183406112165436\n",
            "loss: 40.12067169014739\n",
            "loss: 40.05810498463816\n",
            "loss: 39.99570463748454\n",
            "loss: 39.93347616903194\n",
            "loss: 39.8714216862118\n",
            "loss: 39.809528160569805\n",
            "loss: 39.74780809689468\n",
            "loss: 39.68625239923551\n",
            "loss: 39.624864047960955\n",
            "loss: 39.563641753131094\n",
            "loss: 39.50258146424208\n",
            "loss: 39.4416897473243\n",
            "loss: 39.380960685442254\n",
            "loss: 39.320396307539575\n",
            "loss: 39.25999489720394\n",
            "loss: 39.1997575092434\n",
            "loss: 39.139682006264714\n",
            "loss: 39.07976534398245\n",
            "loss: 39.020012609493165\n",
            "loss: 38.9604152676935\n",
            "loss: 38.900984698467425\n",
            "loss: 38.8417152407305\n",
            "loss: 38.782601936561804\n",
            "loss: 38.72364519871833\n",
            "loss: 38.66484831827182\n",
            "loss: 38.60620434715507\n",
            "loss: 38.54772126726877\n",
            "loss: 38.489396101659\n",
            "loss: 38.43122572404189\n",
            "loss: 38.3732122566648\n",
            "loss: 38.315349805916405\n",
            "loss: 38.257647110222436\n",
            "loss: 38.200098321732106\n",
            "loss: 38.14269956530537\n",
            "loss: 38.08545239044377\n",
            "loss: 38.02836609573506\n",
            "loss: 37.97142291242989\n",
            "loss: 37.91463671809302\n",
            "loss: 37.858001208686474\n",
            "loss: 37.801515163821065\n",
            "loss: 37.745180760234824\n",
            "loss: 37.688991788195025\n",
            "loss: 37.63295710679224\n",
            "loss: 37.57706625916383\n",
            "loss: 37.52132624395204\n",
            "loss: 37.465733041907605\n",
            "loss: 37.41028781226375\n",
            "loss: 37.35498943914319\n",
            "loss: 37.29983449036421\n",
            "loss: 37.244828514966564\n",
            "loss: 37.18996611221195\n",
            "loss: 37.13525060510467\n",
            "loss: 37.08067758168675\n",
            "loss: 37.02625041024937\n",
            "loss: 36.97196546269639\n",
            "loss: 36.91782666291228\n",
            "loss: 36.86382556448546\n",
            "loss: 36.80996967991905\n",
            "loss: 36.75625139359279\n",
            "loss: 36.70267768354091\n",
            "loss: 36.64924705153584\n",
            "loss: 36.59595511728354\n",
            "loss: 36.542797844581635\n",
            "loss: 36.48978661512747\n",
            "loss: 36.43691330787837\n",
            "loss: 36.38417060210308\n",
            "loss: 36.33157931820198\n",
            "loss: 36.27911606014287\n",
            "loss: 36.22679193113154\n",
            "loss: 36.17460862011642\n",
            "loss: 36.122554437783556\n",
            "loss: 36.07063922055917\n",
            "loss: 36.018860751175204\n",
            "loss: 35.967217140481715\n",
            "loss: 35.9157052943604\n",
            "loss: 35.86432907885931\n",
            "loss: 35.81308785991245\n",
            "loss: 35.76197835992266\n",
            "loss: 35.71100129011855\n",
            "loss: 35.66016001128487\n",
            "loss: 35.6094497249066\n",
            "loss: 35.55887035141598\n",
            "loss: 35.50842154164806\n",
            "loss: 35.45810253802524\n",
            "loss: 35.40791892008412\n",
            "loss: 35.357860731683985\n",
            "loss: 35.30793273672369\n",
            "loss: 35.2581338874095\n",
            "loss: 35.20846098947932\n",
            "loss: 35.15891606930576\n",
            "loss: 35.10949904503378\n",
            "loss: 35.06021709073115\n",
            "loss: 35.011056399863826\n",
            "loss: 34.96202238709242\n",
            "loss: 34.913118093391766\n",
            "loss: 34.86433286291806\n",
            "loss: 34.81567680311377\n",
            "loss: 34.76714133162894\n",
            "loss: 34.718735559109035\n",
            "loss: 34.670452254880665\n",
            "loss: 34.62229579013794\n",
            "loss: 34.5742597713423\n",
            "loss: 34.526350316813605\n",
            "loss: 34.478557300456345\n",
            "loss: 34.430892283144125\n",
            "loss: 34.38334512757586\n",
            "loss: 34.33592070929531\n",
            "loss: 34.288615091901455\n",
            "loss: 34.24143599158809\n",
            "loss: 34.194375134880445\n",
            "loss: 34.14743125139711\n",
            "loss: 34.100610631745255\n",
            "loss: 34.05390853415866\n",
            "loss: 34.007323926556076\n",
            "loss: 33.960856193020085\n",
            "loss: 33.91451057550393\n",
            "loss: 33.86827751404185\n",
            "loss: 33.822162557352655\n",
            "loss: 33.77616782510567\n",
            "loss: 33.7302858179957\n",
            "loss: 33.68452643132128\n",
            "loss: 33.6388746066368\n",
            "loss: 33.59334544974407\n",
            "loss: 33.54792569968982\n",
            "loss: 33.50262404109965\n",
            "loss: 33.457437047821585\n",
            "loss: 33.41236685466247\n",
            "loss: 33.367406456010364\n",
            "loss: 33.32255801209064\n",
            "loss: 33.277820232634696\n",
            "loss: 33.23320264403393\n",
            "loss: 33.188695921406946\n",
            "loss: 33.144295815143934\n",
            "loss: 33.10001312575212\n",
            "loss: 33.05583531940709\n",
            "loss: 33.01177319890404\n",
            "loss: 32.96781708990967\n",
            "loss: 32.92397384365558\n",
            "loss: 32.88024014326377\n",
            "loss: 32.8366160802737\n",
            "loss: 32.79310287870367\n",
            "loss: 32.74969560617859\n",
            "loss: 32.70639513274606\n",
            "loss: 32.663207165555754\n",
            "loss: 32.620122112179786\n",
            "loss: 32.57714904496045\n",
            "loss: 32.53428027423275\n",
            "loss: 32.49151613386355\n",
            "loss: 32.448861709393526\n",
            "loss: 32.406307646344224\n",
            "loss: 32.3638653229811\n",
            "loss: 32.32152734217898\n",
            "loss: 32.279292788935514\n",
            "loss: 32.23716372037336\n",
            "loss: 32.195140106730484\n",
            "loss: 32.15321855161986\n",
            "loss: 32.11140295551528\n",
            "loss: 32.06969330177272\n",
            "loss: 32.02808209377546\n",
            "loss: 31.986576275088847\n",
            "loss: 31.945174279083744\n",
            "loss: 31.903868168390087\n",
            "loss: 31.862667988058313\n",
            "loss: 31.821568817601147\n",
            "loss: 31.78057106727762\n",
            "loss: 31.739676167587536\n",
            "loss: 31.698881688660865\n",
            "loss: 31.658181978269287\n",
            "loss: 31.617584935907754\n",
            "loss: 31.5770875318983\n",
            "loss: 31.536690690122082\n",
            "loss: 31.496392636027924\n",
            "loss: 31.456190390910812\n",
            "loss: 31.41609172848403\n",
            "loss: 31.37608654194653\n",
            "loss: 31.33618098327226\n",
            "loss: 31.29637155274695\n",
            "loss: 31.256659900467323\n",
            "loss: 31.217045642859734\n",
            "loss: 31.177528458456955\n",
            "loss: 31.138104569601943\n",
            "loss: 31.098780780782015\n",
            "loss: 31.05954912662361\n",
            "loss: 31.020414827315548\n",
            "loss: 30.981374621339686\n",
            "loss: 30.942427027146614\n",
            "loss: 30.903575126791363\n",
            "loss: 30.864816373801382\n",
            "loss: 30.826154400964487\n",
            "loss: 30.787582938055618\n",
            "loss: 30.749107276585985\n",
            "loss: 30.710723653697688\n",
            "loss: 30.672433732055637\n",
            "loss: 30.63423604492937\n",
            "loss: 30.596129981313148\n",
            "loss: 30.55811660880684\n",
            "loss: 30.52018983887098\n",
            "loss: 30.48235909613033\n",
            "loss: 30.444620274587677\n",
            "loss: 30.406968798366563\n",
            "loss: 30.36941115296085\n",
            "loss: 30.33193951606571\n",
            "loss: 30.29455877206247\n",
            "loss: 30.25726959548232\n",
            "loss: 30.220068105389537\n",
            "loss: 30.18295673876144\n",
            "loss: 30.145934722380343\n",
            "loss: 30.109000673476103\n",
            "loss: 30.07215472203412\n",
            "loss: 30.035395654184228\n",
            "loss: 29.998724189120793\n",
            "loss: 29.962141031491107\n",
            "loss: 29.92564639588682\n",
            "loss: 29.889236142890017\n",
            "loss: 29.8529161436465\n",
            "loss: 29.816679838270613\n",
            "loss: 29.780526762857917\n",
            "loss: 29.74446259174487\n",
            "loss: 29.7084828558887\n",
            "loss: 29.672589765143275\n",
            "loss: 29.636781396021465\n",
            "loss: 29.60105604594631\n",
            "loss: 29.56541594083122\n",
            "loss: 29.529859305658164\n",
            "loss: 29.494389180010394\n",
            "loss: 29.459002570133343\n",
            "loss: 29.423698562874602\n",
            "loss: 29.388477618415646\n",
            "loss: 29.35334320771398\n",
            "loss: 29.318287774065503\n",
            "loss: 29.283313744252464\n",
            "loss: 29.248422917892164\n",
            "loss: 29.213612943497683\n",
            "loss: 29.178882590404097\n",
            "loss: 29.14423880337718\n",
            "loss: 29.109673949640012\n",
            "loss: 29.0751908655072\n",
            "loss: 29.040786946949456\n",
            "loss: 29.006462768004777\n",
            "loss: 28.97221863086286\n",
            "loss: 28.93805546800125\n",
            "loss: 28.903973197330096\n",
            "loss: 28.869972114848238\n",
            "loss: 28.83604592080142\n",
            "loss: 28.80219789125538\n",
            "loss: 28.768432776470735\n",
            "loss: 28.734744416017676\n",
            "loss: 28.701133398866165\n",
            "loss: 28.66759908970108\n",
            "loss: 28.634142748309163\n",
            "loss: 28.60076787997855\n",
            "loss: 28.567468796088438\n",
            "loss: 28.534243731168054\n",
            "loss: 28.501099368004667\n",
            "loss: 28.468028065876762\n",
            "loss: 28.435035678124887\n",
            "loss: 28.402117034416452\n",
            "loss: 28.369275701835882\n",
            "loss: 28.336511981435756\n",
            "loss: 28.303825101649807\n",
            "loss: 28.271206640826946\n",
            "loss: 28.238667266117442\n",
            "loss: 28.206202243182574\n",
            "loss: 28.173811577715675\n",
            "loss: 28.141496623822565\n",
            "loss: 28.109253900320734\n",
            "loss: 28.077088099980294\n",
            "loss: 28.04499669265121\n",
            "loss: 28.01297298203488\n",
            "loss: 27.981025294965185\n",
            "loss: 27.949151829392093\n",
            "loss: 27.917347844369424\n",
            "loss: 27.885615946209555\n",
            "loss: 27.853958328095196\n",
            "loss: 27.822375371402696\n",
            "loss: 27.790860303911035\n",
            "loss: 27.759416349514968\n",
            "loss: 27.728044084240207\n",
            "loss: 27.69674523336677\n",
            "loss: 27.665518537471048\n",
            "loss: 27.634357384894503\n",
            "loss: 27.603272558423747\n",
            "loss: 27.57225787906772\n",
            "loss: 27.541305985650958\n",
            "loss: 27.51042997080619\n",
            "loss: 27.479624431078065\n",
            "loss: 27.44888764496504\n",
            "loss: 27.418218110789816\n",
            "loss: 27.3876186693643\n",
            "loss: 27.357087482147804\n",
            "loss: 27.326626972162817\n",
            "loss: 27.296231163165366\n",
            "loss: 27.26590677194945\n",
            "loss: 27.235647917412418\n",
            "loss: 27.20545979489199\n",
            "loss: 27.175338758967552\n",
            "loss: 27.145284240537187\n",
            "loss: 27.115297405866414\n",
            "loss: 27.085374194660517\n",
            "loss: 27.055522670087555\n",
            "loss: 27.0257384098415\n",
            "loss: 26.996014781647563\n",
            "loss: 26.966362931112236\n",
            "loss: 26.93677600041564\n",
            "loss: 26.907251034008915\n",
            "loss: 26.87779645992763\n",
            "loss: 26.84840698932993\n",
            "loss: 26.81908295320859\n",
            "loss: 26.789819631471474\n",
            "loss: 26.760623829640217\n",
            "loss: 26.73149305635541\n",
            "loss: 26.70242424806871\n",
            "loss: 26.673423173361375\n",
            "loss: 26.644485094280267\n",
            "loss: 26.61560979058647\n",
            "loss: 26.586798586987967\n",
            "loss: 26.55805114459739\n",
            "loss: 26.52936675826078\n",
            "loss: 26.500744018819933\n",
            "loss: 26.47218911365692\n",
            "loss: 26.443693769758287\n",
            "loss: 26.415261668979912\n",
            "loss: 26.386893621681285\n",
            "loss: 26.35858470175776\n",
            "loss: 26.330335066986066\n",
            "loss: 26.302155361598853\n",
            "loss: 26.27403184733042\n",
            "loss: 26.245968769878615\n",
            "loss: 26.217968166364887\n",
            "loss: 26.19003213533017\n",
            "loss: 26.16215376035859\n",
            "loss: 26.134339276367196\n",
            "loss: 26.10658296014182\n",
            "loss: 26.078885128294743\n",
            "loss: 26.051248538660303\n",
            "loss: 26.02367504142644\n",
            "loss: 25.99616124107626\n",
            "loss: 25.968704763854305\n",
            "loss: 25.941306900131604\n",
            "loss: 25.91396869545178\n",
            "loss: 25.886690596610542\n",
            "loss: 25.85947190092674\n",
            "loss: 25.832312348866555\n",
            "loss: 25.805209001104696\n",
            "loss: 25.778166898307983\n",
            "loss: 25.751183945153823\n",
            "loss: 25.72425680784935\n",
            "loss: 25.697386273511494\n",
            "loss: 25.670577081619797\n",
            "loss: 25.64382298822871\n",
            "loss: 25.617129795963535\n",
            "loss: 25.590489254904355\n",
            "loss: 25.56391009732908\n",
            "loss: 25.537384450626682\n",
            "loss: 25.510915086005657\n",
            "loss: 25.484504024864975\n",
            "loss: 25.45814877493931\n",
            "loss: 25.431853192320773\n",
            "loss: 25.40560975549049\n",
            "loss: 25.37942064814027\n",
            "loss: 25.35328888454087\n",
            "loss: 25.3272174852367\n",
            "loss: 25.301197043911763\n",
            "loss: 25.275233306391364\n",
            "loss: 25.249325052179135\n",
            "loss: 25.223471246017013\n",
            "loss: 25.197671136375007\n",
            "loss: 25.171927315952306\n",
            "loss: 25.146235457557122\n",
            "loss: 25.120598733892226\n",
            "loss: 25.095017819216352\n",
            "loss: 25.0694879751346\n",
            "loss: 25.04401328767567\n",
            "loss: 25.018594304500493\n",
            "loss: 24.993226817899536\n",
            "loss: 24.96791462701948\n",
            "loss: 24.94265354007044\n",
            "loss: 24.91744599361675\n",
            "loss: 24.892291345704276\n",
            "loss: 24.867190805917836\n",
            "loss: 24.842140324073608\n",
            "loss: 24.817140881127784\n",
            "loss: 24.79220039389583\n",
            "loss: 24.767308734368722\n",
            "loss: 24.74247063337254\n",
            "loss: 24.717681206744928\n",
            "loss: 24.692943893725612\n",
            "loss: 24.66825910999531\n",
            "loss: 24.643625669493574\n",
            "loss: 24.61904386783783\n",
            "loss: 24.594512820742437\n",
            "loss: 24.570033426053048\n",
            "loss: 24.545603422310823\n",
            "loss: 24.521223017897512\n",
            "loss: 24.496895815117433\n",
            "loss: 24.472619543098688\n",
            "loss: 24.448390986084327\n",
            "loss: 24.424210495973732\n",
            "loss: 24.400084348465768\n",
            "loss: 24.376008739879172\n",
            "loss: 24.351980218183325\n",
            "loss: 24.32800255731293\n",
            "loss: 24.30407324140689\n",
            "loss: 24.28019462048788\n",
            "loss: 24.256363014678303\n",
            "loss: 24.232580942450483\n",
            "loss: 24.20884921745881\n",
            "loss: 24.185164116250007\n",
            "loss: 24.161526192725752\n",
            "loss: 24.137937161111722\n",
            "loss: 24.114400221762143\n",
            "loss: 24.09090972127876\n",
            "loss: 24.067465493469456\n",
            "loss: 24.044071203581936\n",
            "loss: 24.020720885595\n",
            "loss: 23.997421552273163\n",
            "loss: 23.974168121821283\n",
            "loss: 23.950963336673894\n",
            "loss: 23.927805214334175\n",
            "loss: 23.904694061256937\n",
            "loss: 23.881629653599763\n",
            "loss: 23.858612735721735\n",
            "loss: 23.835640242101707\n",
            "loss: 23.812713099531102\n",
            "loss: 23.789837756064028\n",
            "loss: 23.76700558387166\n",
            "loss: 23.744219554263285\n",
            "loss: 23.721481529764652\n",
            "loss: 23.69878605789608\n",
            "loss: 23.67614039371949\n",
            "loss: 23.65353841222257\n",
            "loss: 23.63097812281268\n",
            "loss: 23.60846773349872\n",
            "loss: 23.586001550016114\n",
            "loss: 23.56357843076868\n",
            "loss: 23.541202420543595\n",
            "loss: 23.51887036710547\n",
            "loss: 23.496582933348147\n",
            "loss: 23.474338614504724\n",
            "loss: 23.45214101963295\n",
            "loss: 23.42998577973853\n",
            "loss: 23.40787539298358\n",
            "loss: 23.38580920819177\n",
            "loss: 23.363788822016744\n",
            "loss: 23.341809720199862\n",
            "loss: 23.319875268197993\n",
            "loss: 23.29798308933036\n",
            "loss: 23.276136791026392\n",
            "loss: 23.254332319034003\n",
            "loss: 23.232569352784434\n",
            "loss: 23.210855564076653\n",
            "loss: 23.18918006969548\n",
            "loss: 23.167547806710246\n",
            "Parameter containing:\n",
            "tensor([[-3.3880],\n",
            "        [ 2.9794],\n",
            "        [-6.5523],\n",
            "        [ 1.1584],\n",
            "        [ 0.5867]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY3XajWcmYrp",
        "colab_type": "code",
        "outputId": "2d6298d8-472a-472c-c970-60989157078b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Plot the original training data again, together with the polynomial we fit\n",
        "plt.plot(x, t, 'r.')\n",
        "plt.plot(x, np.dot(feature_matrix, w), 'b-')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6aaf78ba58>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWYEe11YmYrs",
        "colab_type": "text"
      },
      "source": [
        "## Neural Net Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7bnv5LemYru",
        "colab_type": "text"
      },
      "source": [
        "In this example we will implement a (nonlinear) regression model using a neural network. To implement and train a neural net using Autograd, you only have to define the forward pass of the network and the loss function you wish to use; you do _not_ need to implement the _backward pass_ of the network. When you take the gradient of the loss function using `grad`, Autograd automatically computes computes the backward pass. It essentially executes the backpropagation algorithm implicitly.\n",
        "\n",
        "![Neural Network Architecture for Regression](https://drive.google.com/uc?export=view&id=1iBNS40V_afm_Y1MUosDqeio0wbxgycfh)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TuIWDkCmYr5",
        "colab_type": "code",
        "outputId": "7a7ead0c-353a-47ba-e020-568c9b652000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Generate synthetic data\n",
        "x = np.linspace(-5, 5, 1000)\n",
        "t = x ** 3 - 20 * x + 10 + npr.normal(0, 4, x.shape[0])\n",
        "plt.plot(x, t, 'r.')\n",
        "\n",
        "x = torch.from_numpy(x).float()\n",
        "t = torch.from_numpy(t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yphlCjMmmYr9",
        "colab_type": "code",
        "outputId": "13396351-9c29-425b-85ac-65692a823a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "inputs = x.reshape(x.shape[-1],1)\n",
        "W1 = torch.nn.Parameter(torch.randn(1,4))\n",
        "b1 =  torch.nn.Parameter(torch.randn(4))\n",
        "W2 =  torch.nn.Parameter(torch.randn(4,4))\n",
        "b2 = torch.nn.Parameter(torch.randn(4))\n",
        "W3 =  torch.nn.Parameter(torch.randn(4, 1))\n",
        "b3 =  torch.nn.Parameter(torch.randn(1))\n",
        "\n",
        "params = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2, 'W3': W3, 'b3': b3 }\n",
        "\n",
        "\n",
        "#We can define an optimizer which takes care of updating parameters based on their gradient. We can use more complex optimizers like SGD+Momntum or Adam.\n",
        "optimizer = torch.optim.SGD(params.values(), lr=0.0001, weight_decay=0.0001, momentum=0.9)\n",
        "\n",
        "#Pytorch also has implementation of wide range of activation functions such as: Tanh, ReLU, LeakyReLU, ...\n",
        "nonlinearity = torch.nn.ReLU()\n",
        "\n",
        "def predict(params, inputs):\n",
        "    h1 = nonlinearity(torch.mm(inputs, params['W1']) + params['b1'])\n",
        "    h2 = nonlinearity(torch.mm(h1, params['W2']) + params['b2'])\n",
        "    output = torch.mm(h2, params['W3']) + params['b3']\n",
        "    return output\n",
        "\n",
        "def cost(params):\n",
        "    output = predict(params, inputs)\n",
        "    return (1.0 / inputs.shape[0]) * torch.sum(0.5 * (output.reshape(output.shape[0]) - t)**2)\n",
        "\n",
        "print(cost(params))\n",
        "\n",
        "num_epochs = 10000\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  # Evaluate the gradient of the current parameters stored in params\n",
        "  loss = cost(params)\n",
        "  print(loss)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "with torch.no_grad():\n",
        "  final_y = predict(params, inputs)\n",
        "  plt.plot(x, t, 'r.')\n",
        "  plt.plot(x, final_y, 'b-')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(326.8536, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(326.8536, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(326.7687, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(326.6078, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(326.3797, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(326.0924, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(325.7533, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(325.3693, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(324.9468, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(324.4913, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(324.0081, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(323.5016, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(322.9759, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(322.4344, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(321.8801, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(321.3157, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(320.7432, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(320.1647, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(319.5814, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(318.9948, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(318.4057, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(317.8149, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(317.2229, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(316.6300, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(316.0364, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(315.4422, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(314.8472, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(314.2514, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(313.6543, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(313.0557, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(312.4550, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(311.8516, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(311.2451, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(310.6345, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(310.0193, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(309.3986, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(308.7714, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(308.1368, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(307.4936, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(306.8407, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(306.1768, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(305.5005, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(304.8105, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(304.1052, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(303.3829, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(302.6417, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(301.8798, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(301.0948, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(300.2846, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(299.4467, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(298.5783, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(297.6768, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(296.7388, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(295.7613, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(294.7406, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(293.6729, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(292.5542, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(291.3797, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(290.1448, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(288.8443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(287.4729, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(286.0246, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(284.4931, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(282.8717, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(281.1533, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(279.3305, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(277.3953, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(275.3395, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(273.1548, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(270.8315, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(268.3604, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(265.7326, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(262.9384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(259.9688, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(256.8152, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(253.4699, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(249.9259, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(246.1782, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(242.2238, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(238.0633, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(233.7005, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(229.1428, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(224.4047, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(219.5067, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(214.4774, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(209.3534, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(204.1808, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(199.0149, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(193.9213, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(188.9747, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(184.2560, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(179.8482, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(175.8344, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(172.2918, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(169.2859, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(166.8623, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(165.0408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(163.8103, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(163.1272, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(162.9155, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(163.0736, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(163.4810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(164.0115, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(164.5452, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(164.9793, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(165.2384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(165.2790, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(165.0891, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(164.6855, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(164.1061, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(163.4012, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(162.6255, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(161.8298, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(161.0577, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(160.3417, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(159.7028, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(159.1504, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(158.6858, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(158.3022, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(157.9887, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(157.7308, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(157.5141, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(157.3245, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(157.1488, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(156.9763, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(156.7990, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(156.6112, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(156.4084, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(156.1891, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(155.9534, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(155.7024, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(155.4391, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(155.1663, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(154.8874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(154.6053, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(154.3235, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(154.0456, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(153.7727, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(153.5066, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(153.2485, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(152.9988, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(152.7571, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(152.5229, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(152.2959, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(152.0751, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(151.8590, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(151.6461, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(151.4362, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(151.2281, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(151.0209, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(150.8149, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(150.6096, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(150.4048, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(150.2008, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(149.9982, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(149.7972, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(149.5989, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(149.4028, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(149.2087, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(149.0171, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(148.8290, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(148.6443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(148.4627, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(148.2841, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(148.1097, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(147.9388, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(147.7709, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(147.6061, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(147.4443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(147.2848, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(147.1280, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(146.9736, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(146.8213, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(146.6712, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(146.5234, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(146.3777, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(146.2345, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(146.0932, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(145.9538, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(145.8166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(145.6812, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(145.5478, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(145.4165, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(145.2874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(145.1601, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(145.0346, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(144.9103, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(144.7877, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(144.6668, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(144.5472, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(144.4291, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(144.3124, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(144.1966, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(144.0821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(143.9688, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(143.8566, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(143.7455, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(143.6355, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(143.5265, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(143.4186, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(143.3114, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(143.2050, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(143.0998, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(142.9948, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(142.8902, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(142.7860, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(142.6824, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(142.5794, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(142.4770, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(142.3749, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(142.2736, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(142.1726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(142.0722, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(141.9724, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(141.8729, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(141.7739, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(141.6750, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(141.5765, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(141.4783, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(141.3805, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(141.2829, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(141.1856, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(141.0889, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(140.9922, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(140.8958, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(140.7994, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(140.7027, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(140.6063, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(140.5099, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(140.4138, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(140.3178, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(140.2215, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(140.1253, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(140.0293, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(139.9335, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(139.8373, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(139.7412, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(139.6450, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(139.5490, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(139.4531, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(139.3575, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(139.2621, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(139.1672, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(139.0723, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(138.9773, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(138.8826, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(138.7877, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(138.6926, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(138.5978, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(138.5029, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(138.4076, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(138.3119, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(138.2159, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(138.1193, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(138.0218, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(137.9234, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(137.8249, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(137.7272, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(137.6305, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(137.5351, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(137.4409, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(137.3488, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(137.2587, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(137.1704, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(137.0842, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(136.9996, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(136.9168, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(136.8352, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(136.7548, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(136.6750, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(136.5953, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(136.5151, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(136.4339, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(136.3509, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(136.2656, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(136.1774, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(136.0855, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(135.9895, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(135.8886, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(135.7817, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(135.6670, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(135.5427, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(135.4066, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(135.2551, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(135.0842, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(134.8932, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(134.6940, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(134.4893, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(134.2810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(134.0703, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(133.8584, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(133.6464, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(133.4345, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(133.2227, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(133.0113, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(132.7995, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(132.5869, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(132.3738, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(132.1595, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(131.9443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(131.7278, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(131.5103, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(131.2917, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(131.0720, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(130.8513, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(130.6297, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(130.4071, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(130.1837, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(129.9594, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(129.7344, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(129.5086, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(129.2820, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(129.0548, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(128.8270, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(128.5987, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(128.3699, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(128.1406, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(127.9109, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(127.6810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(127.4507, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(127.2201, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(126.9890, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(126.7575, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(126.5258, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(126.2934, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(126.0605, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(125.8269, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(125.5929, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(125.3584, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(125.1233, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(124.8879, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(124.6522, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(124.4162, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(124.1798, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(123.9432, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(123.7062, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(123.4689, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(123.2317, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(122.9942, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(122.7564, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(122.5187, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(122.2809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(122.0429, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(121.8048, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(121.5668, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(121.3287, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(121.0904, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(120.8520, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(120.6136, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(120.3751, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(120.1365, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(119.8982, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(119.6599, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(119.4214, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(119.1830, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(118.9446, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(118.7009, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(118.4065, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(118.1054, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(117.7997, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(117.4934, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(117.1895, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(116.8895, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(116.5932, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(116.2995, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(116.0066, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(115.7125, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(115.4156, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(115.1150, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(114.8103, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(114.5021, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(114.1914, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(113.8794, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(113.5674, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(113.2565, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(112.9472, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(112.6398, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(112.3341, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(112.0297, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(111.7262, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(111.4229, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(111.1193, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(110.8152, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(110.5107, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(110.2062, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(109.9020, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(109.5987, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(109.2965, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(108.9952, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(108.6946, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(108.3952, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(108.0969, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(107.7993, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(107.5024, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(107.2061, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(106.9101, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(106.6146, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(106.3196, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(106.0254, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(105.7324, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(105.4407, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(105.1499, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(104.8602, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(104.5714, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(104.2838, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(103.9971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(103.7113, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(103.4264, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(103.1426, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(102.8598, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(102.5783, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(102.2978, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(102.0183, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(101.7400, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(101.4630, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(101.1873, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(100.9125, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(100.6388, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(100.3660, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(100.0941, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(99.8232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(99.5533, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(99.2847, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(99.0172, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(98.7508, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(98.4853, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(98.2209, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(97.9581, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(97.6967, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(97.4365, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(97.1775, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(96.9199, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(96.6634, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(96.4085, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(96.1548, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(95.9022, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(95.6507, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(95.4008, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(95.1523, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(94.9050, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(94.6587, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(94.4138, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(94.1701, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(93.9280, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(93.6876, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(93.4486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(93.2108, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(92.9742, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(92.7387, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(92.5045, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(92.2713, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(92.0395, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(91.8087, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(91.5792, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(91.3508, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(91.1236, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(90.8974, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(90.6723, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(90.4488, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(90.2275, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(90.0074, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(89.7885, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(89.5711, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(89.3552, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(89.1407, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(88.9281, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(88.7170, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(88.5074, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(88.2993, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(88.0920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(87.8857, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(87.6806, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(87.4763, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(87.2733, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(87.0717, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(86.8713, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(86.6726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(86.4752, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(86.2788, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(86.0835, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(85.8894, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(85.6965, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(85.5049, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(85.3145, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(85.1255, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(84.9375, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(84.7507, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(84.5652, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(84.3811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(84.1982, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(84.0170, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(83.8371, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(83.6580, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(83.4800, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(83.3036, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(83.1291, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(82.9559, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(82.7840, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(82.6135, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(82.4443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(82.2764, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(82.1099, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(81.9438, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(81.7788, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(81.6151, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(81.4529, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(81.2919, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(81.1322, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(80.9736, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(80.8164, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(80.6607, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(80.5063, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(80.3530, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(80.2007, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(80.0496, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(79.8995, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(79.7506, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(79.6029, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(79.4564, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(79.3112, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(79.1671, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(79.0242, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(78.8824, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(78.7418, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(78.6025, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(78.4643, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(78.3272, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(78.1908, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(78.0555, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(77.9213, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(77.7881, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(77.6559, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(77.5248, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(77.3943, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(77.2647, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(77.1362, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(77.0082, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(76.8810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(76.7548, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(76.6291, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(76.5043, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(76.3804, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(76.2573, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(76.1352, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(76.0139, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(75.8928, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(75.7726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(75.6534, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(75.5352, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(75.4179, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(75.3017, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(75.1864, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(75.0720, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(74.9581, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(74.8448, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(74.7324, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(74.6207, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(74.5098, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(74.3998, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(74.2909, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(74.1829, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(74.0757, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(73.9695, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(73.8640, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(73.7595, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(73.6556, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(73.5522, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(73.4496, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(73.3477, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(73.2466, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(73.1463, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(73.0467, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(72.9478, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(72.8497, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(72.7523, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(72.6556, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(72.5597, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(72.4642, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(72.3696, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(72.2756, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(72.1824, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(72.0899, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(71.9981, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(71.9069, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(71.8165, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(71.7267, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(71.6375, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(71.5490, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(71.4611, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(71.3738, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(71.2872, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(71.2013, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(71.1160, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(71.0313, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(70.9473, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(70.8638, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(70.7810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(70.6987, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(70.6169, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(70.5357, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(70.4551, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(70.3750, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(70.2950, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(70.2155, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(70.1366, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(70.0582, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(69.9801, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(69.9025, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(69.8254, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(69.7489, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(69.6727, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(69.5969, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(69.5216, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(69.4468, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(69.3724, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(69.2983, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(69.2247, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(69.1517, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(69.0791, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(69.0067, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(68.9347, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(68.8633, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(68.7923, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(68.7218, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(68.6517, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(68.5821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(68.5131, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(68.4451, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(68.3775, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(68.3108, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(68.2451, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(68.1802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(68.1157, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(68.0512, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(67.9869, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(67.9244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(67.8623, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(67.8006, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(67.7391, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(67.6780, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(67.6174, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(67.5577, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(67.4983, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(67.4394, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(67.3812, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(67.3237, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(67.2666, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(67.2099, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(67.1533, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(67.0971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(67.0415, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(66.9868, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(66.9322, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(66.8777, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(66.8235, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(66.7698, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(66.7165, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(66.6636, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(66.6108, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(66.5581, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(66.5054, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(66.4534, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(66.4016, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(66.3499, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(66.2985, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(66.2475, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(66.1968, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(66.1466, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(66.0966, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(66.0467, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.9970, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.9479, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.8990, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.8500, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.8013, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.7528, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.7044, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.6562, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.6080, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.5598, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.5117, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.4638, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.4160, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.3688, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.3215, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.2736, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.2262, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.1789, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.1315, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.0839, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(65.0366, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.9897, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.9428, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.8958, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.8488, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.8020, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.7554, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.7090, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.6626, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.6163, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.5700, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.5237, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.4776, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.4315, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.3855, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.3395, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.2936, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.2476, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.2017, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.1559, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.1100, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.0643, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(64.0185, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.9728, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.9271, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.8815, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.8359, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.7903, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.7446, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.6989, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.6533, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.6076, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.5619, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.5163, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.4707, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.4251, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.3795, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.3339, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.2883, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.2427, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.1971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.1514, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.1057, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.0599, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(63.0142, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.9685, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.9227, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.8771, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.8314, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.7858, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.7401, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.6945, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.6488, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.6031, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.5574, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.5117, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.4660, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.4202, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.3744, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.3287, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.2828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.2369, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.1910, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.1451, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.0991, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.0532, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(62.0072, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.9612, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.9152, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.8692, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.8232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.7771, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.7311, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.6849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.6387, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.5927, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.5465, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.5002, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.4541, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.4079, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.3616, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.3153, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.2689, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.2225, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.1761, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.1297, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.0832, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(61.0367, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.9902, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.9436, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.8969, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.8503, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.8036, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.7569, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.7102, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.6634, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.6165, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.5697, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.5228, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.4758, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.4288, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.3818, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.3347, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.2876, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.2404, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.1932, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.1459, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.0986, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.0512, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(60.0038, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.9563, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.9087, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.8611, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.8136, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.7658, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.7181, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.6704, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.6225, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.5748, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.5269, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.4788, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.4309, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.3829, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.3347, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.2866, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.2384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.1902, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.1419, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.0936, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(59.0452, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.9967, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.9482, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.8996, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.8510, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.8023, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.7535, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.7047, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.6558, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.6069, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.5579, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.5088, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.4597, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.4105, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.3612, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.3119, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.2624, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.2130, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.1635, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.1138, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.0641, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(58.0145, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.9647, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.9148, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.8649, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.8150, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.7650, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.7150, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.6649, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.6147, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.5644, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.5140, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.4636, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.4130, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.3624, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.3117, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.2609, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.2100, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.1592, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.1082, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.0572, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(57.0061, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(56.9550, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(56.9039, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(56.8528, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(56.8017, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(56.7505, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(56.6992, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(56.6479, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(56.5965, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(56.5451, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(56.4936, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(56.4420, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(56.3904, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(56.3387, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(56.2870, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(56.2352, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(56.1833, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(56.1314, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(56.0795, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(56.0275, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(55.9755, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(55.9235, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(55.8715, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(55.8194, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(55.7673, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(55.7151, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(55.6628, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(55.6105, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(55.5582, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(55.5058, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(55.4533, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(55.4008, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(55.3481, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(55.2954, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(55.2425, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(55.1896, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(55.1366, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(55.0837, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(55.0304, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(54.9773, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(54.9241, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(54.8711, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(54.8179, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(54.7645, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(54.7112, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(54.6581, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(54.6045, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(54.5511, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(54.4975, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(54.4439, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(54.3902, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(54.3365, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(54.2827, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(54.2288, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(54.1748, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(54.1208, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(54.0667, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(54.0124, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(53.9581, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(53.9038, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(53.8493, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(53.7951, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(53.7408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(53.6862, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(53.6317, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(53.5772, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(53.5226, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(53.4678, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(53.4130, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(53.3583, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(53.3035, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(53.2486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(53.1937, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(53.1387, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(53.0836, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(53.0285, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(52.9734, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(52.9182, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(52.8629, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(52.8075, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(52.7522, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(52.6968, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(52.6416, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(52.5862, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(52.5306, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(52.4752, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(52.4198, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(52.3644, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(52.3090, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(52.2537, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(52.1982, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(52.1428, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(52.0873, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(52.0318, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(51.9763, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(51.9207, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(51.8651, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(51.8095, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(51.7539, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(51.6982, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(51.6424, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(51.5866, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(51.5308, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(51.4748, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(51.4189, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(51.3628, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(51.3067, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(51.2506, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(51.1944, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(51.1381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(51.0818, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(51.0253, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(50.9688, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(50.9122, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(50.8555, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(50.7988, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(50.7420, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(50.6851, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(50.6282, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(50.5713, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(50.5142, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(50.4571, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(50.3999, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(50.3426, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(50.2853, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(50.2279, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(50.1704, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(50.1129, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(50.0553, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(49.9976, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(49.9399, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(49.8821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(49.8242, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(49.7663, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(49.7084, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(49.6504, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(49.5923, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(49.5342, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(49.4761, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(49.4178, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(49.3595, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(49.3011, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(49.2425, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(49.1838, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(49.1250, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(49.0661, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(49.0072, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(48.9481, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(48.8890, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(48.8297, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(48.7704, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(48.7110, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(48.6515, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(48.5920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(48.5323, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(48.4726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(48.4129, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(48.3531, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(48.2932, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(48.2333, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(48.1734, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(48.1134, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(48.0534, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(47.9934, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(47.9333, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(47.8732, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(47.8130, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(47.7527, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(47.6924, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(47.6322, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(47.5719, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(47.5116, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(47.4513, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(47.3909, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(47.3306, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(47.2702, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(47.2097, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(47.1493, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(47.0888, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(47.0283, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(46.9677, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(46.9069, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(46.8462, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(46.7853, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(46.7244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(46.6635, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(46.6024, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(46.5413, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(46.4801, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(46.4190, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(46.3578, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(46.2967, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(46.2355, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(46.1742, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(46.1129, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(46.0516, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(45.9902, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(45.9288, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(45.8674, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(45.8059, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(45.7443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(45.6828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(45.6212, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(45.5595, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(45.4978, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(45.4361, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(45.3743, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(45.3126, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(45.2508, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(45.1890, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(45.1270, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(45.0648, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(45.0026, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(44.9403, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(44.8781, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(44.8154, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(44.7527, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(44.6897, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(44.6267, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(44.5638, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(44.5009, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(44.4380, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(44.3750, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(44.3119, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(44.2488, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(44.1857, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(44.1226, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(44.0596, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(43.9965, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(43.9335, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(43.8706, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(43.8077, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(43.7445, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(43.6813, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(43.6180, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(43.5547, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(43.4916, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(43.4286, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(43.3655, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(43.3025, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(43.2396, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(43.1766, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(43.1138, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(43.0511, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(42.9886, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(42.9260, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(42.8635, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(42.8009, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(42.7385, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(42.6760, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(42.6136, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(42.5512, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(42.4889, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(42.4267, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(42.3645, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(42.3023, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(42.2401, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(42.1780, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(42.1160, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(42.0540, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(41.9920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(41.9300, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(41.8681, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(41.8062, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(41.7442, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(41.6823, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(41.6203, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(41.5584, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(41.4964, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(41.4345, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(41.3725, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(41.3106, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(41.2487, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(41.1868, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(41.1249, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(41.0631, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(41.0013, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(40.9396, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(40.8780, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(40.8161, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(40.7543, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(40.6926, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(40.6309, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(40.5693, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(40.5077, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(40.4461, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(40.3846, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(40.3232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(40.2618, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(40.2005, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(40.1391, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(40.0778, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(40.0165, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(39.9551, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(39.8938, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(39.8326, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(39.7714, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(39.7102, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(39.6490, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(39.5880, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(39.5269, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(39.4659, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(39.4049, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(39.3438, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(39.2827, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(39.2216, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(39.1605, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(39.0994, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(39.0382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(38.9769, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(38.9158, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(38.8546, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(38.7934, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(38.7323, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(38.6712, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(38.6101, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(38.5491, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(38.4881, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(38.4271, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(38.3663, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(38.3056, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(38.2449, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(38.1845, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(38.1241, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(38.0638, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(38.0036, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(37.9434, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(37.8833, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(37.8234, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(37.7634, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(37.7035, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(37.6437, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(37.5840, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(37.5244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(37.4647, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(37.4050, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(37.3453, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(37.2857, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(37.2262, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(37.1669, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(37.1077, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(37.0487, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(36.9897, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(36.9309, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(36.8723, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(36.8137, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(36.7554, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(36.6971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(36.6389, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(36.5808, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(36.5227, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(36.4647, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(36.4068, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(36.3491, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(36.2914, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(36.2338, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(36.1763, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(36.1188, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(36.0615, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(36.0043, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(35.9472, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(35.8903, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(35.8335, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(35.7768, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(35.7201, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(35.6635, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(35.6070, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(35.5506, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(35.4942, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(35.4378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(35.3816, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(35.3256, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(35.2696, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(35.2137, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(35.1580, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(35.1024, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(35.0469, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(34.9914, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(34.9361, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(34.8809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(34.8260, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(34.7712, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(34.7166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(34.6620, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(34.6075, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(34.5532, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(34.4989, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(34.4449, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(34.3909, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(34.3371, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(34.2834, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(34.2296, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(34.1760, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(34.1223, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(34.0687, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(34.0152, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(33.9618, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(33.9086, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(33.8554, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(33.8025, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(33.7498, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(33.6971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(33.6446, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(33.5921, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(33.5398, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(33.4876, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(33.4354, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(33.3833, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(33.3313, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(33.2795, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(33.2277, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(33.1761, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(33.1246, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(33.0732, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(33.0219, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.9707, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.9197, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.8688, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.8181, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.7675, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.7170, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.6666, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.6164, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.5664, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.5165, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.4667, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.4170, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.3674, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.3177, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.2682, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.2187, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.1693, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.1201, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.0711, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(32.0221, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.9733, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.9246, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.8760, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.8276, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.7793, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.7311, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.6829, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.6346, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.5865, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.5384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.4904, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.4426, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.3947, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.3470, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.2994, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.2521, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.2048, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.1574, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.1102, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.0631, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(31.0162, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.9694, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.9227, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.8760, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.8294, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.7830, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.7367, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.6906, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.6445, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.5986, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.5529, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.5073, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.4619, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.4166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.3715, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.3265, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.2817, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.2370, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.1926, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.1482, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.1041, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.0602, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(30.0164, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.9728, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.9294, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.8861, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.8429, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.7995, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.7563, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.7132, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.6703, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.6275, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.5848, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.5423, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.5000, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.4578, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.4158, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.3738, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.3318, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.2900, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.2483, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.2067, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.1653, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.1239, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.0827, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.0414, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(29.0002, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.9592, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.9183, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.8776, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.8369, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.7962, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.7557, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.7154, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.6751, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.6350, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.5950, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.5551, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.5154, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.4758, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.4364, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.3972, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.3581, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.3191, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.2803, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.2417, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.2031, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.1647, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.1264, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.0883, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.0502, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(28.0123, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.9743, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.9365, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.8987, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.8611, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.8234, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.7859, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.7484, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.7110, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.6737, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.6365, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.5995, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.5625, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.5258, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.4891, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.4526, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.4161, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.3798, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.3436, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.3075, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.2716, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.2358, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.2001, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.1644, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.1289, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.0934, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.0581, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(27.0228, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.9877, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.9527, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.9178, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.8830, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.8483, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.8137, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.7791, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.7447, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.7105, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.6764, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.6424, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.6084, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.5746, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.5408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.5071, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.4733, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.4397, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.4061, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.3728, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.3395, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.3064, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.2733, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.2402, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.2072, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.1744, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.1417, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.1091, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.0766, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.0443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(26.0122, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.9801, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.9482, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.9163, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.8845, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.8527, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.8210, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.7895, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.7580, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.7267, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.6955, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.6643, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.6332, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.6021, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.5712, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.5404, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.5097, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.4791, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.4486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.4181, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.3878, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.3575, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.3274, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.2973, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.2673, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.2375, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.2078, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.1782, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.1488, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.1193, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.0900, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.0607, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.0316, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(25.0026, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.9737, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.9449, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.9162, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.8877, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.8592, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.8307, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.8024, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.7741, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.7460, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.7179, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.6900, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.6621, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.6344, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.6068, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.5792, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.5518, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.5245, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.4973, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.4701, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.4431, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.4162, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.3894, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.3627, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.3361, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.3095, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.2830, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.2567, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.2305, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.2044, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.1783, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.1522, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.1262, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.1004, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.0747, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.0490, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(24.0235, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.9980, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.9726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.9473, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.9220, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.8967, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.8715, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.8462, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.8210, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.7960, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.7711, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.7462, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.7214, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.6967, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.6721, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.6475, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.6231, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.5988, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.5746, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.5505, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.5264, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.5023, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.4784, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.4545, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.4307, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.4070, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.3834, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.3598, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.3362, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.3126, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.2891, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.2657, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.2422, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.2188, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.1955, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.1723, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.1491, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.1260, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.1030, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.0800, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.0571, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.0343, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.0115, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.9888, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.9662, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.9436, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.9210, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.8986, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.8762, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.8539, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.8316, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.8095, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.7873, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.7653, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.7434, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.7215, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.6997, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.6779, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.6562, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.6346, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.6129, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.5914, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.5700, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.5486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.5273, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.5060, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.4849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.4637, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.4426, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.4215, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.4005, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.3795, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.3583, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.3372, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.3162, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.2954, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.2746, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.2539, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.2332, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.2124, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.1917, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.1711, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.1505, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.1300, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.1096, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.0892, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.0688, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.0486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.0284, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(22.0082, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.9882, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.9682, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.9483, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.9284, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.9087, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.8889, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.8690, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.8493, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.8296, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.8100, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.7905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.7710, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.7516, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.7321, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.7128, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.6935, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.6743, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.6550, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.6356, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.6163, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.5971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.5780, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.5590, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.5401, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.5211, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.5023, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.4835, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.4647, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.4460, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.4273, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.4087, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.3902, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.3717, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.3533, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.3349, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.3166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.2985, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.2803, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.2622, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.2443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.2264, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.2085, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.1907, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.1730, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.1553, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.1377, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.1201, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.1026, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.0851, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.0676, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.0501, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.0327, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(21.0152, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.9977, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.9802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.9628, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.9453, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.9279, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.9105, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.8931, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.8757, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.8585, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.8412, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.8241, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.8070, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.7899, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.7729, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.7559, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.7390, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.7221, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.7054, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.6886, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.6719, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.6553, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.6387, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.6222, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.6058, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.5894, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.5731, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.5568, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.5407, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.5245, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.5083, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.4922, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.4761, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.4601, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.4442, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.4283, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.4125, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.3967, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.3809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.3653, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.3496, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.3341, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.3186, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.3032, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.2878, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.2724, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.2571, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.2418, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.2266, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.2114, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.1963, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.1813, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.1662, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.1512, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.1363, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.1213, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.1062, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.0912, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.0763, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.0613, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.0464, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.0315, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.0166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(20.0017, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.9869, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.9722, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.9575, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.9429, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.9282, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.9137, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.8991, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.8847, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.8703, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.8558, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.8412, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.8267, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.8121, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.7976, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.7831, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.7686, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.7542, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.7398, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.7255, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.7112, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.6969, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.6827, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.6685, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.6544, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.6404, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.6263, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.6123, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.5983, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.5844, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.5705, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.5565, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.5426, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.5288, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.5150, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.5012, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.4874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.4736, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.4599, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.4462, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.4326, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.4190, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.4055, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.3920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.3786, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.3652, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.3518, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.3385, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.3252, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.3120, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.2988, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.2857, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.2726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.2595, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.2464, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.2334, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.2204, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.2075, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.1946, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.1817, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.1689, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.1561, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.1433, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.1306, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.1179, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.1052, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.0926, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.0800, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.0675, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.0550, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.0426, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.0302, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.0179, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(19.0056, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.9933, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.9811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.9689, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.9567, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.9446, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.9325, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.9204, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.9082, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.8961, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.8840, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.8719, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.8599, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.8479, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.8359, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.8240, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.8121, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.8003, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.7885, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.7767, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.7650, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.7533, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.7417, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.7300, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.7183, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.7067, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.6951, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.6836, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.6720, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.6604, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.6488, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.6373, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.6258, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.6144, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.6030, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.5916, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.5803, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.5690, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.5578, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.5465, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.5352, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.5240, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.5128, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.5016, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.4905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.4794, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.4683, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.4573, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.4463, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.4353, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.4243, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.4133, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.4024, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.3914, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.3805, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.3697, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.3589, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.3481, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.3373, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.3265, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.3157, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.3050, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.2943, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.2837, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.2731, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.2625, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.2519, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.2414, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.2309, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.2204, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.2099, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.1995, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.1891, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.1786, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.1682, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.1578, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.1474, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.1370, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.1267, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.1163, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.1060, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.0958, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.0855, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.0753, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.0652, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.0550, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.0449, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.0348, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.0248, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.0147, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(18.0047, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.9948, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.9848, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.9748, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.9649, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.9550, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.9451, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.9353, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.9255, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.9157, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.9059, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.8962, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.8865, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.8768, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.8672, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.8576, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.8479, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.8384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.8288, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.8193, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.8098, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.8003, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.7909, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.7814, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.7719, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.7624, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.7529, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.7434, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.7339, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.7244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.7150, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.7057, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.6964, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.6871, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.6778, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.6686, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.6594, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.6503, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.6412, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.6322, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.6232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.6142, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.6052, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.5962, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.5873, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.5783, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.5694, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.5605, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.5516, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.5428, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.5339, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.5250, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.5162, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.5074, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.4986, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.4898, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.4810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.4723, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.4635, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.4548, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.4461, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.4375, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.4288, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.4202, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.4116, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.4031, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.3945, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.3860, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.3775, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.3690, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.3606, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.3521, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.3437, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.3354, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.3270, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.3187, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.3104, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.3022, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.2939, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.2857, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.2775, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.2694, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.2611, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.2528, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.2446, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.2364, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.2281, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.2199, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.2117, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.2035, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.1954, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.1872, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.1791, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.1710, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.1629, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.1548, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.1466, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.1386, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.1305, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.1225, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.1145, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.1065, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.0985, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.0905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.0826, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.0746, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.0668, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.0589, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.0510, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.0431, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.0352, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.0273, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.0195, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.0116, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(17.0037, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.9959, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.9881, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.9803, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.9725, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.9649, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.9571, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.9495, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.9418, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.9341, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.9265, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.9189, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.9113, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.9038, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.8963, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.8887, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.8813, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.8738, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.8664, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.8591, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.8517, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.8444, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.8370, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.8298, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.8225, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.8152, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.8080, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.8007, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.7935, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.7863, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.7791, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.7719, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.7648, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.7576, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.7505, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.7433, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.7362, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.7291, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.7220, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.7149, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.7079, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.7008, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.6938, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.6868, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.6798, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.6729, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.6660, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.6591, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.6522, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.6453, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.6384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.6316, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.6248, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.6179, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.6112, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.6044, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.5976, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.5909, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.5842, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.5775, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.5708, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.5641, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.5575, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.5509, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.5443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.5377, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.5311, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.5245, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.5180, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.5114, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.5049, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.4984, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.4920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.4855, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.4790, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.4726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.4662, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.4598, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.4534, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.4470, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.4407, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.4343, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.4280, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.4217, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.4154, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.4091, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.4029, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.3966, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.3904, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.3842, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.3780, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.3717, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.3654, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.3592, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.3529, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.3466, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.3404, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.3341, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.3279, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.3218, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.3156, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.3095, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.3034, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.2973, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.2913, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.2852, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.2792, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.2731, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.2669, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.2608, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.2547, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.2485, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.2424, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.2363, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.2301, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.2240, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.2179, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.2117, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.2056, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.1996, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.1934, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.1873, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.1811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.1750, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.1688, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.1627, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.1565, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.1504, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.1444, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.1383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.1323, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.1262, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.1202, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.1142, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.1082, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.1023, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.0963, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.0903, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.0844, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.0785, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.0726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.0667, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.0609, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.0550, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.0491, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.0433, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.0375, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.0317, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.0260, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.0202, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.0145, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.0088, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(16.0031, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.9974, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.9917, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.9861, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.9804, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.9748, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.9692, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.9636, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.9580, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.9524, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.9469, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.9414, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.9359, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.9304, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.9249, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.9194, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.9139, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.9085, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.9031, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.8976, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.8921, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.8866, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.8812, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.8757, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.8703, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.8649, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.8595, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.8542, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.8488, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.8435, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.8382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.8329, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.8276, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.8224, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.8171, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.8119, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.8067, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.8015, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.7963, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.7911, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.7859, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.7807, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.7755, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.7704, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.7652, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.7601, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.7550, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.7499, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.7448, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.7398, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.7347, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.7297, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.7247, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.7196, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.7146, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.7096, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.7047, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6996, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6945, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6894, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6842, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6790, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6738, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6686, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6634, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6582, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6531, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6479, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6428, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6377, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6326, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6275, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6224, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6173, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6122, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6071, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.6021, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5970, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5870, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5820, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5771, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5721, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5671, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5622, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5572, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5523, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5474, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5424, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5375, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5327, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5278, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5229, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5181, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5132, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5084, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.5034, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4984, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4934, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4884, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4833, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4783, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4733, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4683, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4633, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4583, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4534, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4438, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4389, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4341, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4293, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4245, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4197, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4149, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4102, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4054, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.4006, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3959, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3912, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3865, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3818, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3771, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3724, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3678, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3631, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3585, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3539, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3493, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3447, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3401, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3355, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3310, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3264, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3218, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3172, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3126, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3079, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.3033, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2987, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2940, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2894, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2848, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2756, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2711, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2666, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2621, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2577, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2533, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2488, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2444, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2400, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2355, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2311, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2267, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2223, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2180, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2136, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2093, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2050, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.2006, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1964, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1921, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1878, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1836, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1794, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1752, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1709, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1667, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1625, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1584, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1542, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1500, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1459, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1417, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1376, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1334, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1292, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1252, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1211, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1170, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1129, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1088, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1047, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.1006, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0965, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0925, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0884, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0843, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0801, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0761, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0719, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0679, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0639, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0598, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0559, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0519, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0480, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0440, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0401, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0361, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0322, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0283, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0206, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0167, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0128, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0090, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0052, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(15.0013, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9975, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9937, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9899, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9862, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9824, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9786, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9749, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9711, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9674, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9636, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9599, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9561, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9524, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9449, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9411, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9374, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9337, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9300, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9264, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9227, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9190, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9154, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9117, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9081, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9045, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.9008, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8972, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8936, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8900, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8864, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8829, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8793, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8757, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8722, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8686, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8651, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8615, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8580, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8545, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8510, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8474, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8439, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8404, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8369, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8335, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8300, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8265, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8231, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8196, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8162, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8127, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8093, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8059, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.8025, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7991, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7957, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7923, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7890, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7856, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7822, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7789, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7756, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7721, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7687, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7653, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7618, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7584, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7549, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7515, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7481, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7447, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7413, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7346, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7312, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7279, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7245, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7212, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7179, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7146, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7113, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7080, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7047, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.7014, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6982, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6949, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6916, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6884, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6851, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6819, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6786, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6754, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6722, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6690, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6658, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6626, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6594, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6562, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6530, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6498, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6467, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6435, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6403, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6371, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6339, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6307, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6275, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6243, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6210, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6178, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6146, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6114, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6081, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6049, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.6016, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5984, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5952, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5888, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5856, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5824, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5792, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5759, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5727, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5695, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5662, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5630, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5598, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5566, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5534, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5501, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5469, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5438, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5406, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5374, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5342, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5310, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5278, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5247, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5215, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5183, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5152, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5120, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5089, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5057, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.5026, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4995, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4963, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4932, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4901, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4870, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4839, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4808, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4778, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4747, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4716, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4685, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4655, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4624, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4594, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4564, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4533, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4503, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4473, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4412, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4352, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4321, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4290, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4260, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4230, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4200, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4169, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4138, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4108, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4077, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4048, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.4018, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3987, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3957, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3927, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3898, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3868, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3839, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3779, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3750, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3720, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3691, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3661, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3631, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3602, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3572, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3543, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3513, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3484, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3454, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3425, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3395, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3366, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3337, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3307, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3278, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3249, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3220, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3191, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3162, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3133, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3105, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3076, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3048, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.3019, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2991, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2963, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2934, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2906, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2878, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2850, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2822, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2794, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2766, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2739, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2711, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2683, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2656, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2629, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2601, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2574, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2547, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2520, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2493, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2466, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2439, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2412, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2385, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2358, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2331, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2305, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2278, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2251, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2225, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2198, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2172, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2145, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2118, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2092, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2065, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2038, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.2012, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1985, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1959, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1932, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1906, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1880, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1853, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1827, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1801, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1775, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1749, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1723, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1697, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1672, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1646, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1620, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1594, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1569, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1543, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1518, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1492, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1467, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1441, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1416, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1391, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1365, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1340, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1315, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1290, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1265, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1240, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1215, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1190, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1141, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1117, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1093, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1068, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1044, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.1020, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0995, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0973, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0948, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0923, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0901, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0851, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0826, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0803, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0779, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0755, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0731, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0708, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0684, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0660, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0637, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0613, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0591, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0567, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0545, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0521, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0498, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0476, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0452, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0430, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0407, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0362, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0339, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0317, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0295, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0272, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0250, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0228, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0206, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0184, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0162, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0140, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0118, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0096, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0074, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0053, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0031, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(14.0009, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9987, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9966, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9944, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9923, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9901, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9880, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9858, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9837, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9816, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9795, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9773, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9752, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9731, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9710, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9689, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9668, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9647, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9626, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9605, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9584, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9563, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9542, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9522, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9501, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9480, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9459, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9439, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9418, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9398, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9377, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9356, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9335, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9314, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9293, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9273, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9252, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9231, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9210, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9190, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9169, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9149, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9128, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9108, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9088, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9068, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9048, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9027, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.9007, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8987, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8967, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8946, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8926, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8885, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8865, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8845, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8825, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8805, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8785, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8765, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8745, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8725, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8705, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8686, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8666, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8646, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8627, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8607, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8588, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8568, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8549, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8529, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8510, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8490, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8471, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8451, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8432, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8413, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8394, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8375, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8356, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8337, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8318, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8299, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8280, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8262, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8243, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8224, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8206, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8187, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8169, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8150, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8132, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8114, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8096, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8078, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8060, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8041, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8024, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.8005, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7988, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7970, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7952, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7934, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7916, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7898, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7881, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7863, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7845, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7793, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7775, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7758, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7740, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7723, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7706, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7688, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7671, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7654, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7637, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7619, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7601, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7584, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7566, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7548, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7530, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7512, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7494, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7477, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7459, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7441, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7424, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7406, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7389, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7371, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7353, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7335, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7317, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7299, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7281, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7263, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7227, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7209, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7191, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7173, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7156, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7138, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7120, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7103, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7085, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7068, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7051, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7031, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.7013, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6995, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6978, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6960, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6941, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6923, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6906, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6888, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6871, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6854, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6836, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6819, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6785, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6768, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6750, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6733, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6716, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6699, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6682, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6665, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6648, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6631, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6614, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6597, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6580, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6563, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6546, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6530, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6513, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6496, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6480, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6463, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6447, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6430, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6413, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6397, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6364, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6348, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6331, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6315, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6299, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6283, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6266, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6250, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6234, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6218, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6202, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6186, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6170, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6154, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6138, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6122, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6106, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6090, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6074, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6058, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6041, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6025, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.6008, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5992, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5975, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5959, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5943, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5926, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5910, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5894, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5878, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5862, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5843, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5825, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5808, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5791, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5774, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5756, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5738, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5722, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5706, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5690, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5673, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5657, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5642, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5626, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5610, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5593, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5577, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5560, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5544, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5528, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5511, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5495, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5479, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5463, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5447, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5431, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5415, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5399, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5368, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5352, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5336, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5320, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5304, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5289, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5273, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5257, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5241, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5226, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5210, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5195, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5179, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5164, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5148, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5133, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5117, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5102, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5087, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5071, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5056, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5041, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5026, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.5010, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4995, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4980, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4965, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4950, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4935, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4889, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4858, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4842, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4826, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4795, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4779, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4764, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4748, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4733, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4717, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4702, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4687, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4672, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4656, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4641, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4626, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4611, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4596, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4581, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4565, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4550, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4535, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4520, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4505, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4490, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4475, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4460, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4445, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4430, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4415, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4400, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4385, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4370, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4356, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4341, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4326, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4311, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4297, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4282, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4267, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4253, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4238, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4224, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4209, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4195, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4181, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4152, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4137, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4123, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4108, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4094, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4080, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4065, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4051, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4037, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4023, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.4009, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3995, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3981, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3966, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3953, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3938, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3924, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3911, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3897, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3883, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3869, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3855, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3841, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3827, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3813, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3800, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3786, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3772, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3758, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3745, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3731, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3717, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3704, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3691, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3677, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3664, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3650, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3637, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3624, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3610, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3597, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3583, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3569, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3556, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3542, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3528, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3515, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3501, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3488, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3474, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3461, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3448, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3434, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3421, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3395, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3369, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3356, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3343, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3329, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3317, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3303, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3290, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3277, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3265, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3252, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3239, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3226, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3213, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3200, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3187, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3175, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3162, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3149, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3137, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3124, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3111, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3099, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3086, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3074, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3061, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3049, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3036, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3024, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.3011, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2999, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2986, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2974, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2961, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2948, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2935, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2922, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2910, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2897, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2884, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2872, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2859, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2847, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2834, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2822, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2797, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2785, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2772, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2760, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2747, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2736, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2723, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2712, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2698, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2687, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2675, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2663, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2650, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2639, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2627, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2614, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2603, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2591, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2579, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2567, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2556, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2544, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2532, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2520, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2509, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2497, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2474, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2463, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2451, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2440, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2428, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2417, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2406, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2394, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2371, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2359, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2348, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2336, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2324, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2312, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2300, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2288, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2276, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2265, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2253, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2242, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2230, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2219, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2207, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2196, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2184, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2173, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2162, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2150, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2139, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2128, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2116, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2105, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2093, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2082, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2071, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2060, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2049, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2037, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2026, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2015, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.2004, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1993, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1982, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1960, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1949, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1938, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1928, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1917, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1907, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1895, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1886, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1864, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1853, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1843, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1832, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1822, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1800, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1790, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1780, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1769, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1759, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1748, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1738, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1729, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1718, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1708, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1697, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1688, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1677, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1667, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1658, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1647, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1638, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1628, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1618, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1608, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1598, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1588, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1578, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1569, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1559, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1549, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1540, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1530, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1520, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1511, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1501, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1492, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1482, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1472, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1463, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1453, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1433, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1424, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1414, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1404, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1394, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1385, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1375, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1365, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1356, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1346, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1337, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1327, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1318, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1308, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1299, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1289, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1280, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1270, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1261, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1252, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1242, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1233, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1224, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1214, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1205, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1196, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1186, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1177, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1168, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1159, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1150, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1140, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1131, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1121, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1112, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1103, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1094, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1084, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1074, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1065, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1056, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1047, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1037, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1028, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1019, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1010, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.1000, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0991, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0982, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0973, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0964, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0955, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0946, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0937, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0928, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0919, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0910, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0900, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0891, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0882, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0865, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0856, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0847, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0838, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0829, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0820, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0793, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0785, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0776, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0767, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0758, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0749, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0741, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0732, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0723, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0714, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0706, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0697, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0688, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0680, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0671, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0662, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0654, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0645, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0637, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0628, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0620, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0611, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0603, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0595, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0586, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0578, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0569, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0561, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0553, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0544, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0536, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0528, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0520, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0511, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0503, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0495, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0487, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0478, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0470, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0462, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0454, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0446, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0437, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0429, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0421, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0413, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0405, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0397, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0389, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0373, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0365, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0357, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0349, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0341, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0333, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0325, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0317, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0309, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0301, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0293, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0284, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0276, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0267, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0258, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0250, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0241, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0224, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0215, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0207, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0198, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0190, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0182, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0174, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0165, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0157, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0149, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0141, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0133, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0124, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0116, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0108, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0100, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0092, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0084, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0075, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0067, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0059, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0051, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0043, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0035, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0027, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0019, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0011, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(13.0003, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9995, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9987, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9979, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9963, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9955, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9948, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9940, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9932, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9924, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9916, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9909, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9901, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9893, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9885, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9878, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9870, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9862, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9855, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9847, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9839, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9831, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9824, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9816, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9808, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9801, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9793, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9785, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9777, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9770, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9762, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9755, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9747, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9739, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9732, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9724, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9716, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9709, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9701, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9694, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9686, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9679, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9671, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9663, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9656, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9648, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9641, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9633, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9626, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9619, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9611, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9604, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9596, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9589, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9581, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9574, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9567, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9559, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9552, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9544, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9537, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9530, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9522, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9515, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9508, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9501, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9493, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9479, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9472, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9465, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9457, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9450, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9436, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9429, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9422, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9415, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9401, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9394, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9387, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9380, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9373, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9367, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9360, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9353, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9346, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9339, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9332, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9325, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9318, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9312, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9305, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9298, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9291, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9285, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9278, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9271, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9264, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9258, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9251, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9238, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9231, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9224, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9218, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9211, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9204, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9198, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9191, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9185, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9178, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9171, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9165, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9158, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9152, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9145, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9139, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9132, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9126, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9119, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9113, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9106, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9100, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9093, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9087, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9081, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9074, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9068, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9061, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9055, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9049, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9042, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9036, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9030, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9023, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9016, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9010, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.9003, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8997, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8990, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8983, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8977, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8970, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8963, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8957, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8950, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8944, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8937, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8931, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8925, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8918, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8912, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8899, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8892, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8886, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8879, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8873, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8866, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8860, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8854, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8847, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8841, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8834, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8822, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8816, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8803, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8797, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8791, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8785, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8778, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8772, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8766, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8760, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8754, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8748, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8742, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8736, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8730, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8724, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8718, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8712, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8706, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8700, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8694, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8688, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8682, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8676, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8670, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8664, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8658, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8652, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8646, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8641, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8635, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8629, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8623, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8617, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8611, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8606, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8600, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8594, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8588, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8582, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8577, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8571, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8565, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8559, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8554, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8548, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8542, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8536, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8531, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8525, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8519, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8514, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8508, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8502, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8497, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8491, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8485, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8480, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8474, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8469, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8463, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8457, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8451, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8444, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8438, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8432, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8426, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8420, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8414, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8402, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8396, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8390, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8385, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8373, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8367, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8361, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8356, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8350, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8344, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8338, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8332, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8327, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8321, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8315, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8310, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8304, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8298, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8293, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8287, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8281, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8276, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8270, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8264, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8259, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8253, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8247, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8242, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8236, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8231, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8225, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8219, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8214, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8208, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8203, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8197, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8192, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8186, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8181, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8175, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8170, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8164, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8157, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8151, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8145, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8140, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8133, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8127, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8121, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8115, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8110, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8104, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8098, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8093, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8088, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8082, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8077, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8071, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8065, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8060, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8054, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8049, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8043, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8038, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8032, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8027, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8021, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8016, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8010, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.8005, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7999, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7994, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7988, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7983, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7978, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7972, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7968, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7962, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7957, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7951, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7946, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7941, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7936, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7930, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7925, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7915, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7909, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7899, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7894, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7888, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7883, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7878, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7873, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7868, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7863, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7858, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7853, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7847, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7843, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7838, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7833, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7823, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7818, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7813, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7808, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7803, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7799, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7793, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7789, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7784, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7779, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7774, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7770, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7764, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7759, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7753, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7748, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7742, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7737, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7730, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7725, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7719, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7714, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7708, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7702, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7697, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7690, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7685, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7679, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7674, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7669, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7664, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7659, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7654, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7648, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7643, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7638, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7632, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7627, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7621, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7617, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7611, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7606, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7601, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7596, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7591, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7585, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7580, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7575, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7570, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7565, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7560, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7555, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7550, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7544, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7539, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7535, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7529, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7524, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7519, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7515, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7510, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7504, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7500, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7494, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7490, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7484, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7480, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7475, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7470, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7465, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7460, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7455, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7451, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7446, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7441, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7436, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7432, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7427, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7422, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7417, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7413, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7403, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7398, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7393, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7389, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7380, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7375, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7370, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7366, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7361, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7356, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7352, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7347, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7343, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7338, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7333, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7329, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7324, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7320, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7315, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7311, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7306, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7302, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7297, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7293, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7288, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7284, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7279, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7275, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7270, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7266, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7261, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7257, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7252, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7248, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7239, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7235, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7230, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7226, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7222, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7217, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7213, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7209, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7204, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7200, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7196, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7191, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7187, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7183, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7178, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7173, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7168, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7163, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7158, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7153, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7148, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7143, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7138, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7133, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7128, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7124, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7119, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7115, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7110, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7105, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7101, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7096, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7092, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7087, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7083, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7078, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7073, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7069, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7064, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7060, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7055, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7051, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7046, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7041, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7037, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7032, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7028, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7024, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7019, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7015, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7010, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7006, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.7002, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6997, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6993, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6988, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6984, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6980, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6975, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6967, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6962, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6958, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6954, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6950, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6945, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6941, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6937, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6933, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6928, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6924, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6916, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6912, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6907, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6903, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6899, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6895, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6891, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6887, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6882, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6878, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6870, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6866, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6862, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6858, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6854, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6850, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6845, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6841, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6837, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6834, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6829, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6826, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6818, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6813, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6805, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6801, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6798, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6793, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6790, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6786, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6782, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6777, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6774, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6769, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6766, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6762, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6758, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6754, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6749, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6746, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6742, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6738, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6734, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6730, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6723, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6719, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6715, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6710, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6709, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6703, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6701, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6695, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6694, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6688, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6685, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6679, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6679, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6672, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6670, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6664, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6661, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6658, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6653, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6650, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6646, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6642, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6638, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6634, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6631, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6627, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6624, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6620, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6616, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6613, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6608, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6604, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6601, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6596, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6594, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6588, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6584, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6580, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6576, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6572, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6567, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6563, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6559, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6555, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6551, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6548, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6544, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6540, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6537, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6532, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6530, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6524, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6524, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6516, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6514, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6509, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6505, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6501, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6497, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6494, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6490, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6482, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6478, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6474, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6471, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6467, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6463, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6460, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6456, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6452, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6450, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6445, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6437, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6438, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6430, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6431, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6423, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6425, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6417, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6417, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6410, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6409, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6403, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6401, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6396, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6393, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6389, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6385, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6374, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6370, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6366, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6364, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6360, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6357, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6352, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6349, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6345, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6342, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6338, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6334, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6331, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6327, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6324, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6321, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6317, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6314, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6310, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6307, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6304, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6301, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6297, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6294, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6290, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6287, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6284, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6281, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6277, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6274, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6270, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6267, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6263, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6260, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6257, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6255, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6251, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6248, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6241, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6237, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6234, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6231, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6228, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6224, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6221, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6218, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6215, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6211, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6208, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6205, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6203, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6199, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6196, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6194, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6190, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6188, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6183, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6182, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6177, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6176, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6170, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6169, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6164, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6162, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6158, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6154, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6152, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6148, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6146, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6142, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6139, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6136, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6132, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6130, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6126, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6124, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6120, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6117, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6114, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6111, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6108, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6105, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6102, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6099, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6096, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6093, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6090, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6087, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6084, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6080, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6078, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6075, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6072, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6068, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6066, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6063, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6060, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6057, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6053, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6050, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6047, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6044, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6040, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6037, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6033, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6030, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6026, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6023, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6020, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6017, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6014, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6011, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6008, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6004, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.6002, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5998, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5996, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5992, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5990, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5986, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5983, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5980, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5977, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5973, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5967, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5965, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5961, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5958, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5955, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5952, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5949, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5948, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5943, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5941, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5937, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5935, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5931, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5929, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5926, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5923, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5917, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5914, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5911, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5908, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5902, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5899, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5896, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5893, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5891, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5889, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5886, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5882, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5880, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5876, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5871, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5868, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5865, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5862, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5860, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5857, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5855, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5851, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5846, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5844, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5840, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5838, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5835, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5832, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5829, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5826, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5824, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5818, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5815, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5813, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5807, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5805, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5799, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5796, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5794, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5791, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5788, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5786, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5783, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5780, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5777, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5775, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5772, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5769, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5767, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5764, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5762, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5759, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5756, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5754, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5751, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5748, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5746, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5743, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5740, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5738, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5735, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5733, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5730, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5723, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5720, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5717, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5713, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5711, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5708, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5706, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5702, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5700, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5697, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5695, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5691, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5690, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5685, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5683, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5680, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5677, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5674, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5672, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5669, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5666, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5663, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5661, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5658, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5655, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5654, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5650, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5648, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5645, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5643, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5640, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5638, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5634, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5633, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5630, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5628, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5624, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5623, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5619, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5617, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5614, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5611, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5609, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5606, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5604, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5601, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5598, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5596, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5593, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5591, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5588, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5586, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5583, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5580, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5578, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5575, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5573, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5570, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5568, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5565, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5563, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5560, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5558, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5555, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5553, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5550, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5548, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5545, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5543, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5540, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5537, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5534, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5532, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5529, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5526, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5523, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5520, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5518, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5515, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5513, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5510, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5508, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5505, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5502, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5500, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5497, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5494, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5492, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5489, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5487, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5484, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5481, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5479, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5476, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5474, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5471, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5468, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5466, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5463, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5461, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5458, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5456, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5453, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5450, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5448, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5445, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5440, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5438, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5435, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5433, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5430, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5428, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5425, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5423, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5420, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5418, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5415, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5413, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5410, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5405, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5403, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5400, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5398, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5396, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5393, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5391, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5388, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5386, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5376, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5374, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5371, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5369, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5366, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5364, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5362, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5359, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5357, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5354, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5352, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5350, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5347, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5345, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5342, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5340, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5337, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5334, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5332, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5330, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5327, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5325, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5322, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5320, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5317, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5315, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5312, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5310, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5307, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5305, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5302, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5300, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5298, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5295, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5293, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5290, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5288, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5285, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5283, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5281, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5278, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5276, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5273, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5271, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5268, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5266, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5264, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5261, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5259, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5256, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5254, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5252, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5249, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5246, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5243, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5240, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5237, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5233, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5230, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5227, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5224, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5221, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5218, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5215, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5212, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5209, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5207, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5204, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5201, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5199, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5196, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5193, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5191, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5188, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5185, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5182, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5180, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5177, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5174, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5171, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5169, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5163, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5160, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5158, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5155, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5153, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5150, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5147, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5145, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5142, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5140, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5137, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5134, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5132, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5129, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5127, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5124, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5122, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5119, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5116, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5114, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5111, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5109, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5106, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5104, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5101, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5099, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5096, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5094, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5091, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5089, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5087, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5084, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5082, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5079, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5077, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5074, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5072, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5069, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5067, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5065, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5062, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5060, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5057, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5055, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5053, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5050, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5048, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5045, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5043, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5041, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5038, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5036, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5033, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5031, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5029, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5026, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5024, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5022, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5019, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5017, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5012, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5009, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5004, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.5003, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4997, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4997, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4992, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4993, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4988, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4987, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4984, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4981, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4979, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4974, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4972, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4968, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4966, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4963, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4960, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4958, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4956, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4954, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4951, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4947, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4944, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4942, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4939, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4937, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4934, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4931, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4929, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4926, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4923, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4921, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4918, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4916, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4913, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4910, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4908, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4903, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4900, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4898, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4895, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4892, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4890, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4887, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4885, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4882, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4880, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4877, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4875, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4872, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4869, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4867, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4864, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4862, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4859, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4857, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4854, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4852, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4847, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4844, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4841, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4839, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4836, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4834, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4831, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4829, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4826, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4824, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4819, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4816, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4814, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4806, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4804, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4801, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4799, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4796, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4793, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4791, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4788, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4786, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4783, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4781, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4779, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4776, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4774, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4771, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4769, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4766, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4764, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4761, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4759, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4756, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4754, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4751, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4749, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4746, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4744, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4741, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4739, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4737, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4734, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4732, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4729, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4727, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4724, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4722, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4720, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4717, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4715, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4712, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4710, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4707, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4705, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4703, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4701, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4698, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4696, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4693, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4691, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4688, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4686, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4684, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4681, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4679, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4676, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4674, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4672, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4669, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4667, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4664, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4662, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4660, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4657, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4655, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4653, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4650, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4648, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4646, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4644, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4641, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4638, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4636, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4634, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4631, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4629, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4626, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4624, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4622, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4619, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4617, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4614, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4612, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4610, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4607, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4605, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4603, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4600, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4598, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4595, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4593, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4591, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4588, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4586, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4583, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4581, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4579, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4576, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4574, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4572, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4569, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4567, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4564, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4562, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4560, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4557, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4555, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4553, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4550, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4548, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4546, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4543, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4541, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4539, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4536, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4534, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4532, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4530, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4527, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4525, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4523, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4520, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4518, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4516, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4513, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4511, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4509, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4506, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4504, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4502, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4500, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4497, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4495, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4493, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4490, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4488, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4483, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4481, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4479, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4476, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4474, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4471, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4469, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4466, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4464, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4461, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4459, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4457, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4454, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4452, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4450, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4447, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4445, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4440, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4438, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4435, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4433, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4431, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4428, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4426, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4424, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4421, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4419, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4417, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4414, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4412, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4410, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4407, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4405, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4403, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4400, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4398, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4396, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4393, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4391, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4389, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4387, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4380, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4377, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4375, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4373, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4371, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4368, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4366, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4364, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4362, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4359, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4357, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4355, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4353, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4350, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4348, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4346, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4344, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4341, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4339, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4337, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4335, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4332, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4330, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4328, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4326, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4324, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4321, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4319, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4317, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4315, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4313, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4310, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4308, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4306, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4304, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4302, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4299, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4297, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4295, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4293, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4291, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4289, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4286, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4284, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4282, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4280, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4278, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4276, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4273, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4271, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4269, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4267, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4265, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4263, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4261, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4259, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4256, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4254, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4252, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4250, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4248, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4246, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4242, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4239, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4237, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4235, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4233, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4231, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4229, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4227, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4225, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4223, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4220, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4218, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4216, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4214, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4212, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4210, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4208, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4206, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4204, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4202, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4200, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4197, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4195, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4193, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4191, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4189, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4187, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4185, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4183, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4181, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4179, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4177, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4175, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4173, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4171, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4168, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4164, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4162, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4160, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4158, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4156, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4154, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4152, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4150, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4148, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4146, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4144, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4142, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4140, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4138, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4136, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4134, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4132, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4130, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4128, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4126, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4124, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4122, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4120, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4118, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4116, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4114, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4112, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4110, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4107, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4106, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4104, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4101, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4100, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4098, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4096, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4093, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4092, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4090, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4087, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4086, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4084, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4082, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4080, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4078, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4076, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4074, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4072, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4070, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4068, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4066, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4064, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4062, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4060, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4058, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4056, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4054, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4052, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4050, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4048, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4046, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4044, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4042, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4040, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4038, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4036, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4034, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4032, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4030, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4028, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4026, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4025, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4023, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4021, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4019, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4017, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4015, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4013, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4011, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4009, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4007, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4005, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4003, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.4001, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3999, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3998, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3996, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3994, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3992, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3990, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3988, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3986, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3984, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3982, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3980, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3978, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3976, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3975, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3973, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3969, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3967, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3965, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3963, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3961, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3959, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3957, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3956, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3954, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3952, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3950, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3948, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3946, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3944, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3942, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3940, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3939, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3937, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3935, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3933, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3931, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3929, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3927, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3926, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3924, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3922, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3918, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3916, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3914, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3912, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3911, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3909, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3907, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3903, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3901, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3900, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3898, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3896, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3894, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3892, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3890, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3888, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3887, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3885, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3883, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3881, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3879, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3877, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3876, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3872, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3870, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3868, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3866, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3865, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3863, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3861, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3859, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3857, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3856, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3854, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3852, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3850, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3848, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3847, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3845, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3843, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3841, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3839, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3837, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3836, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3834, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3832, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3830, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3827, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3825, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3823, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3820, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3818, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3816, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3814, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3812, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3807, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3805, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3803, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3800, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3798, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3796, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3795, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3793, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3791, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3790, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3788, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3786, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3784, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3783, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3781, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3779, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3777, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3775, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3774, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3772, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3770, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3768, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3767, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3765, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3763, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3762, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3760, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3758, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3756, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3755, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3753, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3751, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3749, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3748, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3746, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3744, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3743, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3741, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3739, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3737, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3736, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3734, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3732, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3731, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3729, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3727, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3724, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3722, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3721, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3719, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3717, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3716, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3714, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3712, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3711, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3709, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3707, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3706, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3704, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3702, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3701, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3699, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3698, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3696, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3694, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3693, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3691, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3690, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3688, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3686, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3685, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3683, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3681, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3680, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3678, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3677, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3675, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3673, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3672, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3670, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3669, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3667, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3665, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3664, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3662, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3661, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3659, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3658, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3656, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3654, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3653, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3651, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3650, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3648, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3646, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3645, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3643, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3642, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3640, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3639, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3637, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3635, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3634, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3632, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3631, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3629, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3628, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3626, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3625, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3623, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3622, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3620, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3618, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3617, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3615, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3614, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3612, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3611, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3609, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3608, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3606, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3605, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3603, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3601, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3600, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3598, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3597, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3595, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3594, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3592, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3591, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3589, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3588, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3586, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3585, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3583, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3582, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3580, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3579, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3577, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3575, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3574, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3572, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3571, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3569, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3568, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3566, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3565, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3563, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3562, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3560, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3559, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3557, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3556, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3554, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3553, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3551, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3550, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3548, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3547, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3545, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3544, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3542, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3541, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3539, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3538, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3536, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3535, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3533, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3532, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3530, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3529, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3527, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3526, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3524, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3523, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3522, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3520, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3519, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3517, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3516, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3514, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3513, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3511, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3510, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3508, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3507, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3505, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3504, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3502, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3501, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3499, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3498, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3497, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3495, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3494, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3492, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3491, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3489, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3488, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3485, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3483, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3482, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3480, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3479, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3478, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3476, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3475, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3473, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3472, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3470, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3469, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3467, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3466, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3465, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3463, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3462, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3460, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3459, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3457, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3456, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3455, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3453, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3452, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3450, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3449, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3447, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3446, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3445, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3442, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3440, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3439, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3437, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3436, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3435, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3433, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3432, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3430, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3429, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3427, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3426, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3425, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3423, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3422, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3420, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3419, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3418, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3416, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3415, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3414, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3412, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3411, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3409, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3406, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3405, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3404, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3402, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3401, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3400, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3398, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3397, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3395, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3394, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3393, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3391, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3390, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3389, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3387, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3386, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3385, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3376, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3375, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3374, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3372, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3371, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3370, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3369, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3367, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3366, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3364, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3363, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3362, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3360, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3359, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3358, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3357, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3355, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3354, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3353, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3351, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3350, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3349, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3347, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3346, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3345, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3343, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3342, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3341, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3339, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3338, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3337, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3336, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3334, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3333, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3332, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3330, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3329, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3328, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3326, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3325, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3324, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3323, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3321, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3320, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3319, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3317, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3316, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3315, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3314, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3312, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3311, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3310, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3308, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3307, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3306, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3305, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3303, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3302, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3301, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3300, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3298, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3297, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3296, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3294, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3293, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3292, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3291, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3289, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3288, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3287, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3285, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3284, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3283, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3282, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3280, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3279, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3278, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3277, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3275, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3274, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3273, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3272, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3270, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3269, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3268, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3267, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3265, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3264, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3263, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3262, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3260, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3259, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3258, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3257, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3255, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3254, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3253, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3252, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3250, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3249, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3248, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3247, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3245, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3243, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3242, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3240, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3239, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3238, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3237, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3235, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3234, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3233, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3231, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3229, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3228, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3227, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3226, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3224, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3223, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3222, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3221, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3219, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3218, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3217, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3216, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3215, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3213, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3212, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3211, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3210, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3208, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3207, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3206, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3205, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3204, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3202, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3201, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3200, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3199, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3197, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3196, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3195, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3194, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3193, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3191, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3190, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3189, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3188, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3187, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3185, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3184, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3183, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3182, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3180, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3179, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3178, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3177, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3176, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3175, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3173, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3172, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3171, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3170, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3169, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3167, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3165, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3164, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3163, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3161, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3160, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3159, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3158, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3157, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3155, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3154, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3153, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3152, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3151, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3150, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3148, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3147, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3146, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3145, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3144, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3142, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3141, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3140, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3139, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3138, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3137, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3135, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3134, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3133, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3132, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3131, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3129, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3128, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3127, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3126, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3125, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3124, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3122, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3121, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3120, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3119, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3118, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3117, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3115, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3114, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3113, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3112, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3111, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3110, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3109, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3107, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3106, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3105, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3104, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3103, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3102, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3100, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3099, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3098, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3097, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3096, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3095, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3094, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3092, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3092, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3090, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3089, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3088, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3087, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3086, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3085, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3083, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3083, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3081, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3081, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3079, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3078, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3077, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3075, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3074, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3073, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3072, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3071, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3070, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3069, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3068, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3067, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3065, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3065, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3063, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3062, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3061, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3060, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3059, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3058, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3057, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3056, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3054, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3053, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3052, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3051, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3050, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3049, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3048, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3047, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3046, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3045, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3044, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3043, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3042, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3040, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3040, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3038, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3038, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3036, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3035, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3034, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3033, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3032, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3031, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3030, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3029, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3028, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3027, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3025, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3025, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3023, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3023, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3021, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3021, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3019, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3019, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3017, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3017, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3015, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3015, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3013, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3013, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3011, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3010, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3008, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3008, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3007, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3006, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3005, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3004, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3002, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3002, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3000, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.3000, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2998, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2998, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2996, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2996, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2994, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2994, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2992, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2992, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2990, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2990, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2988, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2987, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2986, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2985, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2984, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2983, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2982, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2981, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2980, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2979, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2978, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2977, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2976, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2975, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2974, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2973, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2972, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2969, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2969, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2968, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2967, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2965, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2966, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2964, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2963, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2961, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2962, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2960, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2959, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2957, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2958, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2955, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2955, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2953, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2952, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2952, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2951, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2950, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2949, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2948, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2947, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2946, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2944, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2944, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2942, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2941, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2940, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2939, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2938, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2937, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2936, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2936, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2935, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2933, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2933, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2931, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2931, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2930, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2929, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2928, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2927, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2926, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2925, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2924, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2923, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2922, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2921, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2919, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2918, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2917, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2916, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2915, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2914, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2913, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2912, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2911, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2910, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2909, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2908, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2907, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2906, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2904, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2903, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2902, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2901, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2900, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2899, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2898, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2897, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2896, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2895, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2894, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2894, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2893, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2891, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2891, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2890, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2889, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2888, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2887, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2886, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2885, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2884, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2883, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2882, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2881, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2880, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2879, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2878, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2877, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2876, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2875, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2873, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2872, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2871, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2871, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2869, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2869, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2868, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2867, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2866, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2865, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2864, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2863, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2862, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2861, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2861, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2859, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2859, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2857, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2857, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2855, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2855, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2854, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2853, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2852, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2851, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2850, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2848, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2847, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2846, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2845, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2844, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2843, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2842, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2842, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2840, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2840, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2839, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2838, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2837, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2836, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2835, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2834, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2833, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2832, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2831, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2830, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2829, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2827, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2826, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2826, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2825, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2824, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2823, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2822, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2820, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2819, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2818, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2817, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2817, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2815, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2815, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2814, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2813, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2812, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2808, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2807, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2807, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2806, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2805, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2804, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2803, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2801, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2801, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2799, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2799, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2798, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2797, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2796, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2795, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2794, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2793, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2792, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2791, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2790, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2789, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2788, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2787, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2786, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2785, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2784, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2783, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2782, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2781, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2780, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2779, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2778, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2777, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2776, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2776, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2775, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2774, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2773, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2772, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2771, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2770, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2769, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2768, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2767, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2766, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2765, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2764, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2764, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2763, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2762, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2761, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2760, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2759, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2758, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2757, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2756, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2755, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2754, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2753, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2752, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2751, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2750, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2749, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2748, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2747, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2747, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2746, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2745, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2744, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2743, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2742, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2741, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2740, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2739, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2738, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2737, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2737, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2736, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2735, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2734, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2733, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2732, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2731, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2730, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2729, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2728, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2727, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2725, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2724, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2723, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2722, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2721, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2720, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2719, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2718, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2717, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2716, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2715, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2714, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2714, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2713, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2712, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2711, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2710, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2709, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2708, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2707, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2706, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2705, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2705, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2703, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2703, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2702, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2701, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2700, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2699, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2698, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2697, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2696, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2695, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2695, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2694, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2693, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2692, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2691, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2690, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2689, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2688, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2687, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2686, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2686, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2685, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2684, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2683, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2682, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2681, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2680, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2679, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2678, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2678, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2677, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2676, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2675, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2674, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2673, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2672, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2672, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2670, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2670, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2669, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2668, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2667, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2666, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2665, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2664, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2664, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2663, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2662, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2661, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2660, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2659, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2658, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2657, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2656, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2656, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2655, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2654, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2653, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2652, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2651, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2650, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2650, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2649, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2648, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2647, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2646, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2645, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2644, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2644, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2643, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2642, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2641, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2640, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2639, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2638, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2637, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2637, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2636, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2635, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2634, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2633, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2632, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2631, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2630, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2630, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2629, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2628, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2627, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2626, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2626, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2624, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2624, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2623, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2622, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2621, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2620, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2620, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2618, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2618, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2617, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2617, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2615, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2615, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2613, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2613, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2612, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2611, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2610, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2609, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2608, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2607, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2607, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2606, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2605, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2604, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2603, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2602, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2601, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2601, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2600, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2599, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2598, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2597, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2597, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2595, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2594, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2593, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2592, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2591, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2590, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2590, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2589, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2588, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2587, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2586, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2585, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2584, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2583, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2582, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2581, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2580, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2579, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2578, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2578, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2577, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2576, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2575, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2574, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2573, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2572, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2571, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2570, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2569, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2568, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2567, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2566, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2566, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2565, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2564, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2563, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2562, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2561, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2560, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2559, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2558, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2557, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2556, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2556, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2555, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2554, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2553, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2552, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2551, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2550, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2549, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2548, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2548, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2547, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2546, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2545, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2544, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2543, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2542, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2541, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2540, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2539, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2539, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2538, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2537, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2536, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2535, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2534, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2533, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2532, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2531, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2531, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2530, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2529, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2528, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2527, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2526, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2525, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2524, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2524, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2523, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2522, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2521, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2520, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2519, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2518, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2517, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2516, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2516, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2515, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2514, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2513, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2512, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2511, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2510, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2509, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2509, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2508, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2507, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2506, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2505, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2504, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2503, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2502, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2502, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2501, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2500, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2499, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2498, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2497, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2496, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2496, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2495, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2494, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2493, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2492, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2491, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2490, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2489, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2489, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2488, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2487, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2485, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2484, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2483, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2483, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2482, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2481, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2480, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2479, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2478, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2477, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2477, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2476, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2475, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2474, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2473, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2472, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2472, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2471, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2470, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2469, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2468, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2467, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2466, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2466, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2465, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2464, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2463, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2462, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2461, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2460, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2460, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2459, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2458, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2457, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2456, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2455, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2455, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2454, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2453, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2452, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2451, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2450, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2450, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2449, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2448, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2447, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2446, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2445, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2444, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2444, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2442, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2441, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2440, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2439, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2439, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2438, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2437, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2436, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2435, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2434, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2434, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2433, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2432, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2431, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2430, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2430, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2429, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2428, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2427, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2426, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2425, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2425, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2424, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2423, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2422, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2421, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2420, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2419, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2419, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2418, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2417, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2416, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2415, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2414, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2413, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2412, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2411, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2411, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2410, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2409, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2407, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2406, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2406, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2405, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2404, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2403, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2402, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2401, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2400, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2400, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2399, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2398, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2397, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2396, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2395, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2394, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2394, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2393, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2392, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2391, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2390, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2389, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2389, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2388, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2387, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2386, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2385, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2380, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2377, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2376, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2375, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2374, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2373, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2372, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2372, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2371, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2370, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2369, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2368, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2367, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2367, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2366, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2365, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2364, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2363, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2362, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2362, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2361, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2360, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2359, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2358, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2358, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2357, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2356, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2355, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2354, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2353, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2353, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2352, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2351, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2350, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2349, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2348, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2348, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2347, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2346, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2345, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2344, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2343, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2343, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2342, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2341, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2340, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2339, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2339, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2338, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2337, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2336, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2335, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2335, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2334, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2333, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2332, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2331, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2331, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2330, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2329, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2328, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2327, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2326, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2326, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2325, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2324, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2323, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2322, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2322, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2321, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2320, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2319, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2318, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2318, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2317, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2316, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2315, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2314, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2314, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2313, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2312, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2311, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2310, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2310, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2309, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2308, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2307, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2306, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2306, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2305, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2304, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2303, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2302, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2302, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2301, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2300, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2299, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2298, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2298, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2297, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2296, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2295, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2295, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2294, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2293, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2292, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2291, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2291, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2290, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2289, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2288, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2287, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2287, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2286, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2285, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2284, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2283, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2283, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2282, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2281, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2280, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2280, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2279, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2278, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2277, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2276, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2276, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2275, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2274, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2273, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2273, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2272, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2271, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2270, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2269, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2269, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2268, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2267, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2266, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2266, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2265, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2264, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2263, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2262, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2262, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2261, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2260, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2259, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2259, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2258, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2257, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2256, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2256, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2255, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2254, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2253, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2253, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2252, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2251, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2250, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2249, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2249, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2248, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2247, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2246, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2246, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2245, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2243, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2243, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2242, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2241, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2240, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2240, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2239, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2238, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2237, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2237, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2236, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2235, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2234, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2234, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2233, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2231, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2230, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2230, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2229, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2228, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2227, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2227, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2226, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2225, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2224, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2224, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2223, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2222, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2221, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2221, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2220, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2219, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2218, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2218, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2217, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2216, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2215, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2215, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2214, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2213, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2212, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2212, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2211, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2210, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2209, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2209, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2208, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2207, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2206, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2206, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2205, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2204, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2203, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2203, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2202, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2201, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2200, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2200, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2199, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2198, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2197, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2197, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2196, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2195, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2194, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2194, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2193, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2192, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2191, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2191, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2190, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2189, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2188, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2188, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2187, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2186, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2185, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2185, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2184, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2183, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2183, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2182, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2181, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2180, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2180, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2179, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2178, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2177, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2177, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2176, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2175, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2174, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2174, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2173, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2172, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2172, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2171, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2170, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2169, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2169, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2168, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2167, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2165, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2164, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2164, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2163, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2162, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2161, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2161, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2160, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2159, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2158, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2158, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2157, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2156, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2156, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2155, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2154, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2153, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2153, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2152, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2151, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2151, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2150, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2149, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2148, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2148, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2147, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2146, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2146, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2145, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2144, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2143, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2143, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2142, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2141, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2141, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2140, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2139, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2138, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2138, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2137, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2136, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2136, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2135, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2134, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2133, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2133, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2132, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2131, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2131, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2130, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2129, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2129, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2128, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2127, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2126, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2126, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2125, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2124, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2124, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2123, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2122, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2122, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2121, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2120, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2119, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2119, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2118, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2117, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2117, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2116, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2115, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2115, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2114, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2113, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2112, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2112, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2111, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2110, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2110, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2109, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2108, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2108, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2107, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2106, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2106, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2105, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2104, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2104, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2103, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2102, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2101, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2101, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2100, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2099, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2099, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2098, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2097, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2097, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2096, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2095, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2095, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2094, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2093, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2093, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2092, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2092, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2091, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2090, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2089, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2089, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2088, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2087, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2086, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2086, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2085, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2084, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2084, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2083, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2082, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2081, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2081, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2080, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2080, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2079, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2078, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2078, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2077, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2076, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2075, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2075, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2074, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2074, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2073, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2072, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2072, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2071, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2070, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2070, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2069, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2068, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2067, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2067, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2066, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2066, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2065, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2064, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2064, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2063, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2062, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2061, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2061, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2060, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2060, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2059, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2058, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2058, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2057, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2056, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2055, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2055, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2054, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2054, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2053, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2052, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2052, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2051, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2050, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2050, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2049, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2048, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2048, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2047, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2046, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2046, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2045, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2044, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2044, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2043, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2042, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2042, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2041, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2040, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2040, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2039, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2038, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2038, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2037, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2037, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2036, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2035, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2035, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2034, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2033, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2033, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2032, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2031, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2031, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2031, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2029, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2030, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2028, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2028, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2027, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2026, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2026, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2025, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2025, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2024, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2023, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2023, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2022, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2021, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2021, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2020, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2019, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2019, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2018, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2017, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2017, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2016, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2016, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2015, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2014, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2014, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2013, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2013, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2012, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2011, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2011, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2010, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2009, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2009, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2008, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2008, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2007, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2006, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2006, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2005, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2004, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2004, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2003, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2003, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2002, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2002, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2001, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2000, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.2000, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1999, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1999, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1998, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1997, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1997, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1996, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1996, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1995, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1994, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1994, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1993, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1993, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1992, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1991, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1991, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1990, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1990, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1989, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1988, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1988, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1987, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1987, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1986, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1985, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1985, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1984, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1984, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1983, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1983, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1982, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1981, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1981, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1980, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1980, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1979, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1978, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1978, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1977, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1977, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1976, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1976, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1975, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1974, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1974, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1973, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1973, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1972, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1970, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1970, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1969, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1969, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1968, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1967, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1967, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1966, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1966, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1965, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1964, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1964, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1963, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1963, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1962, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1962, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1961, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1960, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1960, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1959, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1959, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1958, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1958, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1957, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1956, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1956, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1955, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1955, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1954, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1954, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1953, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1952, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1952, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1951, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1951, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1950, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1950, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1949, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1948, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1948, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1947, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1947, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1946, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1946, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1945, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1944, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1944, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1943, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1943, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1942, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1942, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1941, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1941, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1940, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1939, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1939, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1938, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1938, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1937, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1937, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1936, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1935, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1935, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1934, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1934, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1933, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1933, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1932, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1932, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1931, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1930, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1930, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1929, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1929, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1928, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1928, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1927, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1927, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1926, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1925, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1925, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1924, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1924, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1923, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1923, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1922, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1922, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1921, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1919, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1919, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1918, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1918, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1917, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1917, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1916, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1915, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1915, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1914, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1914, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1913, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1913, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1912, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1912, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1911, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1911, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1910, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1909, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1909, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1908, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1908, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1907, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1907, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1906, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1906, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1904, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1903, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1903, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1902, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1902, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1901, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1901, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1900, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1900, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1899, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1899, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1898, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1898, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1897, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1896, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1896, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1895, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1895, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1894, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1894, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1893, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1893, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1892, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1892, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1891, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1890, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1890, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1889, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1889, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1888, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1888, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1887, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1887, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1886, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1886, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1885, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1885, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1884, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1884, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1883, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1883, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1882, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1881, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1881, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1880, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1880, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1879, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1879, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1878, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1878, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1877, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1877, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1876, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1876, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1875, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1875, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1873, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1873, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1872, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1872, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1871, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1871, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1870, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1870, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1869, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1869, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1868, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1868, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1867, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1867, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1866, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1866, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1865, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1865, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1864, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1864, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1863, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1862, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1862, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1861, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1861, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1860, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1860, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1859, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1859, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1858, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1858, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1857, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1857, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1856, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1856, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1855, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1855, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1854, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1854, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1853, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1853, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1852, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1852, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1851, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1851, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1850, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1850, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1848, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1848, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1847, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1846, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1846, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1845, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1845, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1844, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1844, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1843, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1843, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1842, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1842, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1841, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1841, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1840, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1840, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1839, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1839, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1838, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1838, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1837, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1837, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1836, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1836, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1835, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1835, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1834, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1834, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1833, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1833, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1832, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1832, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1831, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1831, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1830, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1830, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1829, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1829, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1827, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1827, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1826, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1826, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1825, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1825, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1824, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1824, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1823, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1823, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1822, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1822, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1820, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1820, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1819, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1819, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1818, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1818, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1817, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1817, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1816, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1816, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1815, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1815, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1814, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1814, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1813, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1813, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1812, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1812, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1808, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1808, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1807, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1807, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1806, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1806, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1805, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1805, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1804, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1804, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1804, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1803, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1801, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1801, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1800, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1800, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1799, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1799, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1798, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1798, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1797, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1797, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1796, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1796, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1795, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1795, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1794, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1794, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1793, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1793, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1792, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1792, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1791, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1791, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1790, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1789, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1789, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1788, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1787, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1786, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1785, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1785, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1784, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1784, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1783, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1783, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1782, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1781, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1781, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1780, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1780, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1779, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1778, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1778, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1777, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1777, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1776, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1776, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1775, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1775, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1774, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1773, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1773, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1772, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1772, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1771, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1771, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1770, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1769, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1769, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1768, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1768, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1767, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1767, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1766, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1766, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1765, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1765, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1764, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1763, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1763, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1762, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1762, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1761, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1761, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1760, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1760, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1759, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1759, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1758, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1758, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1757, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1756, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1756, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1755, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1755, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1754, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1754, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1753, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1753, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1752, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1752, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1751, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1751, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1750, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1750, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1749, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1749, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1748, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1748, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1747, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1746, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1746, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1745, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1745, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1744, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1744, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1743, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1743, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1742, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1742, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1741, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1741, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1740, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1740, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1739, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1739, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1738, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1738, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1737, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1737, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1736, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1736, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1735, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1735, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1734, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1734, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1733, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1732, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1732, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1731, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1731, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1730, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1730, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1729, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1729, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1728, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1728, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1727, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1727, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1726, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1725, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1725, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1724, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1724, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1723, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1723, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1722, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1722, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1721, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1721, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1720, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1720, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1719, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1719, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1718, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1718, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1717, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1717, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1716, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1716, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1715, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1715, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1714, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1714, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1713, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1713, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1712, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1712, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1711, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1711, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1710, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1710, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1709, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1709, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1708, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1708, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1707, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1707, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1706, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1706, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1705, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1705, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1704, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1704, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1703, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1703, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1702, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1702, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1701, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1701, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1700, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1700, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1699, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1699, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1698, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1698, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1697, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1697, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1696, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1696, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1695, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1695, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1694, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1694, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1693, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1693, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1692, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1692, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1691, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1691, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1690, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1690, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1689, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1689, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1688, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1688, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1688, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1687, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1687, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1686, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1685, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1685, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1684, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1683, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1682, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1682, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1681, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1681, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1680, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1680, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1679, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1679, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1678, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1677, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1677, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1676, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1676, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1675, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1675, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1674, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1674, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1673, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1673, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1672, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1672, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1671, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1670, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1670, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1669, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1669, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1668, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1668, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1667, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1667, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1666, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1665, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1665, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1664, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1664, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1663, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1663, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1662, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1662, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1661, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1661, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1660, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1660, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1659, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1659, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1658, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1657, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1657, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1656, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1656, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1655, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1655, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1654, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1654, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1653, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1653, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1652, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1652, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1651, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1650, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1650, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1649, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1649, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1648, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1648, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1647, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1647, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1646, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1646, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1645, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1645, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1644, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1644, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1643, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1642, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1642, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1641, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1641, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1640, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1640, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1639, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1639, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1638, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1638, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1637, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1637, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1636, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1636, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1635, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1635, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1634, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1634, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1633, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1633, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1632, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1632, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1631, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1631, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1630, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1630, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1629, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1629, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1628, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1627, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1627, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1626, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1626, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1625, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1625, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1624, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1624, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1623, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1623, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1622, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1622, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1621, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1621, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1620, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1620, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1619, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1619, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1618, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1618, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1617, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1616, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1616, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1616, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1615, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1615, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1614, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1614, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1613, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1612, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1612, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1611, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1611, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1610, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1610, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1609, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1609, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1608, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1608, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1607, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1607, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1607, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1606, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1605, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1605, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1604, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1604, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1603, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1603, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1602, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1602, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1601, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1601, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1600, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1600, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1599, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1599, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1598, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1598, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1597, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1597, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1596, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1596, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1596, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1595, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1595, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1594, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1593, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1593, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1592, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1592, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1591, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1591, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1590, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1590, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1589, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1589, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1588, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1588, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1587, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1587, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1586, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1586, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1585, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1585, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1584, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1584, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1584, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1583, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1582, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1582, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1581, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1581, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1580, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1580, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1580, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1579, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1579, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1578, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1578, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1577, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1577, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1576, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1576, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1575, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1575, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1574, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1574, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1573, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1573, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1572, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1572, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1571, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1571, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1570, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1570, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1569, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1569, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1568, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1568, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1567, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1567, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1566, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1566, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1565, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1565, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1564, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1564, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1564, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1563, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1562, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1562, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1562, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1561, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1561, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1560, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1560, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1559, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1559, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1558, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1558, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1557, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1557, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1556, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1556, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1555, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1555, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1554, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1554, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1554, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1553, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1552, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1552, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1552, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1551, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1551, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1550, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1550, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1549, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1549, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1548, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1548, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1547, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1547, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1547, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1546, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1546, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1546, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1545, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1546, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1544, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1544, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1543, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1543, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1543, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1542, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1542, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1541, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1541, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1540, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1540, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1539, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1538, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1539, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1537, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1538, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1536, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1536, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1536, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1535, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1535, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1534, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1534, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1534, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1533, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1534, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1532, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1533, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1531, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1532, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1531, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1530, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1530, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1529, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1530, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1528, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1528, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1528, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1527, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1527, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1526, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1526, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1525, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1524, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1525, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1524, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1524, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1523, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1523, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1523, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1521, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1522, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1521, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1521, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1520, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1520, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1519, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1518, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1519, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1518, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1518, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1517, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1517, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1516, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1516, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1515, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1515, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1514, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1514, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1514, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1513, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1513, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1512, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1512, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1511, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1511, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1510, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1510, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1510, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1509, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1509, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1508, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1508, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1507, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1507, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1507, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1506, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1506, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1506, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1505, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1505, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1504, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1504, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1503, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1503, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1503, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1502, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1502, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1501, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1501, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1501, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1500, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1500, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1499, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1499, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1499, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1498, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1498, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1497, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1497, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1496, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1496, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1496, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1495, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1495, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1494, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1494, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1494, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1493, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1493, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1492, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1492, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1492, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1491, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1491, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1490, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1490, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1490, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1489, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1489, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1488, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1488, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1488, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1487, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1487, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1487, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1486, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1485, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1485, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1485, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1484, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1484, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1483, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1483, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1483, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1482, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1482, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1481, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1481, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1481, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1480, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1480, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1479, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1479, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1479, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1478, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1478, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1477, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1477, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1477, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1476, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1476, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1475, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1475, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1475, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1474, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1474, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1473, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1473, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1473, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1472, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1472, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1472, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1471, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1471, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1470, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1470, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1470, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1469, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1469, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1468, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1468, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1468, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1467, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1467, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1466, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1466, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1466, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1465, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1465, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1465, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1464, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1464, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1463, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1463, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1463, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1462, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1462, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1461, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1461, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1461, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1460, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1460, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1460, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1459, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1459, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1458, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1458, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1458, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1457, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1457, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1457, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1456, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1456, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1455, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1455, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1455, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1454, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1454, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1453, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1453, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1453, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1452, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1452, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1452, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1451, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1451, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1450, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1450, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1450, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1449, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1449, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1449, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1448, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1448, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1447, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1447, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1447, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1446, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1446, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1446, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1445, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1445, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1444, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1444, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1444, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1443, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1442, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1442, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1441, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1441, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1441, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1440, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1440, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1440, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1439, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1439, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1438, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1438, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1438, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1437, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1437, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1437, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1436, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1436, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1436, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1435, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1435, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1434, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1434, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1434, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1433, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1433, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1433, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1432, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1432, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1431, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1431, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1431, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1430, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1430, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1430, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1429, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1429, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1429, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1428, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1428, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1427, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1427, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1427, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1426, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1426, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1426, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1425, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1425, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1425, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1424, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1424, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1423, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1423, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1423, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1422, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1422, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1422, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1421, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1421, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1420, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1420, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1420, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1419, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1419, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1419, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1418, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1418, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1418, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1417, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1417, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1417, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1416, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1416, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1415, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1415, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1415, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1414, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1414, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1414, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1413, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1413, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1413, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1412, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1412, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1412, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1411, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1411, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1410, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1410, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1410, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1409, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1409, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1409, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1408, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1407, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1407, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1407, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1406, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1406, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1405, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1405, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1405, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1404, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1404, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1404, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1403, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1403, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1403, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1402, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1402, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1402, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1401, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1401, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1401, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1400, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1400, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1400, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1399, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1399, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1398, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1398, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1398, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1397, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1397, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1397, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1396, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1396, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1396, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1395, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1395, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1395, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1394, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1394, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1394, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1393, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1393, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1393, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1392, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1392, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1391, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1391, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1391, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1390, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1390, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1390, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1389, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1389, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1389, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1388, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1388, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1388, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1387, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1387, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1387, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1386, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1386, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1386, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1385, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1385, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1385, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1384, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1383, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1382, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1381, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1380, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1380, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1379, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1378, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1377, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1377, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1377, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1376, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1376, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1376, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1375, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1375, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1375, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1374, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1374, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1374, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1373, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1373, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1373, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1372, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1372, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1372, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1371, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1371, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1371, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1370, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1370, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1370, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1369, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1369, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1369, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1368, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1368, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1368, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1367, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1367, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1367, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1366, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1366, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1366, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1365, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1365, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1365, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1364, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1364, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1364, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1363, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1363, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1363, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1362, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1362, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1362, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1361, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1361, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1361, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1360, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1360, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1360, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1359, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1359, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1359, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1358, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1358, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1358, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1357, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1357, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1357, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1356, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1356, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1356, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1356, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1355, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1355, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1355, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1354, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1354, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1354, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1353, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1353, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1353, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1352, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1352, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1352, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1351, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1351, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1351, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1350, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1350, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1350, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1349, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1349, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1349, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1348, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1348, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1348, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1347, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1347, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1347, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1346, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1346, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1346, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1345, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1345, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1345, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1344, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1344, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1344, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1344, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1343, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1343, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1343, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1342, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1342, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1342, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1341, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1341, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1341, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1340, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1340, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1340, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1339, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1339, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1339, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1338, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1338, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1338, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1337, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1337, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1337, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1336, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1336, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1336, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1336, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1335, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1335, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1335, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1334, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1334, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1334, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1333, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1333, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1333, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1332, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1332, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1332, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1332, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1332, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1331, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1331, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1330, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1330, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1328, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1323, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1322, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1319, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1316, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1308, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1307, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1307, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1307, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1304, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1303, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1305, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1306, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1303, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1301, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1301, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1300, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1299, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1297, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1297, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1297, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1296, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1295, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1295, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1295, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1294, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1293, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1292, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1292, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1291, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1290, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1289, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1289, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1288, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1288, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1287, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1287, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1286, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1286, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1285, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1284, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1284, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1283, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1283, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1282, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1282, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1281, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1281, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1280, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1280, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1279, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1279, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1278, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1277, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1277, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1276, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1276, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1275, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1275, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1274, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1274, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1274, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1273, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1273, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1272, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1271, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1271, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1270, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1270, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1269, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1269, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1268, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1268, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1267, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1267, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1267, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1266, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1265, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1265, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1264, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1264, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1263, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1263, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1263, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1262, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1262, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1261, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1261, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1260, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1260, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1259, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1259, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1258, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1258, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1257, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1257, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1256, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1256, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1255, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1255, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1254, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1254, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1253, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1253, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1252, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1252, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1251, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1251, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1251, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1250, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1250, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1249, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1249, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1248, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1248, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1247, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1247, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1246, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1246, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1245, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1245, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1244, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1243, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1243, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1242, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1242, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1242, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1241, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1241, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1240, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1240, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1239, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1239, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1238, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1238, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1237, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1237, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1236, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1236, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1235, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1235, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1234, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1234, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1233, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1233, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1232, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1231, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1231, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1230, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1230, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1229, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1229, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1228, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1228, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1227, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1227, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1226, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1226, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1226, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1225, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1225, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1224, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1224, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1223, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1223, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1222, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1222, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1221, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1221, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1220, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1220, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1220, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1219, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1219, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1218, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1218, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1217, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1217, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1216, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1216, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1215, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1215, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1215, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1214, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1214, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1213, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1213, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1212, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1212, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1211, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1211, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1210, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1210, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1210, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1209, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1209, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1208, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1208, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1207, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1207, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1206, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1206, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1205, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1205, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1205, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1204, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1204, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1203, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1203, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1202, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1202, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1201, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1201, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1200, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1200, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1200, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1199, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1199, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1198, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1198, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1197, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1197, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1197, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1196, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1196, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1195, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1195, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1195, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1194, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1193, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1193, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1193, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1192, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1192, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1191, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1191, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1190, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1190, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1189, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1189, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1189, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1188, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1188, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1187, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1187, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1186, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1186, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1185, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1185, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1185, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1184, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1184, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1183, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1183, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1182, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1182, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1181, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1181, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1181, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1180, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1180, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1179, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1179, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1178, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1178, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1178, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1177, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1177, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1176, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1176, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1175, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1175, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1174, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1174, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1174, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1173, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1173, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1172, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1172, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1171, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1171, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1171, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1170, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1170, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1169, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1169, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1168, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1168, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1168, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1167, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1167, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1166, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1165, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1165, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1164, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1164, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1163, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1163, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1162, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1162, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1162, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1161, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1161, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1160, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1160, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1160, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1159, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1159, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1158, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1158, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1158, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1157, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1157, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1156, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1156, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1156, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1155, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1155, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1154, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1154, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1154, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1153, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1153, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1152, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1152, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1151, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1151, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1151, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1150, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1150, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1149, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1149, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1148, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1148, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1148, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1147, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1147, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1147, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1146, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1146, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1145, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1145, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1145, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1144, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1144, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1143, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1143, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1142, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1142, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1142, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1141, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1141, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1141, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1140, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1140, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1139, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1139, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1139, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1138, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1138, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1137, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1137, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1137, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1136, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1136, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1136, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1135, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1135, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1134, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1134, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1133, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1133, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1133, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1132, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1132, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1132, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1131, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1131, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1130, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1130, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1130, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1129, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1129, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1128, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1128, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1128, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1127, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1127, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1126, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1126, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1126, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1125, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1125, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1125, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1124, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1124, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1123, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1123, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1123, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1122, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1122, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1121, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1121, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1121, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1120, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1120, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1120, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1119, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1119, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1118, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1118, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1118, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1117, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1117, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1116, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1116, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1116, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1115, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1115, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1115, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1114, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1114, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1113, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1113, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1113, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1112, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1112, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1112, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1111, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1111, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1110, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1110, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1110, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1109, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1109, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1109, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1108, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1108, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1107, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1107, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1107, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1106, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1106, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1106, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1105, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1105, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1104, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1104, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1104, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1103, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1103, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1103, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1102, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1102, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1102, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1101, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1101, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1100, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1100, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1100, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1099, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1099, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1098, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1098, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1098, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1097, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1097, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1097, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1096, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1096, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1096, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1095, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1095, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1094, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1094, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1094, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1093, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1093, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1093, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1092, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1092, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1091, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1091, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1091, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1090, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1090, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1090, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1089, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1089, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1089, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1088, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1088, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1087, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1087, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1087, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1086, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1086, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1086, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1085, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1085, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1085, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1084, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1084, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1084, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1083, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1083, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1082, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1082, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1082, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1081, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1081, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1081, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1080, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1080, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1080, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1079, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1079, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1078, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1078, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1078, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1077, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1077, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1077, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1076, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1076, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1076, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1075, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1075, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1075, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1074, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1074, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1073, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1073, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1073, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1072, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1072, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1072, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1071, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1071, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1071, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1070, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1070, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1070, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1069, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1069, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1068, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1068, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1068, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1067, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1067, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1067, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1066, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1066, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1066, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1065, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1065, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1065, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1064, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1064, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1064, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1063, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1063, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1062, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1062, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1062, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1061, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1061, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1061, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1060, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1060, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1060, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1059, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1059, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1059, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1058, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1058, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1058, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1057, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1057, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1057, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1056, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1056, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1056, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1055, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1055, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1054, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1054, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1054, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1053, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1053, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1053, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1052, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1052, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1052, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1051, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1051, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1051, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1050, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1050, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1050, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1049, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1049, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1049, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1048, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1048, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1048, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1047, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1047, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1047, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1046, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1046, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1046, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1045, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1045, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1045, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1044, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1044, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1044, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1043, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1043, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1043, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1042, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1042, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1042, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1041, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1041, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1040, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1040, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1040, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1039, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1039, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1039, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1038, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1038, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1038, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1037, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1037, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1037, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1036, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1036, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1036, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1035, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1035, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1035, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1034, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1034, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1034, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1033, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1033, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1033, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1032, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1032, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1032, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1031, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1031, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1031, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1030, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1030, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1030, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1029, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1029, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1029, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1028, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1028, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1028, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1027, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1027, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1027, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1026, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1026, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1026, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1025, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1025, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1025, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1024, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1024, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1024, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1023, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1023, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1023, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1022, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1022, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1022, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1021, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1021, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1021, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1020, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1020, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1020, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1019, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1019, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1019, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1018, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1018, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1018, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1018, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1017, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1017, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1017, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1016, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1016, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1016, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1015, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1015, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1015, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1014, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1014, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1014, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1013, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1013, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1013, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1012, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1012, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1012, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1011, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1011, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1011, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1010, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1010, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1010, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1009, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1009, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1009, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1008, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1008, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1008, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1008, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1007, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1007, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1007, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1006, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1006, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1006, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1005, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1005, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1005, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1004, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1004, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1004, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1003, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1003, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1003, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1002, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1002, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1002, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1001, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1001, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1001, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1000, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1000, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1000, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.1000, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0999, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0999, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0999, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0998, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0998, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0998, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0997, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0997, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0997, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0996, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0996, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0996, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0995, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0995, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0995, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0994, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0994, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0994, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0994, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0993, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0993, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0993, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0992, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0992, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0992, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0991, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0991, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0991, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0990, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0990, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0990, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0989, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0989, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0989, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0989, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0988, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0988, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0988, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0987, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0987, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0987, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0986, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0986, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0986, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0985, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0985, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0985, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0984, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0984, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0984, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0984, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0983, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0983, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0983, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0982, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0982, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0982, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0982, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0981, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0981, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0981, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0980, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0980, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0980, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0979, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0979, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0979, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0978, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0978, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0978, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0978, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0977, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0977, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0977, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0976, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0976, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0976, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0975, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0975, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0975, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0975, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0974, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0974, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0974, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0973, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0973, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0973, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0972, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0972, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0972, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0971, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0970, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0970, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0970, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0969, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0969, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0969, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0969, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0968, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0968, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0968, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0967, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0967, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0967, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0966, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0966, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0966, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0966, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0965, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0965, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0965, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0964, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0964, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0964, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0964, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0963, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0963, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0963, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0962, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0962, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0962, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0962, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0961, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0961, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0961, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0960, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0960, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0960, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0959, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0959, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0959, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0959, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0958, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0958, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0958, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0957, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0957, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0957, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0957, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0956, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0956, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0956, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0955, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0955, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0955, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0955, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0954, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0954, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0954, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0953, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0953, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0954, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0953, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0953, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0952, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0952, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0951, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0952, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0952, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0951, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0951, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0950, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0950, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0949, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0950, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0950, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0949, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0949, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0949, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0948, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0948, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0947, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0947, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0947, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0947, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0947, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0946, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0947, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0946, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0946, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0945, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0944, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0944, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0944, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0944, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0944, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0943, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0944, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0943, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0943, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0943, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0942, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0942, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0941, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0941, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0942, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0941, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0942, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0940, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0940, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0940, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0939, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0939, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0938, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0939, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0938, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0938, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0938, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0937, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0938, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0937, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0937, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0937, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0936, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0936, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0936, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0935, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0935, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0936, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0935, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0934, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0935, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0934, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0933, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0934, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0933, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0932, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0933, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0932, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0932, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0933, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0931, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0931, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0932, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0930, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0930, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0930, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0930, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0929, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0929, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0930, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0929, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0928, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0929, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0928, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0928, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0928, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0927, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0929, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0927, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0927, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0927, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0926, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0928, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0925, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0926, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0926, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0925, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0926, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0924, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0924, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0924, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0923, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0925, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0923, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0923, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0923, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0922, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0924, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0922, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0922, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0922, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0921, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0921, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0921, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0920, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0919, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0919, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0919, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0919, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0918, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0918, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0918, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0918, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0917, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0918, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0917, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0916, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0917, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0916, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0916, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0916, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0915, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0915, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0915, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0915, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0914, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0914, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0914, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0913, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0913, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0913, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0913, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0913, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0912, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0913, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0912, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0912, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0912, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0911, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0911, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0911, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0910, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0910, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0910, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0910, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0910, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0909, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0910, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0909, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0909, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0909, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0908, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0908, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0908, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0907, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0907, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0907, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0907, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0906, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0907, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0906, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0906, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0906, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0905, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0904, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0904, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0904, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0904, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0904, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0903, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0903, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0903, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0902, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0902, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0902, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0902, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0901, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0902, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0901, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0901, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0901, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0900, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0900, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0900, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0900, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0899, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0899, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0899, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0899, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0899, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0898, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0898, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0898, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0898, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0897, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0897, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0897, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0897, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0896, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0896, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0896, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0896, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0896, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0895, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0895, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0895, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0896, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0895, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0896, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0894, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0895, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0893, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0895, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0894, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0894, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0893, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0892, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0892, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0892, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0892, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0892, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0891, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0892, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0891, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0891, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0890, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0890, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0891, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0890, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0890, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0889, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0890, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0889, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0889, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0889, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0889, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0888, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0888, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0888, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0887, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0887, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0888, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0887, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0887, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0886, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0886, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0886, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0886, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0885, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0885, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0885, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0885, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0885, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0884, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0884, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0884, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0884, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0883, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0884, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0884, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0883, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0883, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0883, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0882, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0882, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0882, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0882, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0883, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0881, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0882, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0881, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0881, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0880, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0881, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0880, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0880, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0879, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0879, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0879, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0879, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0878, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0879, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0879, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0878, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0878, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0877, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0877, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0877, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0877, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0877, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0876, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0876, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0876, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0876, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0875, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0875, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0876, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0875, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0875, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0875, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0874, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0873, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0873, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0873, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0873, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0872, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0872, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0872, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0872, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0872, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0871, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0871, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0871, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0871, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0870, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0870, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0870, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0870, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0870, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0869, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0869, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0869, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0869, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0869, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0869, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0868, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0868, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0868, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0868, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0867, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0868, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0867, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0867, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0867, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0867, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0866, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0866, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0866, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0866, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0866, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0866, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0865, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0865, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0865, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0865, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0865, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0864, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0864, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0863, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0864, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0863, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0863, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0863, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0863, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0863, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0862, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0862, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0862, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0862, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0861, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0861, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0861, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0861, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0861, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0860, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0860, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0860, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0860, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0860, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0860, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0860, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0859, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0859, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0859, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0858, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0858, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0858, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0858, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0858, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0858, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0857, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0857, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0857, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0857, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0857, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0856, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0856, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0856, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0856, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0856, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0855, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0856, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0855, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0855, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0855, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0854, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0854, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0854, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0854, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0854, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0854, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0853, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0853, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0853, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0853, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0852, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0852, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0852, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0852, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0852, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0852, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0851, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0852, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0851, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0851, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0851, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0850, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0850, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0850, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0850, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0848, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0849, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0848, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0848, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0848, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0847, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0848, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0847, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0847, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0847, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0847, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0847, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0846, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0846, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0846, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0846, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0845, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0845, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0845, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0845, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0844, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0844, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0844, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0844, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0844, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0844, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0844, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0843, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0843, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0843, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0843, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0842, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0842, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0842, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0842, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0841, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0842, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0841, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0841, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0841, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0840, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0840, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0840, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0840, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0840, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0839, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0839, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0840, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0839, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0840, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0838, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0839, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0838, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0838, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0838, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0837, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0837, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0837, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0837, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0837, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0837, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0837, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0836, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0836, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0836, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0835, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0835, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0835, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0835, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0835, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0835, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0835, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0834, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0834, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0834, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0834, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0834, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0834, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0833, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0834, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0833, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0833, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0833, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0832, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0833, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0832, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0832, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0832, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0831, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0831, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0831, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0831, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0831, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0831, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0830, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0831, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0830, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0831, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0829, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0830, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0829, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0829, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0829, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0830, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0830, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0827, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0827, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0828, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0826, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0827, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0826, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0826, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0826, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0825, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0825, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0825, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0825, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0825, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0824, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0824, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0824, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0824, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0824, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0823, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0824, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0823, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0823, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0823, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0823, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0823, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0823, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0822, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0823, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0822, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0822, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0822, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0822, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0820, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0820, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0819, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0821, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0819, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0820, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0819, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0819, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0819, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0818, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0819, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0818, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0818, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0817, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0817, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0817, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0817, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0817, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0817, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0816, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0817, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0816, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0816, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0816, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0815, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0816, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0815, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0816, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0815, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0815, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0815, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0814, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0814, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0814, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0814, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0814, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0813, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0814, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0813, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0813, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0813, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0813, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0812, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0812, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0812, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0812, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0812, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0812, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0811, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0810, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0809, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0808, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0808, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0808, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0808, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0808, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0807, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0807, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0807, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0807, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0807, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0807, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0807, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0806, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0806, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0806, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0806, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0805, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0806, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0806, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0805, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0805, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0805, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0805, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0804, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0804, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0804, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0804, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0804, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0804, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0804, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0803, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0803, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0803, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0803, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0803, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0803, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0801, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0802, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0801, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0801, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(12.0800, dtype=torch.float64, grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Jn-1Z0NcmYsA",
        "colab_type": "code",
        "outputId": "5875bb05-86e2-48b2-9807-547475397693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot(x, final_y, 'b-')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6aaf6d9390>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd5xU5fXH8c+h2RCxIFJUiB2NGt2g\niTE2VFREsYKoWBKCQY0dUREJYDCoYIuKsWAsuIhEQiwBxIIKsiAhIBZsASJFEVE0SHl+f5zZn2tc\nyjJ35pm5832/XvvanbJzz2By9s65z3OOhRAQEZF0qhU7ABERyR0leRGRFFOSFxFJMSV5EZEUU5IX\nEUmxOrEDqGqbbbYJLVq0iB2GiEhRmTJlyqchhEbVPVZQSb5FixZUVFTEDkNEpKiY2cdrekzlGhGR\nFFOSFxFJMSV5EZEUU5IXEUkxJXkRkRRTkhcRSTEleRGRFFOST7FvvoEHH4Rly2JHIiKxKMmn2MCB\ncN550KEDrFoVOxoRiUFJPqUWL4ZbbvGfx4yB3/8+bjwiEoeSfErdfDN8+SVMnw7nnutJfvTo2FGJ\nSL4pyafQggVw223QsSP8+Mdw112w335w5pkwe3bs6EQknxJJ8mb2kZn9y8ymmVlF5r6tzGyMmb2X\n+b5lEseSdRswAJYvhxtu8NubbAIjRkDt2nDSSboQK1JKkjyTPyyEsG8IoSxz+2pgXAhhF2Bc5rbk\n2Ny5cPfd0KUL7Lrrd/e3aAGPPw4zZkDXrqD57SKlIZflmhOAoZmfhwIn5vBYktGvH6xeDb16/fCx\no46Cvn3hscfgzjvzH5uI5F9SST4A/zCzKWbWNXNf4xDCJ5mf5wONq/tFM+tqZhVmVrFo0aKEwilN\nH3wA998Pv/61n7lXp2dPOP54uOwymDAhr+GJSAQWEvjcbmbNQgjzzGxbYAxwETAqhNCwynM+DyGs\ntS5fVlYWNDRkw3XpAuXl8P770LTpmp+3ZAn89Kfw1VcwdSo0aZK/GEUkeWY2pUqp/HsSOZMPIczL\nfF8IjARaAwvMrEkmgCbAwiSOJdWbNQseeQS6d197ggdo2BBGjoSlS+G002DFivzEKCL5l3WSN7PN\nzGzzyp+Bo4AZwCigS+ZpXYCnsz2WrFnv3rDpptCjx/o9f6+94M9/9pLNlVfmNjYRiSeJGa+NgZFm\nVvl6j4UQnjOzyUC5mZ0PfAyclsCxpBrTpsHw4XDdddCo2lG+1evUCSZN8jX1Bxzgt0UkXRKpySdF\nNfkN0749vPIKfPihl2JqYsUKOOIImDIFJk70zVMiUlxyXpOXeCZOhL/9zUsuNU3wAHXr+sXaLbbw\njVJLliQfo4jEoyRf5Hr18hLNxRdv+Gtst52Xez76CM4+29fZi0g6KMkXsRdfhLFjfe17/frZvdZB\nB8Gtt/qnghtvTCQ8ESkASvJFKgS/0Nq0KXTrlsxrXnghdO4M118Pzz+fzGuKSFxK8kXquefg1Ve9\nXLPJJsm8phkMGeIXX884w8s3IlLclOSLUOVZfIsWPvkpSZtu6h0rV63yC7HffJPs64tIfinJF6G/\n/tXbEdxwA9Srl/zr77yz755980347W/VsVKkmCnJF5lVq7xEs9tuXj/PlXbtvDb/0ENewhGR4pTE\njlfJoyeegJkzYdgwqJPj/3q9e8PkyXDRRbDvvr4rVkSKi3a8FpEVK6BVK6+bv/km1MrD57DFi6Gs\nDL791ktE226b+2OKSM1ox2tKPPywz2jt2zc/CR5gq638Quxnn8Hpp8PKlfk5rogkQ0m+SCxfDr//\nPbRu7UM/8uknP4F77/XNV9dck99ji0h2VJMvEvfdB//+t7cH9oaf+XX22d6xcuBA/0Nzyin5j0FE\nak41+SLw9dew006+omb8+DhJHrwuf8ghPgz8jTdgjz3ixCEi36eafJG76y6YP99r8bESPPia/Cef\n9Au/HTr4ZCkRKWyJJXkzq21mb5rZ6MztlmY2ycxmm9kTZpaDbTvpt3Qp3HQTHH00HHxw7GigWTNf\nxjl7Npx7rjZKiRS6JM/kfwfMqnL7JmBQCGFn4HPg/ASPVTIGD/aVLf36xY7kO4ce6n94nnrKa/Qi\nUrgSSfJm1hw4Dvhz5rYBhwNPZp4yFDgxiWOVksWL4ZZb4MQTfa16IbnsMh8C3rMnjBsXOxoRWZOk\nzuQHA1cBleMmtgaWhBAqV1XPBZpV94tm1tXMKsysYtGiRQmFkw4DB8KXX/rSyUJjBvffD7vvDh07\nwpw5sSMSkepkneTNrB2wMIQwZUN+P4QwJIRQFkIoa1STKdQpt2AB3H67J9BCnbtav76XbJYv9yWV\ny5fHjkhE/lcSZ/IHAe3N7CNgGF6muQ1oaGaV6/CbA/MSOFbJGDDAk+YNN8SOZO122w2GDvUlldmM\nIBSR3Mg6yYcQeoYQmocQWgAdgRdCCJ2B8UDllpkuwNPZHqtUzJ0Ld98NXbrArrvGjmbdOnSAq6/2\nbpUPPBA7GhGpKpfr5HsAl5nZbLxGf38Oj5Uq/fr5MO1evWJHsv769YM2bbz//JQNKtyJSC5ox2uB\n+eADL4H85jdw552xo6mZTz+F/ff3i7JTpsDWW8eOSKQ0aMdrEenTx/vEF2MjsG228R2xn3wCnTr5\ngBMRiUtJvoDMmuVj9y68EJo2jR3NhvnpT70Nw5gxPllKROJSki8gvXt7X5gePWJHkp1f/cq/brwR\nntbldpGolOQLxLRpMHw4XHqplz2K3R13+C7ds8+Gd9+NHY1I6VKSLxC9ekHDht4uIA023tjr83Xr\nwkknwVdfxY5IpDQpyReAiRNh9Gi48kpP9Gmx444+cHzWLC/fFNBCLpGSoSRfAK67Dho1SueO0TZt\noH9/b098222xoxEpPUrykY0f710ce/b0XjBp1KOHd9K84gp4+eXY0YiUFiX5iELws/hmzeCCC2JH\nkztm3t9mp528PfF//hM7IpHSoSQf0XPPwWuveaLfeOPY0eRWgwYwcqRfgD3lFJ8XKyK5pyQfSeVZ\nfMuWcN55saPJj1atvIHZ66/D5ZfHjkakNNRZ91MkF0aOhKlT4aGHfEB2qTjtNJg0CW69FQ44AM48\nM3ZEIummBmURrFoF++wDK1fCjBneq6aUrFzpq27eeMPP6vfZJ3ZEIsVNDcoKzLBhMHOmj/UrtQQP\n/p6feAK22so3Sn3+eeyIRNJLST7PVqzwaU/77OMXIEtV48bexmHOHC/ZrF697t8RkZpLYsbrxmb2\nhpn908xmmlmfzP0tzWySmc02syfMrIQqz2s2dCjMng19+0KtEv8T+7OfweDB8Mwz/u8hUqquugrG\njs3NayeRZpYDh4cQ9gH2Bdqa2YHATcCgEMLOwOfA+Qkcq6gtX+4lmtatoV272NEUhgsu8CZmffp4\nshcpNZMnw8CBkKvLkUnMeA0hhMr2U3UzXwEf6P1k5v6hwInZHqvY3Xeflyf69/cNQuL/Dvfc4+Wr\nzp19MpZIKbnxRthySx+dmQuJFAzMrLaZTQMWAmOA94ElIYSVmafMBZqt4Xe7mlmFmVUsWrQoiXAK\n0tdfe3I/5BA44ojY0RSWTTaBESM84Z90kv9biZSCRYtg1Cgf99mgQW6OkUiSDyGsCiHsCzQHWgO7\n1+B3h4QQykIIZY0aNUoinIJ0110wf74PvNZZ/A/96Efw6KMwfTp066aOlVIannrKFx106pS7YyR6\n6S+EsAQYD/wMaGhmlQsEmwPzkjxWMVm6FAYMgLZt4Re/iB1N4TrmGF959Je/wJ/+FDsakdwrL4fd\ndoMf/zh3x0hidU0jM2uY+XkT4EhgFp7sKxcJdgFKdhDc4MGweLFWkKyP666D446DSy7xvj4iabVg\nAbz4ou8Cz+Wn+yTO5JsA481sOjAZGBNCGA30AC4zs9nA1sD9CRyr6CxeDLfcAh06+Dg8WbtatfxM\nfocd4NRTvcQlkkaVpZrTTsvtcbLebxlCmA78pJr7P8Dr8yVt4ED48ktfOinrZ8stvbfPgQfC6af7\n+uG6dWNHJZKs4cNhjz1gzz1ze5wS346TWwsWwO23+0WVvfaKHU1x2XtvX3L68ss+dEQkTebPh5de\nyn2pBpTkc+oPf/ANUL17x46kOHXuDBddBIMGea8bkbSoLNWcemruj6UknyNz5sDdd0OXLrDrrrGj\nKV433ww//zmcf743dRNJg/Jyn6+Q61INKMnnTL9+vtb7+utjR1Lc6tXz2uXmm/vF6y++iB2RSHY+\n+cTLkLm+4FpJST4H3n/fJyB17Qo77hg7muLXtKmf+Xz4oX8yUsdKKWYjRvgJYD5KNaAknxOVfeKv\nvTZ2JOlx8MFeunn6abjpptjRiGy48nJfiNGqVX6OpySfsFmz4JFH4MILoUmT2NGky8UXQ8eOvmFq\nzJjY0YjU3Lx5MGFC/ko1oCSfuN69YdNNtewvF8zgz3/2M6BOneDjj2NHJFIz+S7VgJJ8ot580y8S\nXnopbLNN7GjSabPNfPnZihVw8snw3//Gjkhk/Q0f7ntAdl/vFo7ZU5JP0PXXQ8OGcNllsSNJt112\n8dYHU6Z4WUykGMQo1YCSfGImToTRo32MV8OGsaNJv/bt/cL2/ff7zliRQvdkZoRSPks1ABYKqHF3\nWVlZqMjVDKwca9MG/vUvXz5Zv37saErDqlXesXL8eHjlFR+rKFKoDjoIli2DadOSf20zmxJCqLYF\nos7kEzB+PIwbBz17KsHnU+3aPmikSRM45RSfsiNSiObM8dbZ+S7VgJJ81kLwJX3NmvlEI8mvrbf2\nC7ELF/qKm5Ur1/07IvkWq1QDSvJZe+45/wvdqxdsvHHsaErTfvt5n6Bx4/wPrkihKS+Hn/zEFw3k\nWxKTobY3s/Fm9paZzTSz32Xu38rMxpjZe5nvW2YfbmGpPItv2RLOPTd2NKXt3HN9GPJNN/mZvUih\n+PhjX5gRo1QDyZzJrwQuDyG0Ag4EuptZK+BqYFwIYRdgXOZ2qowcCVOn+gaoevViRyO33eYXX885\nB95+O3Y0Ii5mqQZysLrGzJ4G7sx8HRpC+MTMmgAvhhB2W9vvFtPqmlWrfFPD6tUwY4ZfBJT45syB\n/ff3zWiTJnn3SpGYDjjA80UuU1veVteYWQt8FOAkoHEI4ZPMQ/OBxkkeK7Zhw+Ctt6BPHyX4QrL9\n9v7f5p134LzzvKQmEstHH8Ebb8Qr1UCCSd7M6gMjgEtCCEurPhb840K1/3czs65mVmFmFYuKZA3c\nihVwww2wzz6+dE8Ky+GHw4AB/jH5lltiRyOlLHapBhJK8mZWF0/wj4YQKi97LciUach8X1jd74YQ\nhoQQykIIZY0aNUoinJwbOhRmz4a+faGW1icVpCuu8N42PXr4PgaRGMrLoazMF2fEksTqGgPuB2aF\nEG6t8tAooEvm5y7A09keqxAsX+794g84ANq1ix2NrIkZPPigj148/XSYOzd2RFJqPvwQJk+OW6qB\nZM7kDwLOAg43s2mZr2OBAcCRZvYe0CZzu+gNGeIX9/r1y/2UdcnO5pv7CqhvvvGy2vLlsSOSUjJ8\nuH+PWaoB9a6pka+/hh/9yNuEjh+vJF8sRozwJN+tm2+aEsmHsjJflDFpUu6Ppd41CbnzTliwQGfx\nxebkk7076D33wEMPxY5GSsH773sr7NilGlCSX29Ll/puyrZt4Re/iB2N1FT//nDYYXDBBT7cRSSX\nKks1hbD6Tkl+PQ0eDIsX+1m8FJ86dXz9/DbbwEknwWefxY5I0qy8HA48EHbcMXYkSvLrZfFiX2/d\noYPvppTitO22Xp//z3+gc2ffhSiStNmz/dNiIZRqQEl+vQwcCF9+6Usnpbi1bg233w7PP++7lUWS\nVkilGlCSX6f58z0pdOoEe+0VOxpJQteu3rWyb1/4299iRyNpU14OP/uZt9goBEry6zBggK+vvuGG\n2JFIUszgrru8D/1ZZ/nHa5EkvPuuj/crlFINKMmv1Zw5vq76nHPiNPuX3NlkE6/P167tF2KXLYsd\nkaRBoZVqQEl+rfr18y6GvXrFjkRyoUULePxxbxXdtas6Vkr2yst9YHfz5rEj+Y6S/Bq8/z488IBP\nGyqEZVCSG0cd5bX5xx6DO+6IHY0Us7ffhunTC6tUA0rya9SnD9StC9dcEzsSybWePaF9e7j8cpgw\nIXY0UqyGD/frPSefHDuS71OSr8Zbb8Ejj8CFF0KTJrGjkVyrVQseftjLN6eeCp98ss5fEfmB8nLf\nDd+sWexIvk9Jvhq9e0P9+t7vRErDFlt4x8qlS/3j9ooVsSOSYvLWW35tp9BKNaAk/wNvvunTXC69\n1LfAS+nYay+4/34v2VxxRexopJgUaqkGlOR/oFcv2HJLT/JSejp2hEsu8Q1wjz0WOxopFsOHwy9/\nWZjlXSX5Kl5/Hf7+d7jySmjYMHY0Essf/wgHHwy/+pWvlhBZm5kz/Sv2cJA1SWrG6wNmttDMZlS5\nbyszG2Nm72W+b5nEsXKpVy9vYnXxxbEjkZjq1vWLaA0b+kapJUtiRySFrJBLNZDcmfxDQNv/ue9q\nYFwIYRdgXOZ2wRo/HsaN8+V0m20WOxqJbbvt/NrMxx9764PVq2NHJIUoBD8hOOQQ/99MIUokyYcQ\nXgYW/8/dJwBDMz8PBU5M4li5EAJcd50vferWLXY0Uih+/nMYNAhGj/ahIyL/a+ZMmDWrMFfVVMpl\nTb5xCKFyxfF8oHF1TzKzrmZWYWYVixYtymE4a/bss/Daa16u2XjjKCFIgere3XvP9+4Nzz0XOxop\nNOXlvs/ipJNiR7JmiQ3yNrMWwOgQwl6Z20tCCA2rPP55CGGtdfkYg7xD8EEgX3zh25Lr1s3r4aUI\nfP21t46dM8fndrZsGTsiKQQhwB57eAVg3Li4scQa5L3AzJpkAmgCLMzhsTbYU0/52vjevZXgpXqb\nbur/OwnBz9i++SZ2RFII/vUveOedwi7VQG6T/CigS+bnLsDTOTzWBlm1Cq6/Hnbf3T+Si6zJTjt5\nq4tp03wYuDpWSjGUaiC5JZSPA68Du5nZXDM7HxgAHGlm7wFtMrcLyrBhvh3597/3vuIia3PccX5S\nMHQo3Htv7GgkphB86eThh0OjRrGjWbvEavJJyGdNfsUKr6fVrw9Tp/pfZJF1Wb0a2rWDsWPh5Zfh\nwANjRyQx/POfsO++/se+a9fY0cSryRe0oUO9Z3y/fkrwsv5q1fKyTfPmPv1nwYLYEUkM5eX+6b9D\nh9iRrFtJprfly71Ec8AB/hFcpCa22sovxH72mfe6WbkydkSST5UboIqhVAMlmuSHDPHlcP37+3Zk\nkZqq/Kj+4ou+S1pKx7RpPvy90FfVVCq5JL9smSf3Qw/1v8QiG+rss+G3v4Wbb/5ugLOkXzGVagDq\nxA4g3+66y+uoI0boLF6yN2iQ77M491zYc09o1Sp2RJJLlaWaNm1g661jR7N+SupMfulSuOkmOOYY\nn6gukq169fwsfrPNfL300qWxI5JcmjoVPvigeEo1UGJJftAgWLwY+vaNHYmkSbNmfnY3e7af0RfQ\nqmRJWHk51KkDJxZsu8UfKpkk/9lncOutfra1//6xo5G0OeQQHzby1FP+XdKnslRz5JG+wqpYlEyS\nHzgQvvzSl06K5MKll/rH+Guuid+wSpI3ZQp89FFxlWqgRJL8/Pk+s/OMM/zimEgumPkg8N139/Xz\n//537IgkSeXl3sTwhBNiR1IzJZHkBwyAb7/1TpMiuVS/vpdsli/3HbH//W/siCQJVUs1Wxb8INPv\nS32SnzMH7r4bzjkHdtkldjRSCnbbDR5+GCZP1rzgtJg82UdBFlupBkogyffr59+vvz5uHFJaTjzR\nd8Led5+XcKS4FWupBlKe5N9/Hx54wLvE7bBD7Gik1PTt65tmuneHPA88kwRVlmqOPhoaNlz38wtN\nqpN8nz7+1/eaa2JHIqWodm14/HFo3BhOPhk+/TR2RLIhJk3ysm8xlmogD0nezNqa2TtmNtvMrs71\n8Sq99Za3hL3wQmjSJF9HFfm+bbbxFhoLFkCnTj6NTIpLebnvbG7fPnYkGyanSd7MagN3AccArYBO\nZpaX7h69e/tKhx498nE0kTUrK/OeSWPHQq9esaORmli92ttWtG0LW2wRO5oNk+sz+dbA7BDCByGE\nb4FhQM4vXbz5Jjz5pG9OKZYmQpJu558Pv/oV/OEP8Ne/xo5G1tfEiTB3bvGWaiD3Sb4ZMKfK7bmZ\n+/6fmXU1swozq1i0aFEiB+3Vy9eyXnZZIi8nkog77vCz+i5d4N13Y0cj62P4cNhoIzj++NiRbLjo\nF15DCENCCGUhhLJGCYxZef11+Pvf4aqrivfjlaTTxht7fb5ePe9F/tVXsSOStalaqmnQIHY0Gy7X\nSX4esH2V280z9+XMddfBttvCRRfl8igiG2aHHWDYMHj7bS/fqGNl4Xr9dZg3r7hLNZD7JD8Z2MXM\nWppZPaAjMCpXB3vhBf+65hrv7y1SiI44wqeTPfEEDB4cOxpZk/Ly4i/VQI6TfAhhJXAh8DwwCygP\nIczMzbH8LL55c/jNb3JxBJHk9OjhJZsrr4SXXoodjfyvylLNscfC5pvHjiY7OR//F0J4Bngm18d5\n9ln/eHXvvV77FClkZvDQQ9C6tZcDpk714SNSGF59FT75pPhLNVAAF16TUHkW/6Mf+WQekWLQoIF3\nrFy2DE491TulSmEoL/eTxXbtYkeSvVQk+aee8rXxvXt7GwORYtGqFTz4oH8K1ZLfwrBqle+zOe44\n31BZ7FKR5A84wNfGd+4cOxKRmjv1VLj8ct8V+5e/xI5GJkzwQUNpKNVASpJ88+Y+1q927diRiGyY\nAQPg0EO9Y+q0abGjKW3l5bDJJn4mnwapSPIixa5OHV8/v/XWPmz+889jR1SaVq3yDWvHHZeeZdhK\n8iIFonFjrwXPnQtnnunL+CS/XnnFO4ampVQDSvIiBeXAA+G22+CZZ7wEKflVXg6bburr49NCSV6k\nwHTr5k3M+vTxPkySHytXeqmmXbv0lGpASV6k4Jj58Pl99/Wyzfvvx46oNLz8MixcmK5SDSjJixSk\nTTbx/R9mPjrw669jR5R+5eV+Bn/MMbEjSZaSvEiBatkSHnsMpk/3fkzqWJk7laWa44/3mnyaKMmL\nFLC2bb02/8gjvllKcuPFF33QetpKNaAkL1Lwrr3WLwZeeim89lrsaNKpvNxbGLRtGzuS5CnJixS4\nWrW83cGOO8Ipp/iWe0nOypV+/eP44/1aSNooyYsUgYYNPREtWeIlhRUrYkeUHuPHw2efpbNUA1km\neTM71cxmmtlqMyv7n8d6mtlsM3vHzI7OLkwR2XtvuO8+35XZo0fsaNIjzaUayH5oyAzgJODeqnea\nWSt81N+eQFNgrJntGkJYleXxREpa584waRIMGuQDRzp2jB1RcVuxwj8hnXBCeocNZXUmH0KYFUJ4\np5qHTgCGhRCWhxA+BGYDrbM5loi4m2+Ggw6C88+HGTNiR1PcXngBFi9Ob6kGcleTbwbMqXJ7bua+\nHzCzrmZWYWYVixYtylE4IulRr57PH23QwDtWfvFF7IiKV3m5/zsedVTsSHJnnUnezMaa2Yxqvk5I\nIoAQwpAQQlkIoaxRo0ZJvKRI6jVp4gnqww+9z406Vtbct9/CyJHpLtXAetTkQwhtNuB15wHbV7nd\nPHOfiCTk4IO9dHPJJT505JprYkdUXMaN8779aS7VQO7KNaOAjma2kZm1BHYB3sjRsURK1sUXwxln\n+CD7f/wjdjTFpbwcttgCjjwydiS5le0Syg5mNhf4GfB3M3seIIQwEygH3gKeA7prZY1I8sxgyBDY\nc0/o1Ak++ih2RMXh88+/K9VstFHsaHLLQgF1PSorKwsVFRWxwxApOu+9B2VlsPPO8Oqr6a4xZ2vR\nIl8TP306TJwI++8fO6LsmdmUEEJZdY9px6tICuyyizcxmzoVundXx8o1+fe/4Re/gFmz4Omn05Hg\n10VJXiQljj/ea/MPPOA7Y+X73n7b9xcsWODXL9I04m9tlORFUuSGG+Doo+Gii+ANLXX4fxUVfga/\nYgW89JL/XCqU5EVSpHZtePRRaNrUJ0ppf6E3IDvsMNh8c5gwAfbZJ3ZE+aUkL5IyW2/tU44+/dR7\n26xcGTuieP76V7/IuuOOfkF6551jR5R/SvIiKbTffj4M/IUXfOhIKXrwQf80s99+PqS7adPYEcWh\nJC+SUuecA926wR//6Gf2peTWW+G886BNGxg7FrbaKnZE8SjJi6TY4MFwwAGe8N9+O3Y0uReCf3K5\n/HI49VQYNQo22yx2VHEpyYuk2EYbwZNP+li7Dh3gyy9jR5Q7q1bBBRfAjTdC167w+OPp3826PpTk\nRVKueXN44gl4910499x0bpT69lvv4XPvvdCzJ9xzj680EiV5kZJw2GHeqXLECLjlltjRJGvZMt8I\nVl7uXTlvvNF7+ojLdvyfiBSJK67wDVI9evh2/sMOix1R9hYvhuOO8/f1wAP+SUW+T2fyIiXCzBPh\nbrvB6afDnDnr/p1C9p//wCGHeL+eJ59Ugl8TJXmRErL55j64+ptv4JRTYPny2BFtmNmzvTXBRx/B\ns8/6RWWpnpK8SInZfXd46CEvcVxySexoam76dE/wS5f6Zq/DD48dUWHLdmjIQDN728ymm9lIM2tY\n5bGeZjbbzN4xs6OzD1VEknLyyXDVVb4K5aGHYkez/l59FX75S6hbF155BX7609gRFb5sz+THAHuF\nEPYG3gV6AphZK6AjsCfQFviTmWlBk0gB6d/fz4K7dfO6dqF79lkf1de4sSf7PfaIHVFxyCrJhxD+\nEUKobH80ER/YDXACMCyEsDyE8CEwG2idzbFEJFl16sCwYdCoEZx0Enz2WeyI1uzxx6F9e0/sr7wC\nO+wQO6LikWRN/jzg2czPzYCq1+7nZu77ATPramYVZlaxSH1RRfKqUSNfO//JJ9C5s+8aLTR/+pPH\ndtBB3jZ4221jR1Rc1pnkzWysmc2o5uuEKs+5FlgJPFrTAEIIQ0IIZSGEskaNGtX010UkS61bwx13\nwPPP+9CRQhEC9O3r4wyPP97LNQ0axI6q+KxzM1QIoc3aHjezc4B2wBHhu6ng84DtqzyteeY+ESlA\nv/41TJoE/fr5xcz27ePGs3a3pHQAAAa+SURBVHo1XHYZ3HYbnH023H+/l5ek5rJdXdMWuApoH0L4\nuspDo4COZraRmbUEdgE0jEykQJnBXXf5TtizzoL33osXy4oV3jXzttt8ieeDDyrBZyPbmvydwObA\nGDObZmb3AIQQZgLlwFvAc0D3EEIBVvtEpNLGG/vO0Tp1/ELssmX5j+Gbb3x551/+4qWaW2+FWtrN\nk5Ws/j6GENY4TCuE0B/on83ri0h+tWjhK1natvUSzqOP5q/Z1xdfeJnolVf8YusFF+TnuGmnv5Ei\n8j1HHeW1+ccfh9tvz88xFy70hmmvveZ/WJTgk6MkLyI/cPXVflZ9xRV+Zp1LH38MBx/sk6tGjYJO\nnXJ7vFKjJC8iP1CrFjz8MLRsCaed5uvoc2HWLO9Ds3AhjBkDxxyTm+OUMiV5EanWFlt4x8qlS31e\n6rffJvv6kyf7GfzKlfDSS77ZSZKnJC8ia7TXXr5G/dVXvXSTlHHjvG9OgwYwYQLsvXdyry3fpyQv\nImvVsaOvV7/jDnjkkexfb+RIOPZYX8kzYQLstFP2rylrpiQvIuv0xz96i9+uXb2f+4Z64AEfVrL/\n/vDyy9C0aXIxSvWU5EVknerWhSeegC239I1SS5bU/DVuvhnOP9/bBY8Z468luackLyLrZbvtYPhw\nX/J41lneX2Z9hAA9e8KVV/ps2VGjYLPNchurfEdJXkTW289/DoMGwejRPnRkXVatgt/8BgYM8O+P\nPgr16uU+TvmOkryI1Ej37nDmmdC7t7f/XZPly31j0333wbXXwt13Q23Nh8s7JXkRqREzuPdeX/bY\nuTN88MEPn/PVV94DfvhwuOUWb5OQrx448n1K8iJSY5tu6hOlQvCukV9XaTS+eDG0aeNr4R980PvC\nSzxK8iKyQXbaydfNT5vmDcVCgHnzfKnltGn+R+Ccc2JHKWrFLyIb7LjjvDbfpw9sv71fWP30U6/V\nH3ZY7OgEsp8M1dfMpmcGhvzDzJpm7jczu93MZmce3y+ZcEWk0Fx/ve9g7d/fa/HjxyvBF5JsyzUD\nQwh7hxD2BUYD12fuPwYf+bcL0BW4O8vjiEiBqlXLyzaXXupticvKYkckVWU7GWpplZubAZWDvE8A\nHs4M9p5oZg3NrEkIIUcNS0Ukpi239FF9UniyrsmbWX/gbOALoPJDWjNgTpWnzc3cpyQvIpJH6yzX\nmNlYM5tRzdcJACGEa0MI2wOPAhfWNAAz62pmFWZWsWjRopq/AxERWaN1nsmHENqs52s9CjwD9Abm\nAdtXeax55r7qXn8IMASgrKwsVPccERHZMNmurtmlys0TgLczP48Czs6ssjkQ+EL1eBGR/Mu2Jj/A\nzHYDVgMfA90y9z8DHAvMBr4Gzs3yOCIisgGyXV1z8hruD0D3bF5bRESyp7YGIiIppiQvIpJi5pWV\nwmBmi/DafrHZBvg0dhB5pvecfqX2fqF43/OOIYRG1T1QUEm+WJlZRQihpDZz6z2nX6m9X0jne1a5\nRkQkxZTkRURSTEk+GUNiBxCB3nP6ldr7hRS+Z9XkRURSTGfyIiIppiQvIpJiSvIJM7PLzSyY2Tax\nY8klMxtoZm9nxjuONLOGsWPKFTNra2bvZMZZXh07nlwzs+3NbLyZvWVmM83sd7Fjyhczq21mb5rZ\n6NixJEVJPkFmtj1wFPDv2LHkwRhgrxDC3sC7QM/I8eSEmdUG7sJHWrYCOplZq7hR5dxK4PIQQivg\nQKB7CbznSr8DZsUOIklK8skaBFzFd2MQUyuE8I8QwsrMzYn4zIA0ag3MDiF8EEL4FhiGt9VOrRDC\nJyGEqZmfv8STXrO4UeWemTUHjgP+HDuWJCnJJyQzKWteCOGfsWOJ4Dzg2dhB5MiaRlmWBDNrAfwE\nmBQ3krwYjJ+krY4dSJKynvFaSsxsLLBdNQ9dC1yDl2pSY23vN4TwdOY51+If7x/NZ2ySe2ZWHxgB\nXBJCWBo7nlwys3bAwhDCFDM7NHY8SVKSr4E1jUI0sx8DLYF/mhl46WKqmbUOIczPY4iJWtfoRzM7\nB2gHHBHSu+FivUdZpomZ1cUT/KMhhKdix5MHBwHtzexYYGOggZk9EkI4M3JcWdNmqBwws4+AshBC\nMXazWy9m1ha4FTgkhJDaCexmVge/sHwEntwnA2eEEGZGDSyHzM9UhgKLQwiXxI4n3zJn8leEENrF\njiUJqsnLhroT2BwYY2bTzOye2AHlQubi8oXA8/gFyPI0J/iMg4CzgMMz/22nZc5wpQjpTF5EJMV0\nJi8ikmJK8iIiKaYkLyKSYkryIiIppiQvIpJiSvIiIimmJC8ikmL/B+MKopOuiCPQAAAAAElFTkSu\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPKpJ3UyanuH",
        "colab_type": "text"
      },
      "source": [
        "Unlike Tensorflow, we can define the graph on the fly. That is why it is more convenient to define a function in Python: we call the function as part of constructing the graph.\n",
        "\n",
        "Let's now create a simple model for classifiying MNIST digits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkdDq61Ea38-",
        "colab_type": "text"
      },
      "source": [
        "##MNIST Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiJiOPA5a-lu",
        "colab_type": "text"
      },
      "source": [
        "MNIST is a famous dataset containing hand-written digits. The training set contains 60k and the test set contains 10k images. Pytorch has built-in functions for downloading well-known datasets like MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeeIOIMha5da",
        "colab_type": "code",
        "outputId": "7855870d-92d3-419a-e635-b9172ab46e34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "mnist_train = datasets.MNIST('data', train=True, download=True,\n",
        "                       transform=transforms.ToTensor())\n",
        "\n",
        "mnist_test = datasets.MNIST('../data', train=False, download=True, transform=\n",
        "                            transforms.ToTensor())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 27644958.33it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 438604.63it/s]\n",
            "  1%|          | 16384/1648877 [00:00<00:11, 141285.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 7462473.12it/s]                           \n",
            "8192it [00:00, 178869.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 16384/9912422 [00:00<01:08, 143827.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 31655024.35it/s]                          \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 430081.37it/s]\n",
            "  1%|          | 16384/1648877 [00:00<00:11, 144230.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 7547969.20it/s]                            \n",
            "8192it [00:00, 177445.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTdP7vjzb35H",
        "colab_type": "code",
        "outputId": "37165ce6-13ed-43fb-adda-d1b73fbbad65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(mnist_train)\n",
        "print(mnist_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ../data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dWTw-Rgbh5O",
        "colab_type": "code",
        "outputId": "b19feac0-8842-45a4-cf4e-b10354777392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "i = npr.randint(1, 50000) \n",
        "example = mnist_train[i]\n",
        "print(\"Label: \", example[1])\n",
        "plt.imshow(example[0].reshape((28,28)), cmap = plt.cm.gray)\n",
        "plt.grid(None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label:  7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5cYaF7PcB7v",
        "colab_type": "text"
      },
      "source": [
        "Pytorch's DataLoader is responsible for creating an iterator over the dataset.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WDyu63wcV3Z",
        "colab_type": "code",
        "outputId": "2160a2b1-c814-47de-fc8d-88ce272bebf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "\n",
        "mnist_train = datasets.MNIST('data', train=True, download=True,\n",
        "                       transform=transforms.ToTensor())\n",
        "\n",
        "mnist_test = datasets.MNIST('data', train=False, download=True, transform=\n",
        "                            transforms.ToTensor())\n",
        "\n",
        "bs = 32\n",
        "train_dl = DataLoader(mnist_train, batch_size=bs)\n",
        "test_dl = DataLoader(mnist_test, batch_size = 100)\n",
        "\n",
        "dataiter = iter(train_dl)\n",
        "images, labels = dataiter.next()\n",
        "viz = torchvision.utils.make_grid(images, nrow=10, padding = 2).numpy()\n",
        "fig, ax = plt.subplots(figsize= (8,8))\n",
        "ax.imshow(np.transpose(viz, (1,2,0)))\n",
        "ax.grid(None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAADWCAYAAAD8ftohAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrE140DYzM2sT/wKdLNt6JpQjOgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "779GU7DKdVbn",
        "colab_type": "text"
      },
      "source": [
        "Using pytorch built-in function we can easily define any model like multi-layer perceptrons. After training, we just care about the average test accuracy, so let's write a function to compute the accuracy over test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Led8bErdZrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_stat(model, dl, device):\n",
        "    model.eval()\n",
        "    cum_loss, cum_acc = 0.0, 0.0\n",
        "    for i, (xb, yb) in enumerate(dl):\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        \n",
        "        xb = xb.view(xb.size(0), -1)\n",
        "        y_pred = model(xb)\n",
        "        loss = loss_fn(y_pred, yb)\n",
        "        acc = (torch.max(y_pred.data, 1)[1] == yb).sum() #accuracy(y_pred, yb)\n",
        "        cum_loss += loss.item() * len(yb)\n",
        "        cum_acc += acc.item() * len(yb)\n",
        "    cum_loss /= 10000\n",
        "    cum_acc /= 10000\n",
        "    model.train()\n",
        "    return cum_loss, cum_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohxuCpR9eLGt",
        "colab_type": "code",
        "outputId": "bf710e4d-25eb-4595-c66a-8f340947cde2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "dim_x = 784\n",
        "dim_h = 100\n",
        "dim_out = 10\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(dim_x, dim_h),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(dim_h, dim_out),\n",
        ")\n",
        "\n",
        "learning_rate = 1e-2\n",
        "epochs = 2\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Using GPUs in PyTorch is pretty straightforward\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Using cuda\")\n",
        "    use_cuda = True\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "#we need to tell pytorch to move the model to gpu\n",
        "model.to(device)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    print(epoch)\n",
        "    for i, (xb, yb) in enumerate(train_dl):\n",
        "\n",
        "        #We also need to transfer the data to the target device\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        xb = xb.view(xb.size(0), -1)\n",
        "        \n",
        "        # Forward pass\n",
        "        y_pred = model(xb)\n",
        "        loss = loss_fn(y_pred, yb)\n",
        "\n",
        "        # Backward pass\n",
        "        model.zero_grad()  # Zero out the previous gradient computation\n",
        "        loss.backward()    # Compute the gradient\n",
        "        optimizer.step()   # Use the gradient information to make a step\n",
        "        \n",
        "    test_loss, test_acc = get_test_stat(model, test_dl, device)\n",
        "    print(\"Test loss: {}  Test acc: {}\".format(test_loss, test_acc))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "Test loss: 0.40868745774030685  Test acc: 88.95\n",
            "1\n",
            "Test loss: 0.32542646139860154  Test acc: 90.89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSTuUZlRgeUD",
        "colab_type": "text"
      },
      "source": [
        "## Dynamic Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji_qMWsOgbbj",
        "colab_type": "text"
      },
      "source": [
        "To showcase the power of PyTorch dynamic graphs, we will implement a very strange model: a fully-connected ReLU network that on each forward pass randomly chooses a number between 1 and 4 and has that many hidden layers, reusing the same weights multiple times to compute the innermost hidden layers.\n",
        "\n",
        "By Justin Johnson https://github.com/jcjohnson/pytorch-examples/blob/master/nn/dynamic_net.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5dRsCN9gnvU",
        "colab_type": "code",
        "outputId": "53d5f259-33e5-471a-c77c-3a4e311e3202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "import random\n",
        "\n",
        "\n",
        "class DynamicNet(torch.nn.Module):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        \"\"\"\n",
        "        In the constructor we construct three nn.Linear instances that we will use\n",
        "        in the forward pass.\n",
        "        \"\"\"\n",
        "        super(DynamicNet, self).__init__()\n",
        "        self.input_linear = torch.nn.Linear(D_in, H)\n",
        "        self.middle_linear = torch.nn.Linear(H, H)\n",
        "        self.output_linear = torch.nn.Linear(H, D_out)\n",
        "\n",
        "    def forward(self, x, verbose = False):\n",
        "        \"\"\"\n",
        "        For the forward pass of the model, we randomly choose either 0, 1, 2, or 3\n",
        "        and reuse the middle_linear Module that many times to compute hidden layer\n",
        "        representations.\n",
        "        Since each forward pass builds a dynamic computation graph, we can use normal\n",
        "        Python control-flow operators like loops or conditional statements when\n",
        "        defining the forward pass of the model.\n",
        "        Here we also see that it is perfectly safe to reuse the same Module many\n",
        "        times when defining a computational graph. This is a big improvement from Lua\n",
        "        Torch, where each Module could be used only once.\n",
        "        \"\"\"\n",
        "        h_relu = self.input_linear(x).clamp(min=0)\n",
        "        n_layers = random.randint(0, 3)\n",
        "        if verbose:\n",
        "            print(\"The number of layers for this run is\", n_layers)\n",
        "            # print(h_relu)\n",
        "        for _ in range(n_layers):\n",
        "            h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
        "            if verbose:\n",
        "                pass\n",
        "                # print(h_relu)\n",
        "        y_pred = self.output_linear(h_relu)\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 10, 1\n",
        "\n",
        "# Create random Tensors to hold inputs and outputs, and wrap them in Variables\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out).requires_grad_(False)\n",
        "\n",
        "# Construct our model by instantiating the class defined above\n",
        "model = DynamicNet(D_in, H, D_out)\n",
        "\n",
        "# Construct our loss function and an Optimizer. Training this strange model with\n",
        "# vanilla stochastic gradient descent is tough, so we use momentum\n",
        "criterion = torch.nn.MSELoss(size_average=False)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
        "for t in range(50):\n",
        "    # Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = criterion(y_pred, y)\n",
        "    print(t, loss.data.item())\n",
        "\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 75.55640411376953\n",
            "1 70.62905883789062\n",
            "2 68.52175903320312\n",
            "3 67.78900146484375\n",
            "4 67.55087280273438\n",
            "5 64.86112213134766\n",
            "6 65.32463073730469\n",
            "7 64.64488983154297\n",
            "8 63.54672622680664\n",
            "9 55.22225570678711\n",
            "10 61.446903228759766\n",
            "11 52.19249725341797\n",
            "12 61.66746520996094\n",
            "13 49.172584533691406\n",
            "14 46.79412078857422\n",
            "15 62.26521682739258\n",
            "16 36.166812896728516\n",
            "17 61.603309631347656\n",
            "18 60.44231414794922\n",
            "19 60.42289733886719\n",
            "20 58.4093132019043\n",
            "21 39.76520538330078\n",
            "22 15.52701187133789\n",
            "23 14.356389999389648\n",
            "24 50.251373291015625\n",
            "25 47.5118408203125\n",
            "26 12.718317031860352\n",
            "27 40.992271423339844\n",
            "28 37.508750915527344\n",
            "29 33.78058624267578\n",
            "30 14.939048767089844\n",
            "31 14.200834274291992\n",
            "32 30.23629379272461\n",
            "33 25.431053161621094\n",
            "34 8.687077522277832\n",
            "35 7.065875053405762\n",
            "36 23.72148895263672\n",
            "37 5.090020656585693\n",
            "38 22.105833053588867\n",
            "39 21.376110076904297\n",
            "40 20.54547119140625\n",
            "41 7.041802406311035\n",
            "42 18.9364013671875\n",
            "43 8.251858711242676\n",
            "44 17.38003158569336\n",
            "45 7.78367280960083\n",
            "46 16.413854598999023\n",
            "47 6.391036510467529\n",
            "48 15.602258682250977\n",
            "49 17.063106536865234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX-mRC_5iNvs",
        "colab_type": "text"
      },
      "source": [
        "##Cifar10 Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVftofphh-ng",
        "colab_type": "text"
      },
      "source": [
        "We will finish with an example on CIFAR10, highlighting the importance of applying transformations to your inputs. Example is lifted from:\n",
        "\n",
        "https://github.com/uoguelph-mlrg/Cutout/blob/master/train.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iAw2caKiW97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 120)\n",
        "        self.fc3 = nn.Linear(120, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3p2SQViibIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(data_normalize=False, data_augment=False):\n",
        " \n",
        "    train_transform = transforms.Compose([])\n",
        "    test_transform = transforms.Compose([])\n",
        "\n",
        "    if data_augment:\n",
        "        train_transform.transforms.append(transforms.RandomCrop(32, padding=4))\n",
        "        train_transform.transforms.append(transforms.RandomHorizontalFlip())\n",
        "    \n",
        "    train_transform.transforms.append(transforms.ToTensor())\n",
        "    test_transform.transforms.append(transforms.ToTensor())\n",
        "        \n",
        "    if data_normalize:\n",
        "        normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
        "                                         std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
        "        train_transform.transforms.append(normalize)\n",
        "        test_transform.transforms.append(normalize)\n",
        "\n",
        "  \n",
        "    train_dataset = datasets.CIFAR10(root='data/',\n",
        "                                     train=True,\n",
        "                                     transform=train_transform,\n",
        "                                     download=True)\n",
        "\n",
        "    test_dataset = datasets.CIFAR10(root='data/',\n",
        "                                    train=False,\n",
        "                                    transform=test_transform,\n",
        "                                    download=True)\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                               batch_size=128,\n",
        "                                               shuffle=True,\n",
        "                                               num_workers=2)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                              batch_size=128,\n",
        "                                              shuffle=False,\n",
        "                                              num_workers=2)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def test(net, loader):\n",
        "    net.eval()    # Change model to 'eval' mode (BN uses moving mean/var).\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "    for images, labels in loader:\n",
        "        with torch.no_grad():\n",
        "            pred = net(images)\n",
        "\n",
        "        pred = torch.max(pred.data, 1)[1]\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "\n",
        "    val_acc = correct / total\n",
        "    net.train()\n",
        "    return val_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GR395vyihIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(train_loader, test_loader, epochs=5):\n",
        "    \n",
        "    net = Net()\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9) \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    train_accs = []\n",
        "    test_accs = []\n",
        "    \n",
        "    net.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(epoch)\n",
        "\n",
        "        xentropy_loss_avg = 0.\n",
        "        correct = 0.\n",
        "        total = 0.\n",
        "\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "           \n",
        "            net.zero_grad()\n",
        "            pred = net(images)\n",
        "            xentropy_loss = criterion(pred, labels)\n",
        "            xentropy_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            xentropy_loss_avg += xentropy_loss.item()\n",
        "\n",
        "            # Calculate running average of accuracy\n",
        "            pred = torch.max(pred.data, 1)[1]\n",
        "            total += labels.size(0)\n",
        "            correct += (pred == labels.data).sum().item()\n",
        "            accuracy = correct / total\n",
        "        \n",
        "        test_acc = test(net, test_loader)\n",
        "        print(\"Test acc: \", test_acc)\n",
        "        train_accs.append(accuracy)\n",
        "        test_accs.append(test_acc)\n",
        "    return train_accs, test_accs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MADQb81UijK7",
        "colab_type": "code",
        "outputId": "de18d442-5354-4099-95c1-6ab26a4cba3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "train_loader, test_loader = get_data(data_augment=False, data_normalize=False)\n",
        "train_accs, test_accs = train_model(train_loader, test_loader, epochs=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:02, 73630492.24it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data/\n",
            "Files already downloaded and verified\n",
            "0\n",
            "Test acc:  0.2835\n",
            "1\n",
            "Test acc:  0.3006\n",
            "2\n",
            "Test acc:  0.3557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnYCP-REikzs",
        "colab_type": "code",
        "outputId": "661de97c-cc2f-4c88-9dc9-49fcf1db96a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "train_loader, test_loader = get_data(data_augment=False, data_normalize=True)\n",
        "normalize_train_accs, normalize_test_accs = train_model(train_loader, test_loader, epochs=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "0\n",
            "Test acc:  0.3884\n",
            "1\n",
            "Test acc:  0.4332\n",
            "2\n",
            "Test acc:  0.4502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRwFghLzimSJ",
        "colab_type": "code",
        "outputId": "adf16f14-c354-4bfd-a9d7-f97b4d8bc759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "epochs = 3\n",
        "ax.plot(range(epochs), train_accs, c=\"blue\", label=\"no input normalization\")\n",
        "ax.plot(range(epochs), normalize_train_accs, c=\"red\", label=\"input normalization\")\n",
        "ax.legend()\n",
        "ax.set_xlabel(\"Epochs\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "ax.set_title(\"Train Accuracy\")\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKUGIiEhc/w/DzHjpzmpYlQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}